{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Static Network Analysis\n",
    "* Degree (in-degree/out-degree)\n",
    "* Diameter\n",
    "* (Mean shortest path length)\n",
    "* (Top-k eigenvalues)\n",
    "* (Betweennes centrality)\n",
    "* (Closeness centrality)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A temporal network is goint to be analysed which consists of 678907 vertices and 4729035 edges, where each edge has time information associated with it. Some of the edges have the same source and target vertex, but are association with different timestamps. This statick network analysi, however, ignores time-information and thus we use a graph build solely on the pairs of source and target vertices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"darkgreen\">Imports, configuation and preprocessing</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import igraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = open(\"data/tgraph_real_wikiedithyperlinks_noTime.txt\", 'rb')\n",
    "g_new = igraph.read(wiki)\n",
    "wiki.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5,\n",
       " 10,\n",
       " 10,\n",
       " 12,\n",
       " 14,\n",
       " 15,\n",
       " 17,\n",
       " 20,\n",
       " 21,\n",
       " 24,\n",
       " 31,\n",
       " 34,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 51,\n",
       " 84,\n",
       " 97,\n",
       " 114,\n",
       " 118,\n",
       " 146,\n",
       " 146,\n",
       " 149,\n",
       " 149,\n",
       " 200,\n",
       " 216,\n",
       " 220,\n",
       " 249,\n",
       " 363,\n",
       " 394,\n",
       " 396,\n",
       " 696,\n",
       " 701,\n",
       " 940,\n",
       " 958,\n",
       " 966,\n",
       " 1173,\n",
       " 1264,\n",
       " 1620,\n",
       " 1765,\n",
       " 1769,\n",
       " 1833,\n",
       " 2005,\n",
       " 2051,\n",
       " 2053,\n",
       " 2446,\n",
       " 2479,\n",
       " 2555,\n",
       " 2728,\n",
       " 2764,\n",
       " 3404,\n",
       " 3570,\n",
       " 3722,\n",
       " 4054,\n",
       " 4281,\n",
       " 4466,\n",
       " 4475,\n",
       " 4479,\n",
       " 4491,\n",
       " 4525,\n",
       " 4644,\n",
       " 4724,\n",
       " 4801,\n",
       " 5017,\n",
       " 5020,\n",
       " 5302,\n",
       " 5304,\n",
       " 5342,\n",
       " 5446,\n",
       " 5951,\n",
       " 6237,\n",
       " 6244,\n",
       " 6446,\n",
       " 6563,\n",
       " 7510,\n",
       " 7516,\n",
       " 7540,\n",
       " 7541,\n",
       " 7551,\n",
       " 9145,\n",
       " 9731,\n",
       " 15902,\n",
       " 16500,\n",
       " 17936,\n",
       " 19074,\n",
       " 24001,\n",
       " 24700,\n",
       " 26251,\n",
       " 26254,\n",
       " 29952,\n",
       " 33705,\n",
       " 34183,\n",
       " 34183,\n",
       " 34533,\n",
       " 34936,\n",
       " 36342,\n",
       " 36360,\n",
       " 37559,\n",
       " 39348,\n",
       " 42180,\n",
       " 42584,\n",
       " 47191,\n",
       " 54610,\n",
       " 57237,\n",
       " 57318,\n",
       " 65546,\n",
       " 70098,\n",
       " 78761,\n",
       " 79861,\n",
       " 80178,\n",
       " 80410,\n",
       " 82581,\n",
       " 87426,\n",
       " 87976,\n",
       " 88597,\n",
       " 90674,\n",
       " 90686,\n",
       " 90737,\n",
       " 95371,\n",
       " 97610,\n",
       " 97614,\n",
       " 97628,\n",
       " 97631,\n",
       " 97632,\n",
       " 97632,\n",
       " 97633,\n",
       " 97640,\n",
       " 97641,\n",
       " 97647,\n",
       " 97657,\n",
       " 97663,\n",
       " 97667,\n",
       " 97671,\n",
       " 97672,\n",
       " 97687,\n",
       " 97693,\n",
       " 97694,\n",
       " 97696,\n",
       " 97698]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_new.successors(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "succ = list(nx.dfs_successors(G, '7'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115601"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(succ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directed Graph with parallel edges (due to different timestamps of the edges between pairs of vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki = open(\"data/tgraph_real_wikiedithyperlinks_noTime.txt\", 'rb')\n",
    "G_par = nx.read_edgelist(wiki, create_using=nx.MultiDiGraph())\n",
    "wiki.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directed Graph used for static network analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki = open(\"data/tgraph_real_wikiedithyperlinks_noTime.txt\", 'rb')\n",
    "G = nx.read_edgelist(wiki, create_using=nx.DiGraph())\n",
    "wiki.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataframe(G_in):\n",
    "    df_edge_in = pd.DataFrame(list(G_in.in_degree()), columns=['node', 'in edges'])\n",
    "    df_edge_out = pd.DataFrame(list(G_in.out_degree()), columns=['node', 'out edges'])\n",
    "    df_total = pd.merge(df_edge_in, df_edge_out, on='node')\n",
    "    df_total.index = df_total.index + 1\n",
    "    return df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki_df_par = create_dataframe(G_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>580</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  node  in edges  out edges\n",
       "9    7       580         76"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df.loc[wiki_df.node == '7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.has_node('7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>62</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>1375</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>1068</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  node  in edges  out edges\n",
       "1    1        28         88\n",
       "2    6        10          0\n",
       "3    8        62          6\n",
       "4    9      1375        477\n",
       "5    3      1068        451"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df = create_dataframe(G)\n",
    "wiki_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.dfs_successors(G, '6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-93acc2832502>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwiki_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwiki_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'out edges'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    }
   ],
   "source": [
    "values = list(wiki_df.loc[wiki_df['out edges'] == 0].node.values)\n",
    "values = list(map(int, values))\n",
    "hist(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"darkgreen\">1. Static Network Analysis:</font> Degree distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first network property which is going to be analyzed of the static network is the degree distribution. While it is an easily comprehensible network measure, it can still lead to interesting findings as we have seen in the previous assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki_df['in edges'].mean() == wiki_df['out edges'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is expected of course since every outgoing edge is an incoming edge of the graph. This check is just done to check whether the parsing of the Graph object to a dataframe is done without any errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki_df['in edges'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki_df['in edges'].max(), wiki_df['in edges'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki_df['out edges'].max(), wiki_df['out edges'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean of the incoming edges is just under above the 5 links. The node with the highest number of incoming edges has a little more than $10^4$ incoming edges, while the node with the highest number of outgoing edges has around  $4.3*10^3$ outgoing edges. These values do not implicate anything by themselves, but these values will be used in elaborations further on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue with the static network analysis note that for the static network analysis it does not make sense to consider parallel edges. The parallel edges are edges between a pair of vertices at different time-stamps. But this gives a deceptive view in the static network analysis part. If a page has $y$ incoming edges of the same source vertex $x$, at different time-stamps it does not make sense to consider all of these parallel edges for many measures such as the degree distribution, page-rank etc. The choice is, therefore, made to continue with the network as a directed graph ($DiGraph$ in networkx) instead of a multi-directed graph ($MultiDiGraph$) for the static network analysis. These edges, however, have to be considered in part two for the Temporal Network Analysis where the time information of the edges is of the essence and techniques such as snapshot-based analysis can or even should be exploited.\n",
    "\n",
    "Just to give you an overview of the deceiving effects it can have on the measures calculated over these two types of networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki_df_par['in edges'].mean(), wiki_df_par['in edges'].max(), wiki_df_par['out edges'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It adds up the parallel edges between pair of vertices which result in a higher number of incoming and/or outgoing edges for many vertices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue with the analysis of the degree-distribution now that we have this pecularity out of the way. We are going to divide nodes of the network into deciles to get a better grasp of the characteristics of the top and bottom nodes when it boils down to number of incoming or outgoing edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki_df['decile_incoming_edges'] = pd.cut((wiki_df['in edges']), 10, labels=False)\n",
    "wiki_df.loc[wiki_df.decile_incoming_edges.between(1, 9)].shape, wiki_df.loc[wiki_df.decile_incoming_edges.between(0, 1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki_df['decile_outgoing_edges'] = pd.cut((wiki_df['out edges']), 10, labels=False)\n",
    "wiki_df.loc[wiki_df.decile_outgoing_edges.between(1, 9)].shape, wiki_df.loc[wiki_df.decile_outgoing_edges.between(0, 1)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is a very skewed distribution among the nodes when we make splits based upon their number number of incoming or outgoing edges. There is thus a small set of nodes (i.e. pages) with relatively high number of incoming edges and a small set of nodes with a relatively high number of outgoing edges.\n",
    "\n",
    "Let's divide the nodes in four groups such that in each quartile we have the same number of vertices (not the same as quartiles) intstead of the current configuration since this will faciliate a better comparison of the the groups considering the very skewed distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_incoming_edges = wiki_df.sort_values(['in edges']).reset_index(drop = True)\n",
    "sorted_outgoing_edges = wiki_df.sort_values(['out edges']).reset_index(drop = True)\n",
    "sorted_incoming_edges.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "incoming_edges_q1 = sorted_incoming_edges.iloc[: math.floor(sorted_incoming_edges.shape[0] / 4)]\n",
    "incoming_edges_q2 = sorted_incoming_edges.iloc[math.floor(sorted_incoming_edges.shape[0] / 4) : 2 * (math.floor(sorted_incoming_edges.shape[0] / 4))]\n",
    "incoming_edges_q3 = sorted_incoming_edges.iloc[2 * (math.floor(sorted_incoming_edges.shape[0] / 4)) : 3 * (math.floor(sorted_incoming_edges.shape[0] / 4))]\n",
    "incoming_edges_q4 = sorted_incoming_edges.iloc[3 * (math.floor(sorted_incoming_edges.shape[0] / 4)) :]\n",
    "\n",
    "incoming_edges_bottom_1 = sorted_incoming_edges.iloc[: math.floor(sorted_incoming_edges.shape[0] / 100)]\n",
    "incoming_edges_top_1 = sorted_incoming_edges.iloc[99 * math.floor(sorted_incoming_edges.shape[0] / 100):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outgoing_edges_q1 = sorted_outgoing_edges.iloc[: math.floor(sorted_outgoing_edges.shape[0] / 4)]\n",
    "outgoing_edges_q2 = sorted_outgoing_edges.iloc[math.floor(sorted_outgoing_edges.shape[0] / 4) : 2 * (math.floor(sorted_outgoing_edges.shape[0] / 4))]\n",
    "outgoing_edges_q3 = sorted_outgoing_edges.iloc[2 * (math.floor(sorted_outgoing_edges.shape[0] / 4)) : 3 * (math.floor(sorted_outgoing_edges.shape[0] / 4))]\n",
    "outgoing_edges_q4 = sorted_outgoing_edges.iloc[3 * (math.floor(sorted_outgoing_edges.shape[0] / 4)) :]\n",
    "\n",
    "outgoing_edges_bottom_1 = sorted_outgoing_edges.iloc[: math.floor(sorted_outgoing_edges.shape[0] / 100)]\n",
    "outgoing_edges_top_1 = sorted_outgoing_edges.iloc[99 * math.floor(sorted_outgoing_edges.shape[0] / 100):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And just to double-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(incoming_edges_q4.shape[0] + incoming_edges_q3.shape[0] + \n",
    " incoming_edges_q2.shape[0] + incoming_edges_q1.shape[0]) == sorted_incoming_edges.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at what there are some notable things in the devised groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "incoming_edges_q1['in edges'].mean(), incoming_edges_q2['in edges'].mean(), incoming_edges_q3['in edges'].mean(), incoming_edges_q4['in edges'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "incoming_edges_q1['out edges'].mean(), incoming_edges_q2['out edges'].mean(), incoming_edges_q3['out edges'].mean(), incoming_edges_q4['out edges'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outgoing_edges_q1['in edges'].mean(), outgoing_edges_q2['in edges'].mean(), outgoing_edges_q3['in edges'].mean(), outgoing_edges_q4['in edges'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outgoing_edges_q1['out edges'].mean(), outgoing_edges_q2['out edges'].mean(), outgoing_edges_q3['out edges'].mean(), outgoing_edges_q4['out edges'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "incoming_edges_bottom_1['in edges'].mean(), incoming_edges_top_1['in edges'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "incoming_edges_bottom_1['out edges'].mean(), incoming_edges_top_1['out edges'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outgoing_edges_bottom_1['in edges'].mean(), outgoing_edges_top_1['in edges'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outgoing_edges_bottom_1['out edges'].mean(), outgoing_edges_top_1['out edges'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <i>Mean incoming and outgoing edges total network: $5.3$</i> \n",
    "#### <i>Sorted on number of incoming edges</i>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Group</th>\n",
    "        <th>Mean #Incoming Edges</th>\n",
    "        <th>Mean #Outgoing Edges</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><i>Bottom 1%</i></td>\n",
    "        <td>$0.00$</td>\n",
    "        <td>$4.46$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Q1 <i>(Bottom 25%)</i></td>\n",
    "        <td>$0.00$</td>\n",
    "        <td>$3.83$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Q2</td>\n",
    "        <td>$0.81$</td>\n",
    "        <td>$2.36$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Q3</td>\n",
    "        <td>$1.82$</td>\n",
    "        <td>$3.58$</td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>Q4 <i>(Top 25%)</i></td>\n",
    "        <td>$18.6$</td>\n",
    "        <td>$11.5$</td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td><i>Top 1%</i></td>\n",
    "        <td>$235$</td>\n",
    "        <td>$64.0$</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "#### <i>Sorted on number of outgoing edges</i>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Group</th>\n",
    "        <th>Mean #Incoming Edges</th>\n",
    "        <th>Mean #Outgoing Edges</th>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td><i>Bottom 1%</i></td>\n",
    "        <td>$2.89$</td>\n",
    "        <td>$0.00$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Q1 <i>(Bottom 25%)</i></td>\n",
    "        <td>$3.97$</td>\n",
    "        <td>$0.00$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Q2</td>\n",
    "        <td>$3.67$</td>\n",
    "        <td>$0.81$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Q3</td>\n",
    "        <td>$2.49$</td>\n",
    "        <td>$2.21$</td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>Q4 <i>(Top 25%)</i></td>\n",
    "        <td>$11.1$</td>\n",
    "        <td>$18.2$</td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td><i>Top 1%</i></td>\n",
    "        <td>$112$</td>\n",
    "        <td>$160$</td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two noteworthy things in this graph. The nodes with a relatively high number of outgoing edges (i.e. the top $25\\%$ or even the top $1\\%$) also have a relatively high number of incoming edges when compared to the rest of the network. It thus seems that pages that have a lot of links to other pages also seem to be relatively high linked (i.e. have incoming edges) pages themselves  Note that there is a relatively large group (i.e. pages). The same can be seen in the top groups of when grouped/sorted by number of incoming edges. These groups do not only have a relatively higher number of incoming edges (on average) than the rest of the network, but also a relatively higher frequency of   in the network that do not have incoming edges, but have a relatively high number of outgoing edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(str((wiki_df.loc[wiki_df[\"out edges\"] == 0.00].shape[0] / wiki_df[\"out edges\"].shape[0]) * 100), \"%\")\n",
    "print(str((wiki_df.loc[wiki_df[\"in edges\"] == 0.00].shape[0] / wiki_df[\"in edges\"].shape[0]) * 100), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, one can see that part of the skewness of the degree distribution (see bottom groups) is due to pages that have either no incoming or outgoing edges. Having no incoming edges can be explained by pages that are the \"entry-page\" to this network of pages (i.e. referred to by somebody googling it / typing it in their address bar) while having no outgoing edges can be explained by pages that simply have no links on them (i.e. pages showing files etc.). These possible explanations are, however, just assumptions / guesses. There is no metadata about the pages available, so we can actually not confirm these hypotheses by more in-depth evaluations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"darkgreen\">2. Static Network Analysis:</font> Diameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next meausure which is going to be calculated and evaluated in the context of static network analysis is a grpah distance measure: the diameter. It encapsulates the maximum found eccentricity of any node in the network. Or in other words the longest of all the shortest paths between the vertices in the network. This may sound a bit confusing, but imagine that we have a set of all the shortest paths between each pair of vertices in the network. The maximum found value in this set is the diameter of the network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>A</b> --- <b>B</b> --- <b>C</b>&emsp;&emsp;&emsp; <i>Diameter:</i> $4$ (A-I and G-C) <br> \n",
    "|&emsp;&emsp;|&emsp;&emsp;| <br>\n",
    "<b>D</b> --- <b>E</b> --- <b>F</b> <br>\n",
    "|&emsp;&emsp;|&emsp;&emsp;| <br>\n",
    "<b>G</b> --- <b>H</b> --- <b>I</b> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>A</b> --- <b>B</b> --- <b>C</b>&emsp;&emsp;&emsp; <i>Diameter:</i> $5$  (A-J) <br> \n",
    "|&emsp;&emsp;|&emsp;&emsp;| <br>\n",
    "<b>D</b> --- <b>E</b> --- <b>F</b> <br>\n",
    "|&emsp;&emsp;|&emsp;&emsp;| <br>\n",
    "<b>G</b> --- <b>H</b> --- <b>I</b> --- <b>J</b> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This toyish example should give you a clear overview of what is measured by the distance measure that is diameter. Note, however, that this example is considering undirected edges, while we are of course interested in this measure of a directed graph of links. We will translate the measure back to our problem and network context in a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a directed graph (i.e. network) that is not strongly connected since there are nodes $u$ which have no path to certain nodes $v$, we cannot simply use the diameter function of $networkx$ to calculate the diameter of the graph. The reason for this is a that if a shortest path from $u$ to $v$ is non-existent in the graph, it will be $\\infty$ (think about Dijkstra's shortest path algorithm). And since the diameter function of $networkx$ simply calcultes the eccentricity of the Graph and returns the max value found in this collection, it will not work since the eccentricity function and thus the diameter function will raise an error because the graph is not strongly connected. \n",
    "\n",
    "A hack around this issue is pretty simple when one takes a look at the source code of $networkx$ (praise open-source software :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx.is_strongly_connected(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with the built in $networkx$ function for calculating the diameter of a graphh is that the function relies on the eccentricity function. Eccentricity finds the shortest path from a node $u$ to all the other nodes and does this this for all the graphs in the network. The diameter function then calls this function on the graph and takes the max (i.e. longest shortest path) over the returned collection of all the shortest paths by eccentricity. \n",
    "\n",
    "But we still want to be able to calculate the diameter of this graph which is not strongly connected. Some code is devised below which transforms the original graph to a strongly connected graph by removing the nodes which make it 'weak', but after some evaluation we came to the conclusion that there is a risk of not finding the real diameter of the original graph. We, therefore, took a dive into the source code of $networkx$ and implement the function ourselves to fit our problem context and graph pecularities. The function is rather straigthforward, but unfortunately not very efficient. It is, however, exactly what is done under the hood in the functions of $networkx$ except the fact that we check whether there actually exists a path between a source node $u$ and a target node $v$ before actually calculating the shortest path between these nodes to prevent the function from returning 'infinity' and thus deteriorate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Make original graph strongly connected\n",
    "\n",
    "nodes_in_strong_components = list(list(node)[0] for node in nx.strongly_connected_components(G))\n",
    "gen_strong = G.nbunch_iter(nodes_in_strong_components)\n",
    "\n",
    "edges_in_strong_components = nx.edges(G, nodes_in_strong_components)\n",
    "self_loop_edges = list(nx.selfloop_edges(G))\n",
    "edges_in_strong_components_no_loop = (set(edges_in_strong_components).difference(set(self_loop_edges)))\n",
    "G_strong = G.edge_subgraph(edges_in_strong_components_no_loop)\n",
    "\n",
    "entering_nodes = list(node for node in G_strong.nodes() if ((G_strong.in_degree(node) == 0) | (G_strong.out_degree(node) == 0)))\n",
    "G_strong.remove_nodes_from(entering_nodes)\n",
    "((len(G) - len(G_strong))/ len(G)) * 100\n",
    "nx.is_strongly_connected(G_strong)\n",
    "\n",
    "nx.diameter(G_strong, e = None, usebounds = False)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the function $nx.shortest\\_path\\_length$ relies on an implementation of Dijkstra's algorithm, the choice is made to remove the selfloop-edges since this (can) corrupt the results and the running time of the algorithm depending on the pecularities of the implementation of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "self_loop_edges = list(nx.selfloop_edges(G))\n",
    "edges_no_loop = list(set(G.edges()).difference(set(self_loop_edges)))\n",
    "G_no_loop = G.edge_subgraph(edges_no_loop)\n",
    "len(self_loop_edges) + len(edges_no_loop)== len(G.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# edges_loops = nx.simple_cycles(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the longest shortest path in the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def longest_shortest_path(G_in):\n",
    "    max_distance = len(G_in) - 1\n",
    "    longest = 0\n",
    "    nodes = list(G_in.nodes())\n",
    "    for u in nodes:\n",
    "        for v in list(nx.dfs_successors(G_in, source = u)): # depth-first-search of successors\n",
    "            if ((u != v) & (nx.has_path(G_in, u, v))):\n",
    "                path_length = nx.shortest_path_length(G_in, source = u, target = v)\n",
    "                if (path_length > longest):\n",
    "                    longest = path_length\n",
    "                    print(\"current longest: \", longest)\n",
    "                    if(longest >= len(G_in)):\n",
    "                        return max_distance\n",
    "    return longest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function could be optimized by implementing depth-first-search ourselves and comparing the shortest path-lengths along the way, but thay may be a bit far fetched for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# diameter = longest_shortest_path(G_no_loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def number_of_successors(row):\n",
    "    node = str(row.node)\n",
    "    successors = set(nx.dfs_postorder_nodes(G, node))\n",
    "    successors = list(successors.differnece(set(node)))\n",
    "    print(successors)\n",
    "    return successors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">To-do: Implication of the value of the distance measure in relation to our problem contex/the characteristics of the network.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"darkgreen\">3. Static Network Analysis:</font> Mean shortest-path length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next statistical measure in this static network analysis has a strong relationship to the previous statistical measure. While the diameter captured the maximum eccentricity (i.e. the greatest distance between any pair of nodes in the network) found among all the nodes in the graph, the mean shortest-path length is a metric that captures the average distance (i.e. shortest path) between any pair of vertices in the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few things to consider before we can actually continue with the evaluation of this metric. As we know by know the graph view (ignoring the time-stamps) that is taken in this static network analysis contains selfloop-edges and many other peculartities that can deterioriate the calculation of the means-shortest-path length and thus affect any implications that are going to be suggested after the evaluation of the result in our the context of our network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The choice is made to calculate the mean shortest-path length across all the pairs of vertices $u$ and $v$ in the graph where 1) $u\\, !=\\, v$ and  2) there exist a path from $u$ to $v$ (would otherwise result in $\\infty$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"darkgreen\">4. Static Network Analysis:</font> Betweenness centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-1747e0e4760d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkatz_central\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkatz_centrality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<decorator-gen-176>\u001b[0m in \u001b[0;36mkatz_centrality\u001b[1;34m(G, alpha, beta, max_iter, tol, nstart, normalized, weight)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\networkx\\utils\\decorators.py\u001b[0m in \u001b[0;36m_not_implemented_for\u001b[1;34m(f, *args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m                                             ' '.join(graph_types))\n\u001b[0;32m     69\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_not_implemented_for\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\networkx\\algorithms\\centrality\\katz.py\u001b[0m in \u001b[0;36mkatz_centrality\u001b[1;34m(G, alpha, beta, max_iter, tol, nstart, normalized, weight)\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mnbr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m                 \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnbr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mxlast\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnbr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "katz_central = nx.katz_centrality(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"darkgreen\">5. Static Network Analysis:</font> Closeness centrality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
