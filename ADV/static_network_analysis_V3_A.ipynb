{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Static Network Analysis\n",
    "* Degree (in-degree/out-degree)\n",
    "* Diameter\n",
    "* (Mean shortest path length)\n",
    "* (Top-k eigenvalues)\n",
    "* (Betweennes centrality)\n",
    "* (Closeness centrality)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A temporal network is goint to be analysed which consists of 678907 vertices and 4729035 edges, where each edge has time information associated with it. Some of the edges have the same source and target vertex, but are association with different timestamps. This statick network analysi, however, ignores time-information and thus we use a graph build solely on the pairs of source and target vertices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"darkgreen\">Imports, configuation and preprocessing</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import igraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directed Graph with parallel edges (due to different timestamps of the edges between pairs of vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki = open(\"data/tgraph_real_wikiedithyperlinks_noTime.txt\", 'rb')\n",
    "G_par = nx.read_edgelist(wiki, create_using=nx.MultiDiGraph())\n",
    "wiki.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directed Graph used for static network analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki = open(\"data/tgraph_real_wikiedithyperlinks_noTime.txt\", 'rb')\n",
    "G = nx.read_edgelist(wiki, create_using=nx.DiGraph())\n",
    "wiki.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki = open(\"data/tgraph_real_wikiedithyperlinks_noTime.txt\", 'rb')\n",
    "G_i = igraph.read(wiki) # used for certain functions absenst in networkx / are more efficient in igraph\n",
    "wiki.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataframe(G_in):\n",
    "    df_edge_in = pd.DataFrame(list(G_in.in_degree()), columns=['node', 'in edges'])\n",
    "    df_edge_out = pd.DataFrame(list(G_in.out_degree()), columns=['node', 'out edges'])\n",
    "    df_total = pd.merge(df_edge_in, df_edge_out, on='node')\n",
    "    df_total.index = df_total.index + 1\n",
    "    return df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki_df_par = create_dataframe(G_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>62</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>1375</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>1068</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  node  in edges  out edges\n",
       "1    1        28         88\n",
       "2    6        10          0\n",
       "3    8        62          6\n",
       "4    9      1375        477\n",
       "5    3      1068        451"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df = create_dataframe(G)\n",
    "wiki_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"darkgreen\">1. Static Network Analysis:</font> Degree distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first network property which is going to be analyzed of the static network is the degree distribution. While it is an easily comprehensible network measure, it can still lead to interesting findings as we have seen in the previous assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df['in edges'].mean() == wiki_df['out edges'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is expected of course since every outgoing edge is an incoming edge of the graph. This check is just done to check whether the parsing of the Graph object to a dataframe is done without any errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.3091660566174745"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df['in edges'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10521, 0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df['in edges'].max(), wiki_df['in edges'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4302, 0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df['out edges'].max(), wiki_df['out edges'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean of the incoming edges is just under above the 5 links. The node with the highest number of incoming edges has a little more than $10^4$ incoming edges, while the node with the highest number of outgoing edges has around  $4.3*10^3$ outgoing edges. These values do not implicate anything by themselves, but these values will be used in elaborations further on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue with the static network analysis note that for the static network analysis it does not make sense to consider parallel edges. The parallel edges are edges between a pair of vertices at different time-stamps. But this gives a deceptive view in the static network analysis part. If a page has $y$ incoming edges of the same source vertex $x$, at different time-stamps it does not make sense to consider all of these parallel edges for many measures such as the degree distribution, page-rank etc. The choice is, therefore, made to continue with the network as a directed graph ($DiGraph$ in networkx) instead of a multi-directed graph ($MultiDiGraph$) for the static network analysis. These edges, however, have to be considered in part two for the Temporal Network Analysis where the time information of the edges is of the essence and techniques such as snapshot-based analysis can or even should be exploited.\n",
    "\n",
    "Just to give you an overview of the deceiving effects it can have on the measures calculated over these two types of networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.965659508592488, 15871, 15017)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df_par['in edges'].mean(), wiki_df_par['in edges'].max(), wiki_df_par['out edges'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It adds up the parallel edges between pair of vertices which result in a higher number of incoming and/or outgoing edges for many vertices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue with the analysis of the degree-distribution now that we have this pecularity out of the way. We are going to divide nodes of the network into deciles to get a better grasp of the characteristics of the top and bottom nodes when it boils down to number of incoming or outgoing edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((220, 4), (678830, 4))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df['decile_incoming_edges'] = pd.cut((wiki_df['in edges']), 10, labels=False)\n",
    "wiki_df.loc[wiki_df.decile_incoming_edges.between(1, 9)].shape, wiki_df.loc[wiki_df.decile_incoming_edges.between(0, 1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((305, 5), (678835, 5))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df['decile_outgoing_edges'] = pd.cut((wiki_df['out edges']), 10, labels=False)\n",
    "wiki_df.loc[wiki_df.decile_outgoing_edges.between(1, 9)].shape, wiki_df.loc[wiki_df.decile_outgoing_edges.between(0, 1)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is a very skewed distribution among the nodes when we make splits based upon their number number of incoming or outgoing edges. There is thus a small set of nodes (i.e. pages) with relatively high number of incoming edges and a small set of nodes with a relatively high number of outgoing edges.\n",
    "\n",
    "Let's divide the nodes in four groups such that in each quartile we have the same number of vertices (not the same as quartiles) intstead of the current configuration since this will faciliate a better comparison of the the groups considering the very skewed distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "      <th>decile_incoming_edges</th>\n",
       "      <th>decile_outgoing_edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>678902</th>\n",
       "      <td>300</td>\n",
       "      <td>7975</td>\n",
       "      <td>1686</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678903</th>\n",
       "      <td>3546</td>\n",
       "      <td>8561</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678904</th>\n",
       "      <td>146</td>\n",
       "      <td>9264</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678905</th>\n",
       "      <td>149</td>\n",
       "      <td>9655</td>\n",
       "      <td>545</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678906</th>\n",
       "      <td>394</td>\n",
       "      <td>10521</td>\n",
       "      <td>1777</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        node  in edges  out edges  decile_incoming_edges  \\\n",
       "678902   300      7975       1686                      7   \n",
       "678903  3546      8561          0                      8   \n",
       "678904   146      9264          0                      8   \n",
       "678905   149      9655        545                      9   \n",
       "678906   394     10521       1777                      9   \n",
       "\n",
       "        decile_outgoing_edges  \n",
       "678902                      3  \n",
       "678903                      0  \n",
       "678904                      0  \n",
       "678905                      1  \n",
       "678906                      4  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_incoming_edges = wiki_df.sort_values(['in edges']).reset_index(drop = True)\n",
    "sorted_outgoing_edges = wiki_df.sort_values(['out edges']).reset_index(drop = True)\n",
    "sorted_incoming_edges.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "incoming_edges_q1 = sorted_incoming_edges.iloc[: math.floor(sorted_incoming_edges.shape[0] / 4)]\n",
    "incoming_edges_q2 = sorted_incoming_edges.iloc[math.floor(sorted_incoming_edges.shape[0] / 4) : 2 * (math.floor(sorted_incoming_edges.shape[0] / 4))]\n",
    "incoming_edges_q3 = sorted_incoming_edges.iloc[2 * (math.floor(sorted_incoming_edges.shape[0] / 4)) : 3 * (math.floor(sorted_incoming_edges.shape[0] / 4))]\n",
    "incoming_edges_q4 = sorted_incoming_edges.iloc[3 * (math.floor(sorted_incoming_edges.shape[0] / 4)) :]\n",
    "\n",
    "incoming_edges_bottom_1 = sorted_incoming_edges.iloc[: math.floor(sorted_incoming_edges.shape[0] / 100)]\n",
    "incoming_edges_top_1 = sorted_incoming_edges.iloc[99 * math.floor(sorted_incoming_edges.shape[0] / 100):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outgoing_edges_q1 = sorted_outgoing_edges.iloc[: math.floor(sorted_outgoing_edges.shape[0] / 4)]\n",
    "outgoing_edges_q2 = sorted_outgoing_edges.iloc[math.floor(sorted_outgoing_edges.shape[0] / 4) : 2 * (math.floor(sorted_outgoing_edges.shape[0] / 4))]\n",
    "outgoing_edges_q3 = sorted_outgoing_edges.iloc[2 * (math.floor(sorted_outgoing_edges.shape[0] / 4)) : 3 * (math.floor(sorted_outgoing_edges.shape[0] / 4))]\n",
    "outgoing_edges_q4 = sorted_outgoing_edges.iloc[3 * (math.floor(sorted_outgoing_edges.shape[0] / 4)) :]\n",
    "\n",
    "outgoing_edges_bottom_1 = sorted_outgoing_edges.iloc[: math.floor(sorted_outgoing_edges.shape[0] / 100)]\n",
    "outgoing_edges_top_1 = sorted_outgoing_edges.iloc[99 * math.floor(sorted_outgoing_edges.shape[0] / 100):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And just to double-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(incoming_edges_q4.shape[0] + incoming_edges_q3.shape[0] + \n",
    " incoming_edges_q2.shape[0] + incoming_edges_q1.shape[0]) == sorted_incoming_edges.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at what there are some notable things in the devised groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.806753237571144, 1.8176236993742856, 18.61205215372741)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incoming_edges_q1['in edges'].mean(), incoming_edges_q2['in edges'].mean(), incoming_edges_q3['in edges'].mean(), incoming_edges_q4['in edges'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.8300142582751024, 2.36138835534921, 3.578950779491651, 11.466202004371675)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incoming_edges_q1['out edges'].mean(), incoming_edges_q2['out edges'].mean(), incoming_edges_q3['out edges'].mean(), incoming_edges_q4['out edges'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.9767507629944734, 3.667994296689959, 2.489977964483933, 11.101838813638212)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outgoing_edges_q1['in edges'].mean(), outgoing_edges_q2['in edges'].mean(), outgoing_edges_q3['in edges'].mean(), outgoing_edges_q4['in edges'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.8123446024769334, 2.209997289749361, 18.214094232570744)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outgoing_edges_q1['out edges'].mean(), outgoing_edges_q2['out edges'].mean(), outgoing_edges_q3['out edges'].mean(), outgoing_edges_q4['out edges'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 235.2441141848146)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incoming_edges_bottom_1['in edges'].mean(), incoming_edges_top_1['in edges'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.4613345117101195, 63.97998822836963)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incoming_edges_bottom_1['out edges'].mean(), incoming_edges_top_1['out edges'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.8858447488584473, 112.43952324896998)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outgoing_edges_bottom_1['in edges'].mean(), outgoing_edges_top_1['in edges'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 160.2302825191289)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outgoing_edges_bottom_1['out edges'].mean(), outgoing_edges_top_1['out edges'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <i>Mean incoming and outgoing edges total network: $5.3$</i> \n",
    "#### <i>Sorted on number of incoming edges</i>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Group</th>\n",
    "        <th>Mean #Incoming Edges</th>\n",
    "        <th>Mean #Outgoing Edges</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><i>Bottom 1%</i></td>\n",
    "        <td>$0.00$</td>\n",
    "        <td>$4.46$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Q1 <i>(Bottom 25%)</i></td>\n",
    "        <td>$0.00$</td>\n",
    "        <td>$3.83$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Q2</td>\n",
    "        <td>$0.81$</td>\n",
    "        <td>$2.36$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Q3</td>\n",
    "        <td>$1.82$</td>\n",
    "        <td>$3.58$</td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>Q4 <i>(Top 25%)</i></td>\n",
    "        <td>$18.6$</td>\n",
    "        <td>$11.5$</td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td><i>Top 1%</i></td>\n",
    "        <td>$235$</td>\n",
    "        <td>$64.0$</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "#### <i>Sorted on number of outgoing edges</i>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Group</th>\n",
    "        <th>Mean #Incoming Edges</th>\n",
    "        <th>Mean #Outgoing Edges</th>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td><i>Bottom 1%</i></td>\n",
    "        <td>$2.89$</td>\n",
    "        <td>$0.00$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Q1 <i>(Bottom 25%)</i></td>\n",
    "        <td>$3.97$</td>\n",
    "        <td>$0.00$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Q2</td>\n",
    "        <td>$3.67$</td>\n",
    "        <td>$0.81$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Q3</td>\n",
    "        <td>$2.49$</td>\n",
    "        <td>$2.21$</td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>Q4 <i>(Top 25%)</i></td>\n",
    "        <td>$11.1$</td>\n",
    "        <td>$18.2$</td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td><i>Top 1%</i></td>\n",
    "        <td>$112$</td>\n",
    "        <td>$160$</td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two noteworthy things in this graph. The nodes with a relatively high number of outgoing edges (i.e. the top $25\\%$ or even the top $1\\%$) also have a relatively high number of incoming edges when compared to the rest of the network. It thus seems that pages that have a lot of links to other pages also seem to be relatively high linked (i.e. have incoming edges) pages themselves  Note that there is a relatively large group (i.e. pages). The same can be seen in the top groups of when grouped/sorted by number of incoming edges. These groups do not only have a relatively higher number of incoming edges (on average) than the rest of the network, but also a relatively higher frequency of   in the network that do not have incoming edges, but have a relatively high number of outgoing edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.691253735784134 %\n",
      "29.83103724074137 %\n"
     ]
    }
   ],
   "source": [
    "print(str((wiki_df.loc[wiki_df[\"out edges\"] == 0.00].shape[0] / wiki_df[\"out edges\"].shape[0]) * 100), \"%\")\n",
    "print(str((wiki_df.loc[wiki_df[\"in edges\"] == 0.00].shape[0] / wiki_df[\"in edges\"].shape[0]) * 100), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, one can see that part of the skewness of the degree distribution (see bottom groups) is due to pages that have either no incoming or outgoing edges. Having no incoming edges can be explained by pages that are the \"entry-page\" to this network of pages (i.e. referred to by somebody googling it / typing it in their address bar) while having no outgoing edges can be explained by pages that simply have no links on them (i.e. pages showing files etc.). These possible explanations are, however, just assumptions / guesses. There is no metadata about the pages available, so we can actually not confirm these hypotheses by more in-depth evaluations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"darkgreen\">2. Static Network Analysis:</font> Diameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next meausure which is going to be calculated and evaluated in the context of static network analysis is a grpah distance measure: the diameter. It encapsulates the maximum found eccentricity of any node in the network. Or in other words the longest of all the shortest paths between the vertices in the network. This may sound a bit confusing, but imagine that we have a set of all the shortest paths between each pair of vertices in the network. The maximum found value in this set is the diameter of the network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>A</b> --- <b>B</b> --- <b>C</b>&emsp;&emsp;&emsp; <i>Diameter:</i> $4$ (A-I and G-C) <br> \n",
    "|&emsp;&emsp;|&emsp;&emsp;| <br>\n",
    "<b>D</b> --- <b>E</b> --- <b>F</b> <br>\n",
    "|&emsp;&emsp;|&emsp;&emsp;| <br>\n",
    "<b>G</b> --- <b>H</b> --- <b>I</b> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>A</b> --- <b>B</b> --- <b>C</b>&emsp;&emsp;&emsp; <i>Diameter:</i> $5$  (A-J) <br> \n",
    "|&emsp;&emsp;|&emsp;&emsp;| <br>\n",
    "<b>D</b> --- <b>E</b> --- <b>F</b> <br>\n",
    "|&emsp;&emsp;|&emsp;&emsp;| <br>\n",
    "<b>G</b> --- <b>H</b> --- <b>I</b> --- <b>J</b> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This toyish example should give you a clear overview of what is measured by the distance measure that is diameter. Note, however, that this example is considering undirected edges, while we are of course interested in this measure of a directed graph of links. We will translate the measure back to our problem and network context in a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a directed graph (i.e. network) that is not strongly connected since there are nodes $u$ which have no path to certain nodes $v$, we cannot simply use the diameter function of $networkx$ to calculate the diameter of the graph. The reason for this is a that if a shortest path from $u$ to $v$ is non-existent in the graph, it will be $\\infty$ (think about Dijkstra's shortest path algorithm). And since the diameter function of $networkx$ simply calcultes the eccentricity of the Graph and returns the max value found in this collection, it will not work since the eccentricity function and thus the diameter function will raise an error because the graph is not strongly connected. \n",
    "\n",
    "A hack around this issue is pretty simple when one takes a look at the source code of $networkx$ (praise open-source software :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.is_strongly_connected(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with the built in $networkx$ function for calculating the diameter of a graphh is that the function relies on the eccentricity function. Eccentricity finds the shortest path from a node $u$ to all the other nodes and does this this for all the graphs in the network. The diameter function then calls this function on the graph and takes the max (i.e. longest shortest path) over the returned collection of all the shortest paths by eccentricity. \n",
    "\n",
    "But we still want to be able to calculate the diameter of this graph which is not strongly connected. Some code is devised below which transforms the original graph to a strongly connected graph by removing the nodes which make it 'weak', but after some evaluation we came to the conclusion that there is a risk of not finding the real diameter of the original graph. We, therefore, took a dive into the source code of $networkx$ and implement the function ourselves to fit our problem context and graph pecularities. The function is rather straigthforward, but unfortunately not very efficient. It is, however, exactly what is done under the hood in the functions of $networkx$ except the fact that we check whether there actually exists a path between a source node $u$ and a target node $v$ before actually calculating the shortest path between these nodes to prevent the function from returning 'infinity' and thus deteriorate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMake original graph strongly connected\\n\\nnodes_in_strong_components = list(list(node)[0] for node in nx.strongly_connected_components(G))\\ngen_strong = G.nbunch_iter(nodes_in_strong_components)\\n\\nedges_in_strong_components = nx.edges(G, nodes_in_strong_components)\\nself_loop_edges = list(nx.selfloop_edges(G))\\nedges_in_strong_components_no_loop = (set(edges_in_strong_components).difference(set(self_loop_edges)))\\nG_strong = G.edge_subgraph(edges_in_strong_components_no_loop)\\n\\nentering_nodes = list(node for node in G_strong.nodes() if ((G_strong.in_degree(node) == 0) | (G_strong.out_degree(node) == 0)))\\nG_strong.remove_nodes_from(entering_nodes)\\n((len(G) - len(G_strong))/ len(G)) * 100\\nnx.is_strongly_connected(G_strong)\\n\\nnx.diameter(G_strong, e = None, usebounds = False)\\n\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Make original graph strongly connected\n",
    "\n",
    "nodes_in_strong_components = list(list(node)[0] for node in nx.strongly_connected_components(G))\n",
    "gen_strong = G.nbunch_iter(nodes_in_strong_components)\n",
    "\n",
    "edges_in_strong_components = nx.edges(G, nodes_in_strong_components)\n",
    "self_loop_edges = list(nx.selfloop_edges(G))\n",
    "edges_in_strong_components_no_loop = (set(edges_in_strong_components).difference(set(self_loop_edges)))\n",
    "G_strong = G.edge_subgraph(edges_in_strong_components_no_loop)\n",
    "\n",
    "entering_nodes = list(node for node in G_strong.nodes() if ((G_strong.in_degree(node) == 0) | (G_strong.out_degree(node) == 0)))\n",
    "G_strong.remove_nodes_from(entering_nodes)\n",
    "((len(G) - len(G_strong))/ len(G)) * 100\n",
    "nx.is_strongly_connected(G_strong)\n",
    "\n",
    "nx.diameter(G_strong, e = None, usebounds = False)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the function $nx.shortest\\_path\\_length$ relies on an implementation of Dijkstra's algorithm, the choice is made to remove the selfloop-edges since this (can) corrupt the results and the running time of the algorithm depending on the pecularities of the implementation of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_loop_edges = list(nx.selfloop_edges(G))\n",
    "edges_no_loop = list(set(G.edges()).difference(set(self_loop_edges)))\n",
    "G_no_loop = G.edge_subgraph(edges_no_loop)\n",
    "len(self_loop_edges) + len(edges_no_loop)== len(G.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# edges_loops = nx.simple_cycles(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the longest shortest path in the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def longest_shortest_path(G_in):\n",
    "    max_distance = len(G_in) - 1\n",
    "    longest = 0\n",
    "    nodes = list(G_in.nodes())\n",
    "    for u in nodes:\n",
    "        for v in list(nx.dfs_successors(G_in, source = u)): # depth-first-search of successors\n",
    "            if ((u != v) & (nx.has_path(G_in, u, v))):\n",
    "                path_length = nx.shortest_path_length(G_in, source = u, target = v)\n",
    "                if (path_length > longest):\n",
    "                    longest = path_length\n",
    "                    print(\"current longest: \", longest)\n",
    "                    if(longest >= len(G_in)):\n",
    "                        return max_distance\n",
    "    return longest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function could be optimized by implementing depth-first-search ourselves and comparing the shortest path-lengths along the way, but thay may be a bit far fetched for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# diameter = longest_shortest_path(G_no_loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "      <th>decile_incoming_edges</th>\n",
       "      <th>decile_outgoing_edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>62</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>1375</td>\n",
       "      <td>477</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>1068</td>\n",
       "      <td>451</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  node  in edges  out edges  decile_incoming_edges  decile_outgoing_edges\n",
       "1    1        28         88                      0                      0\n",
       "2    6        10          0                      0                      0\n",
       "3    8        62          6                      0                      0\n",
       "4    9      1375        477                      1                      1\n",
       "5    3      1068        451                      1                      1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracker = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nr_successors_and_diameter_and_mean(node):\n",
    "    node = str(node)\n",
    "    total = mean = 0 # sum shortest path lengths\n",
    "    longest = 0 # track longesth shortest path found\n",
    "    \n",
    "    successors = set(nx.dfs_successors(G, node))\n",
    "    successors = list(successors - (set(node)))\n",
    "    nr_paths = 0 # count paths for average\n",
    "    \n",
    "    for v in successors[-100:]:\n",
    "        global tracker # track progress\n",
    "        print(\"node: \", tracker)\n",
    "        tracker += 1\n",
    "        \n",
    "        path_length = nx.shortest_path_length(G, source = node, target = v)\n",
    "        nr_paths += 1\n",
    "        total += path_length\n",
    "        if (path_length > longest):\n",
    "            longest = path_length\n",
    "    if (nr_paths != 0):\n",
    "        mean = int(total / nr_paths)\n",
    "    return longest, mean, len(successors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wiki_df['longest_sp'], wiki_df['mean_sp'], wiki_df['nr_successors'] = zip(*wiki_df['node'].map(nr_successors_and_diameter_and_mean)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">To-do: Implication of the value of the distance measure in relation to our problem contex/the characteristics of the network.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"darkgreen\">3. Static Network Analysis:</font> Dyads and Triads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might be an uncommon measure in this course, but it can have quite interesting implications for the network in context. We wanted to go beyond the suggested measures and have, therefore, done some reading on networks science ourselves. One of the papers we came accross was an elaboration on Dyads and Triads found in Directed Graphs. It boils down to classifying each pair of nodes $u$ and $v$ in the network (i.e. a directed graph in our context) into three categories, which are:\n",
    "\n",
    "1. <b>Mutual:</b> There is an edge from $u$ to $v$ and also an edge frome $v$ to $u$\n",
    "2. <b>Asymmetric:</b> There is either an edge from $u$ to $v$ or an edge from $v$ to $u$\n",
    "3. <b>Null:</b> There is no edge from $u$ to $v$ and also no edge frome $v$ to $u$\n",
    "\n",
    "The actual implications for our network should be quite evident. We can measure how many pages have a symmetric link between each other, how many pages have a one way link to each other and how many pages have no link between each other. We are going to  elaborate on this further on after some calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dyad_census = G_i.dyad_census()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('asymmetric', 4504680), ('mutual', 112177), ('null', 1275203668)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(graph_dyad_census.as_dict().items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, however, that this includes nodes with self-loops and parallel edges as explained before that deterioriate any observations that can be made about the measures, so before we actually place it in the problem context, let's remove those edges and recalcuate the measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_i = G_i.simplify(multiple = True, loops = True, combine_edges = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph_dyad_census = G_i.dyad_census()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('asymmetric', 3410945), ('mutual', 87818), ('null', 1276321762)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(graph_dyad_census.as_dict().items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To put this in better perspective it makes sense to look at the percentages of the total $u \\times v$ pairs which are possible in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of total for  asymmetric  edges, is:  0.2665 %\n",
      "percentage of total for  mutual  edges, is:  0.0069 %\n"
     ]
    }
   ],
   "source": [
    "total_count = sum(list(graph_dyad_census))\n",
    "for metric in sorted(graph_dyad_census.as_dict().items())[:2]:\n",
    "    print(\"percentage of total for \", metric[0], \" edges, is: \", round(((metric[1] / total_count) * 100), 4), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are thus 1) a lot of pages which do not have an (asymmetric) link to each other, and the number of pages that link to each other (i.e. mutual) are even less common. This actually does make sense when one considers the context of a network of a website/domain. One would not expect that every page has a link to every other page in the network, especially considering the size of this particular network. In addition, having mutual edges on a website depends entirely on the type of webpages one is considering. For some webpages it makes sense considering the navigation of the website. Or consider pages on WikiPedia which refer to a sub-topic of certain topic. This sub-topic is likely to have also a link back to the main topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider, for example, the WikiPedia page on Network Science. Several links to sub-topics and/or related topics have a link on the page back to the page of Network Science. This is not only due to reference links in the text (i.e. information) on that page, but also due to the navigation lay-out of wikipedia which enhances this type of navigation by suggesting similar / related topics and classifiying (sub-)topics into groups (see the Wiki page on Complex Networks for example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One could thus consider the measure to be an indicator of how related certain pages are if one considers this context. This can be interesting to evaulate over time (i.e task 2). We can test this hypothesis of the relation between mutual edges and relations between (sub)-topics by analyzing both the relative and absolute changes of these measures. Note, however, that we cannot confirm these hypotheses by the lack of context (i.e. metadata about the pages). But first, we can go into a little more depth about the implications of these measures and also consider another, related, measure in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment, nodes with no incoming edges are included. The same goes for pages with no outgoing links. The question is, however, if we want to include these pages in our results. If we place the network in question again in the context of its origin one would assume that these pages can be considered as 'entry'-pages to the domain of the network while the nodes with no outgoing links can be pages with only links to pages outside of the domain. Wikipedia has, for example, a lot of pages with media (i.e. pictures) that only have a link to the source of the content (i.e. links to twitter, wikimediafoundation, google images etc.). These pages are not really interesting to for the assessment of the mutuality hypotheses. Let's re-asses the values once more after the removal of these nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_delete_ids = [v.index for v in G_i.vs if ((v.indegree() == 0) | (v.outdegree == 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_i.delete_vertices(to_delete_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('asymmetric', 2549501), ('mutual', 87818), ('null', 442034664)]\n",
      "percentage of total for  asymmetric  edges, is:  0.5733 %\n",
      "percentage of total for  mutual  edges, is:  0.0197 %\n"
     ]
    }
   ],
   "source": [
    "graph_dyad_census = G_i.dyad_census()\n",
    "print(sorted(graph_dyad_census.as_dict().items())[:3])\n",
    "total_count = sum(list(graph_dyad_census))\n",
    "\n",
    "for metric in sorted(graph_dyad_census.as_dict().items())[:2]:\n",
    "    print(\"percentage of total for \", metric[0], \" edges, is: \", round(((metric[1] / total_count) * 100), 4), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which gives a better representation of the measures in our particular network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"darkgreen\">4. Static Network Analysis:</font> Reciprocity and Transitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"darkgreen\">4. Static Network Analysis:</font> Mean shortest-path length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next statistical measure in this static network analysis has a strong relationship to the previous statistical measure. While the diameter captured the maximum eccentricity (i.e. the greatest distance between any pair of nodes in the network) found among all the nodes in the graph, the mean shortest-path length is a metric that captures the average distance (i.e. shortest path) between any pair of vertices in the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few things to consider before we can actually continue with the evaluation of this metric. As we know by know the graph view (ignoring the time-stamps) that is taken in this static network analysis contains selfloop-edges and many other peculartities that can deterioriate the calculation of the means-shortest-path length and thus affect any implications that are going to be suggested after the evaluation of the result in our the context of our network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The choice is made to calculate the mean shortest-path length across all the pairs of vertices $u$ and $v$ in the graph where 1) $u\\, !=\\, v$ and  2) there exist a path from $u$ to $v$ (would otherwise result in $\\infty$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"darkgreen\">5. Static Network Analysis:</font> Betweenness centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nx.betweenness_centrality(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"darkgreen\">6. Static Network Analysis:</font> Closeness centrality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
