{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Static Network Analysis\n",
    "* Degree (in-degree/out-degree)\n",
    "* Diameter\n",
    "* Dyads\n",
    "* Reciprocity and Transitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A temporal network is goint to be analysed which consists of 678907 vertices and 4729035 edges, where each edge has time information associated with it. Some of the edges have the same source and target vertex, but are association with different timestamps. This statick network analysi, however, ignores time-information and thus we use a graph build solely on the pairs of source and target vertices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"darkgreen\">Imports, configuation and preprocessing</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import igraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directed Graph with parallel edges (due to different timestamps of the edges between pairs of vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki = open(\"data/tgraph_real_wikiedithyperlinks_noTime.txt\", 'rb')\n",
    "G_par = nx.read_edgelist(wiki, create_using=nx.MultiDiGraph())\n",
    "wiki.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directed Graph used for static network analysis (networkx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki = open(\"data/tgraph_real_wikiedithyperlinks_noTime.txt\", 'rb')\n",
    "G = nx.read_edgelist(wiki, create_using=nx.DiGraph())\n",
    "wiki.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directed Graph used for static network analysis (igraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki = open(\"data/tgraph_real_wikiedithyperlinks_noTime.txt\", 'rb')\n",
    "G_i = igraph.read(wiki) # used for certain functions absenst in networkx / are more efficient in igraph\n",
    "wiki.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataframe(G_in):\n",
    "    df_edge_in = pd.DataFrame(list(G_in.in_degree()), columns=['node', 'in edges'])\n",
    "    df_edge_out = pd.DataFrame(list(G_in.out_degree()), columns=['node', 'out edges'])\n",
    "    df_total = pd.merge(df_edge_in, df_edge_out, on='node')\n",
    "    df_total.index = df_total.index + 1\n",
    "    return df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki_df_par = create_dataframe(G_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>62</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>1375</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>1068</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  node  in edges  out edges\n",
       "1    1        28         88\n",
       "2    6        10          0\n",
       "3    8        62          6\n",
       "4    9      1375        477\n",
       "5    3      1068        451"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df = create_dataframe(G)\n",
    "wiki_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"darkgreen\">1. Static Network Analysis:</font> Degree distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first network property which is going to be analyzed of the static network is the degree distribution. While it is an easily comprehensible network measure, it can still lead to interesting findings as we have seen in the previous assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df['in edges'].mean() == wiki_df['out edges'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is expected of course since every outgoing edge is an incoming edge of the graph. This check is just done to check whether the parsing of the Graph object to a dataframe is done without any errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.3091660566174745"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df['in edges'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10521, 0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df['in edges'].max(), wiki_df['in edges'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4302, 0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df['out edges'].max(), wiki_df['out edges'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean of the incoming edges is just under above the 5 links. The node with the highest number of incoming edges has a little more than $10^4$ incoming edges, while the node with the highest number of outgoing edges has around  $4.3*10^3$ outgoing edges. These values do not implicate anything by themselves, but these values will be used in elaborations further on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue with the static network analysis note that for the static network analysis it does not make sense to consider parallel edges. The parallel edges are edges between a pair of vertices at different time-stamps. But this gives a deceptive view in the static network analysis part. If a page has $y$ incoming edges of the same source vertex $x$, at different time-stamps it does not make sense to consider all of these parallel edges for many measures such as the degree distribution, page-rank etc. The choice is, therefore, made to continue with the network as a directed graph ($DiGraph$ in networkx) instead of a multi-directed graph ($MultiDiGraph$) for the static network analysis. These edges, however, have to be considered in part two for the Temporal Network Analysis where the time information of the edges is of the essence and techniques such as snapshot-based analysis can or even should be exploited.\n",
    "\n",
    "Just to give you an overview of the deceiving effects it can have on the measures calculated over these two types of networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.965659508592488, 15871, 15017)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df_par['in edges'].mean(), wiki_df_par['in edges'].max(), wiki_df_par['out edges'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It adds up the parallel edges between pair of vertices which result in a higher number of incoming and/or outgoing edges for many vertices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue with the analysis of the degree-distribution now that we have this pecularity out of the way. We are going to divide nodes of the network into deciles to get a better grasp of the characteristics of the top and bottom nodes when it boils down to number of incoming or outgoing edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((220, 4), (678830, 4))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df['decile_incoming_edges'] = pd.cut((wiki_df['in edges']), 10, labels=False)\n",
    "wiki_df.loc[wiki_df.decile_incoming_edges.between(1, 9)].shape, wiki_df.loc[wiki_df.decile_incoming_edges.between(0, 1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((305, 5), (678835, 5))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df['decile_outgoing_edges'] = pd.cut((wiki_df['out edges']), 10, labels=False)\n",
    "wiki_df.loc[wiki_df.decile_outgoing_edges.between(1, 9)].shape, wiki_df.loc[wiki_df.decile_outgoing_edges.between(0, 1)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is a very skewed distribution among the nodes when we make splits based upon their number number of incoming or outgoing edges. There is thus a small set of nodes (i.e. pages) with relatively high number of incoming edges and a small set of nodes with a relatively high number of outgoing edges.\n",
    "\n",
    "Let's divide the nodes in four groups such that in each quartile we have the same number of vertices (not the same as quartiles) intstead of the current configuration since this will faciliate a better comparison of the the groups considering the very skewed distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "      <th>decile_incoming_edges</th>\n",
       "      <th>decile_outgoing_edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>678902</th>\n",
       "      <td>300</td>\n",
       "      <td>7975</td>\n",
       "      <td>1686</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678903</th>\n",
       "      <td>3546</td>\n",
       "      <td>8561</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678904</th>\n",
       "      <td>146</td>\n",
       "      <td>9264</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678905</th>\n",
       "      <td>149</td>\n",
       "      <td>9655</td>\n",
       "      <td>545</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678906</th>\n",
       "      <td>394</td>\n",
       "      <td>10521</td>\n",
       "      <td>1777</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        node  in edges  out edges  decile_incoming_edges  \\\n",
       "678902   300      7975       1686                      7   \n",
       "678903  3546      8561          0                      8   \n",
       "678904   146      9264          0                      8   \n",
       "678905   149      9655        545                      9   \n",
       "678906   394     10521       1777                      9   \n",
       "\n",
       "        decile_outgoing_edges  \n",
       "678902                      3  \n",
       "678903                      0  \n",
       "678904                      0  \n",
       "678905                      1  \n",
       "678906                      4  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_incoming_edges = wiki_df.sort_values(['in edges']).reset_index(drop = True)\n",
    "sorted_outgoing_edges = wiki_df.sort_values(['out edges']).reset_index(drop = True)\n",
    "sorted_incoming_edges.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "incoming_edges_q1 = sorted_incoming_edges.iloc[: math.floor(sorted_incoming_edges.shape[0] / 4)]\n",
    "incoming_edges_q2 = sorted_incoming_edges.iloc[math.floor(sorted_incoming_edges.shape[0] / 4) : 2 * (math.floor(sorted_incoming_edges.shape[0] / 4))]\n",
    "incoming_edges_q3 = sorted_incoming_edges.iloc[2 * (math.floor(sorted_incoming_edges.shape[0] / 4)) : 3 * (math.floor(sorted_incoming_edges.shape[0] / 4))]\n",
    "incoming_edges_q4 = sorted_incoming_edges.iloc[3 * (math.floor(sorted_incoming_edges.shape[0] / 4)) :]\n",
    "\n",
    "incoming_edges_bottom_1 = sorted_incoming_edges.iloc[: math.floor(sorted_incoming_edges.shape[0] / 100)]\n",
    "incoming_edges_top_1 = sorted_incoming_edges.iloc[99 * math.floor(sorted_incoming_edges.shape[0] / 100):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outgoing_edges_q1 = sorted_outgoing_edges.iloc[: math.floor(sorted_outgoing_edges.shape[0] / 4)]\n",
    "outgoing_edges_q2 = sorted_outgoing_edges.iloc[math.floor(sorted_outgoing_edges.shape[0] / 4) : 2 * (math.floor(sorted_outgoing_edges.shape[0] / 4))]\n",
    "outgoing_edges_q3 = sorted_outgoing_edges.iloc[2 * (math.floor(sorted_outgoing_edges.shape[0] / 4)) : 3 * (math.floor(sorted_outgoing_edges.shape[0] / 4))]\n",
    "outgoing_edges_q4 = sorted_outgoing_edges.iloc[3 * (math.floor(sorted_outgoing_edges.shape[0] / 4)) :]\n",
    "\n",
    "outgoing_edges_bottom_1 = sorted_outgoing_edges.iloc[: math.floor(sorted_outgoing_edges.shape[0] / 100)]\n",
    "outgoing_edges_top_1 = sorted_outgoing_edges.iloc[99 * math.floor(sorted_outgoing_edges.shape[0] / 100):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And just to double-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(incoming_edges_q4.shape[0] + incoming_edges_q3.shape[0] + \n",
    " incoming_edges_q2.shape[0] + incoming_edges_q1.shape[0]) == sorted_incoming_edges.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at what there are some notable things in the devised groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.806753237571144, 1.8176236993742856, 18.61205215372741)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incoming_edges_q1['in edges'].mean(), incoming_edges_q2['in edges'].mean(), incoming_edges_q3['in edges'].mean(), incoming_edges_q4['in edges'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.8300142582751024, 2.36138835534921, 3.578950779491651, 11.466202004371675)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incoming_edges_q1['out edges'].mean(), incoming_edges_q2['out edges'].mean(), incoming_edges_q3['out edges'].mean(), incoming_edges_q4['out edges'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.9767507629944734, 3.667994296689959, 2.489977964483933, 11.101838813638212)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outgoing_edges_q1['in edges'].mean(), outgoing_edges_q2['in edges'].mean(), outgoing_edges_q3['in edges'].mean(), outgoing_edges_q4['in edges'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.8123446024769334, 2.209997289749361, 18.214094232570744)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outgoing_edges_q1['out edges'].mean(), outgoing_edges_q2['out edges'].mean(), outgoing_edges_q3['out edges'].mean(), outgoing_edges_q4['out edges'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 235.2441141848146)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incoming_edges_bottom_1['in edges'].mean(), incoming_edges_top_1['in edges'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.4613345117101195, 63.97998822836963)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incoming_edges_bottom_1['out edges'].mean(), incoming_edges_top_1['out edges'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.8858447488584473, 112.43952324896998)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outgoing_edges_bottom_1['in edges'].mean(), outgoing_edges_top_1['in edges'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 160.2302825191289)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outgoing_edges_bottom_1['out edges'].mean(), outgoing_edges_top_1['out edges'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <i>Mean incoming and outgoing edges total network: $5.3$</i> \n",
    "#### <i>Sorted on number of incoming edges</i>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Group</th>\n",
    "        <th>Mean #Incoming Edges</th>\n",
    "        <th>Mean #Outgoing Edges</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><i>Bottom 1%</i></td>\n",
    "        <td>$0.00$</td>\n",
    "        <td>$4.46$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Q1 <i>(Bottom 25%)</i></td>\n",
    "        <td>$0.00$</td>\n",
    "        <td>$3.83$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Q2</td>\n",
    "        <td>$0.81$</td>\n",
    "        <td>$2.36$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Q3</td>\n",
    "        <td>$1.82$</td>\n",
    "        <td>$3.58$</td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>Q4 <i>(Top 25%)</i></td>\n",
    "        <td>$18.6$</td>\n",
    "        <td>$11.5$</td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td><i>Top 1%</i></td>\n",
    "        <td>$235$</td>\n",
    "        <td>$64.0$</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "#### <i>Sorted on number of outgoing edges</i>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Group</th>\n",
    "        <th>Mean #Incoming Edges</th>\n",
    "        <th>Mean #Outgoing Edges</th>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td><i>Bottom 1%</i></td>\n",
    "        <td>$2.89$</td>\n",
    "        <td>$0.00$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Q1 <i>(Bottom 25%)</i></td>\n",
    "        <td>$3.97$</td>\n",
    "        <td>$0.00$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Q2</td>\n",
    "        <td>$3.67$</td>\n",
    "        <td>$0.81$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Q3</td>\n",
    "        <td>$2.49$</td>\n",
    "        <td>$2.21$</td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>Q4 <i>(Top 25%)</i></td>\n",
    "        <td>$11.1$</td>\n",
    "        <td>$18.2$</td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td><i>Top 1%</i></td>\n",
    "        <td>$112$</td>\n",
    "        <td>$160$</td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two noteworthy things in this graph. The nodes with a relatively high number of outgoing edges (i.e. the top $25\\%$ or even the top $1\\%$) also have a relatively high number of incoming edges when compared to the rest of the network. It thus seems that pages that have a lot of links to other pages also seem to be relatively high linked (i.e. have incoming edges) pages themselves  Note that there is a relatively large group (i.e. pages). The same can be seen in the top groups of when grouped/sorted by number of incoming edges. These groups do not only have a relatively higher number of incoming edges (on average) than the rest of the network, but also a relatively higher frequency of   in the network that do not have incoming edges, but have a relatively high number of outgoing edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.691253735784134 %\n",
      "29.83103724074137 %\n"
     ]
    }
   ],
   "source": [
    "print(str((wiki_df.loc[wiki_df[\"out edges\"] == 0.00].shape[0] / wiki_df[\"out edges\"].shape[0]) * 100), \"%\")\n",
    "print(str((wiki_df.loc[wiki_df[\"in edges\"] == 0.00].shape[0] / wiki_df[\"in edges\"].shape[0]) * 100), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, one can see that part of the skewness of the degree distribution (see bottom groups) is due to pages that have either no incoming or outgoing edges. Having no incoming edges can be explained by pages that are the \"entry-page\" to this network of pages (i.e. referred to by somebody googling it / typing it in their address bar) while having no outgoing edges can be explained by pages that simply have no links on them (i.e. pages showing files etc.). These possible explanations are, however, just assumptions / guesses. There is no metadata about the pages available, so we can actually not confirm these hypotheses by more in-depth evaluations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"darkgreen\">2. Static Network Analysis:</font> Diameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next meausure which is going to be calculated and evaluated in the context of static network analysis is a grpah distance measure: the diameter. It encapsulates the maximum found eccentricity of any node in the network. Or in other words the longest of all the shortest paths between the vertices in the network. This may sound a bit confusing, but imagine that we have a set of all the shortest paths between each pair of vertices in the network. The maximum found value in this set is the diameter of the network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>A</b> --- <b>B</b> --- <b>C</b>&emsp;&emsp;&emsp; <i>Diameter:</i> $4$ (A-I and G-C) <br> \n",
    "|&emsp;&emsp;|&emsp;&emsp;| <br>\n",
    "<b>D</b> --- <b>E</b> --- <b>F</b> <br>\n",
    "|&emsp;&emsp;|&emsp;&emsp;| <br>\n",
    "<b>G</b> --- <b>H</b> --- <b>I</b> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>A</b> --- <b>B</b> --- <b>C</b>&emsp;&emsp;&emsp; <i>Diameter:</i> $5$  (A-J) <br> \n",
    "|&emsp;&emsp;|&emsp;&emsp;| <br>\n",
    "<b>D</b> --- <b>E</b> --- <b>F</b> <br>\n",
    "|&emsp;&emsp;|&emsp;&emsp;| <br>\n",
    "<b>G</b> --- <b>H</b> --- <b>I</b> --- <b>J</b> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This toyish example should give you a clear overview of what is measured by the distance measure that is diameter. Note, however, that this example is considering undirected edges, while we are of course interested in this measure of a directed graph of links. We will translate the measure back to our problem and network context in a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a directed graph (i.e. network) that is not strongly connected since there are nodes $u$ which have no path to certain nodes $v$, we cannot simply use the diameter function of $networkx$ to calculate the diameter of the graph. The reason for this is a that if a shortest path from $u$ to $v$ is non-existent in the graph, it will be $\\infty$ (think about Dijkstra's shortest path algorithm). And since the diameter function of $networkx$ simply calcultes the eccentricity of the Graph and returns the max value found in this collection, it will not work since the eccentricity function and thus the diameter function will raise an error because the graph is not strongly connected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.is_strongly_connected(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with the built in $networkx$ function for calculating the diameter of a graphh is that the function relies on the eccentricity function. Eccentricity finds the shortest path from a node $u$ to all the other nodes and does this this for all the graphs in the network. The diameter function then calls this function on the graph and takes the max (i.e. longest shortest path) over the returned collection of all the shortest paths by eccentricity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "847138"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strong_comp = G_i.clusters(mode = 'STRONG')\n",
    "strong_comp_items = list(strong_comp)\n",
    "len(strong_comp_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of self loops and mutual connections as we wil see in the next section. This results in strong components of one or two elements, which are not very useful in this stage. We can excude the components of length $\\leq 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strong_comp_items_substantial = [component for component in strong_comp_items if len(component) > 2]\n",
    "len(strong_comp_items_substantial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results in 209 strong components in the graph. Let's see what the largest strong component is in the graph and try to obtain the diameter of this strong component, for the largest diameter value among the strong components. We can start by excluding more strong components since there are only a few large components in the current collection (i.e. still a lot of relatively small components that will probably not yield the largest diameter of all the strong components of the graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strong_comp_items_substantial = [component for component in strong_comp_items_substantial if len(component) > 100]\n",
    "len(strong_comp_items_substantial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is better. Let's asses what the size of this large strong component is (i.e. a subgraph where each vertex is connected to each other vertex in the graph)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188879"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "component = strong_comp_items_substantial[0]\n",
    "len(component)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So even if we would try to reduce the original graph to a strong connected graph (e.g. the largest stongh graph in the network, it would still be infeasible to calculate it for a strongly connected subgraph by simply exploiting (non-heurisitc) algorithms found in network/graph libraries written in Python/C++ without exploiting more advanced computing mehtodologies (e.g. parallel computing etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementations of the libraries of networkx and igraph need a strong graph as input. The graph was, obviously, not strongly connected. This would not make sense of course for a network representing a network of pages of over 600.000 nodes. Having a strongly connected graph would implicate that there was a link from every page to every other page in the network. Something that you will never encounter in such a network of this magnitude which represents such a domain network.\n",
    "\n",
    "When considering the common definition of the diameter of a (directed) graph one often finds something in the sense of:\n",
    "\n",
    "<i>\"As another means of measuring network graphs, we can define the diameter of a network as the longest of all the calculated shortest paths in a network. It is the shortest distance between the two most distant nodes in the network. In other words, once the shortest path length from every node to all other nodes is calculated, the diameter is the longest of all the calculated path lengths. The diameter is representative of the linear size of a network.\"</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the diameter that has been calculated right now is not really in line with what should be encapsulated by the diameter value. We are interested in the longest shortest path in the graph. Or in other words the shortest path between the two most distant node in the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An exhaustive search for this value is not considered possbile with our resources and time-schedule. Such an algorithm should iterate over $6.7 * 10^5$ nodes, find all of their successors by either exploiting bread-first search or depth-first search based algorithms/variations and calculate the shortest path between each node and its succesors. Just to give you an impression of the computational workload of such a task: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77526"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict(nx.bfs_successors(G, '7')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By having nodes with such large number of successors, it is considered infeasible to calculate this by simple algorithms of Python libraries without exploiting more advanced computing methods. Several variations of algorithms of the networkx, igraph libraries and even the graph-tool library (more efficient since the core data-structures and algorithms are implemented in C++) have been tested for computational feasbility of this task. We even tried to change the source-code to implement implementations that we have devised ourselves for this network. These optimizations were based on the following observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372221"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df.loc[((wiki_df['out edges'] == 0) | (wiki_df['out edges'] == 1))].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The thing worht nothing is the large quantity of nodes with only one outgoing edge or no outgoing edge. This fact can be exploited by skipping nodes with an out_degree of 0 and remembering nodes of degree 1 that were visited in previous iterations over the successors of previous nodes that were considered. These nodes can be skipped in the subsequent checks since considering their successors will never yield the true diameter of the graph. The reason for this is that if this node is a successor of another node, the longest shortest path found for this node among its successors will always be $\\geq$ than the longest shortest path that will be found by exploring the shortest path to the successors of the node of degree $1$ since if we assume that this path would be a longer shortest path, a longest path found by going through that node of out-degree 1 will be at least as long. This observation was exploited in one of the optimizations below. Other optimizations that were exploited invovled implementing/changing the  bread-first search of networkx to prune paths that do not lead to a longer shortest path. We, however, want to limit the amount of code somewhat in this analysis, so the code of only the first optimization is devised below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First note that since the function $nx.shortest\\_path\\_length$ relies on an implementation of Dijkstra's algorithm, the choice is made to remove the selfloop-edges since this (can) corrupt the results and the running time of the algorithm depending on the pecularities of the implementation of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_loop_edges = list(nx.selfloop_edges(G))\n",
    "edges_no_loop = list(set(G.edges()).difference(set(self_loop_edges)))\n",
    "G_no_loop = G.edge_subgraph(edges_no_loop)\n",
    "len(self_loop_edges) + len(edges_no_loop)== len(G.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "already_visited_node = set() # global tracker of nodes of out-degree one that are already visited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the longest shortest path in the network beginning from source node $u$ by iterating over the successors. And facilitating the optimization in another function by storing nodes of out-degree 1 that were already visited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def longest_shortest_path(G_in, u):\n",
    "    global already_visited_node\n",
    "    longest = tracker = 0\n",
    "    reachable = set(nx.dfs_successors(G_in, source = u))\n",
    "    reachable = list(reachable - set(u))\n",
    "    for v in reachable: # depth-first-search of successors\n",
    "        #print(\"successor: \", tracker); tracker += 1\n",
    "        if ((u != v)):\n",
    "            if (G.out_degree(v) == 1):\n",
    "                already_visited_node.add(v)\n",
    "            path_length = nx.shortest_path_length(G_in, source = u, target = v)\n",
    "            if (path_length > longest):\n",
    "                longest = path_length\n",
    "    return longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_diameter(G_in):\n",
    "    global already_visited_node\n",
    "    longest = tracker = 0\n",
    "    nodes = list(G_in)\n",
    "    for node in nodes:\n",
    "        # print(\"node: \", tracker); tracker += 1\n",
    "        if ((G_in.out_degree(node) != 0) and (node not in already_visited_node)):\n",
    "            longest_shortest = longest_shortest_path(G_in, node)\n",
    "            if (longest_shortest > longest):\n",
    "                longest = longest_shortest\n",
    "    return longest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function could be optimized even more by implementing breadth-first-search ourselves and comparing the shortest path-lengths along the way, but thay may be a bit far fetched for this analysis. \n",
    "\n",
    "Assuming having a (network) of computers capable of calculating the diameter of this graph in a reasonable time one can use a function call $diameter\\,=\\,longest\\_shortest\\_path(G)$ to do so. \n",
    "\n",
    "This calculation will take, however, a very long time and we will, therefore, refrain ourselves from these (type of) measures in the rest of the analysis since we have covered more than enough other measures (even though we only had to cover eight measures). Benchmarking this function for a smaller (sub)graph agains the standard diameter functions of networkx, igraph and graph-tool or a similar self-written implementation without the optimization shows indeed that there is a significant improvement in the computation time by these optimizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function can be used to actually fill the $wiki\\_df$ DataFrame with relevant distance measures such as the longest shortest path found amoung the successors of a certain node (i.e. row in the table), the number of successors and the mean shortest path among the sucessors of a certain node. The longest shortest path or the mean shortest path of the graph can then be obtained by simply querying the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracker = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nr_successors_and_diameter_and_mean(node):\n",
    "    node = str(node)\n",
    "    global tracker # track progress\n",
    "    total = mean = longest = nr_paths = 0 \n",
    "    successors = set(nx.dfs_successors(G, node))\n",
    "    successors = list(successors - (set(node)))\n",
    "    \n",
    "    for v in successors:\n",
    "        print(\"node: \", tracker)\n",
    "        tracker += 1\n",
    "        path_length = nx.shortest_path_length(G, source = node, target = v)\n",
    "        nr_paths += 1\n",
    "        total += path_length\n",
    "        if (path_length > longest):\n",
    "            longest = path_length\n",
    "    if (nr_paths != 0):\n",
    "        mean = int(total / nr_paths)\n",
    "    return longest, mean, len(successors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# wiki_df['longest_sp'], wiki_df['mean_sp'], wiki_df['nr_successors'] = zip(*wiki_df['node'].map(nr_successors_and_diameter_and_mean)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we are not able to do the compuations over all the nodes, we can get a rough estimate of the magnitude (i.e. at least a minimum) of the diameter of the graph by doing the longest shortest-path computations of a set of nodes. Let's see what the results are for nodes with a relatively high out-degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "      <th>decile_incoming_edges</th>\n",
       "      <th>decile_outgoing_edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>678897</th>\n",
       "      <td>970034</td>\n",
       "      <td>0</td>\n",
       "      <td>2280</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678898</th>\n",
       "      <td>16115</td>\n",
       "      <td>4</td>\n",
       "      <td>2336</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678899</th>\n",
       "      <td>598952</td>\n",
       "      <td>0</td>\n",
       "      <td>2351</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678900</th>\n",
       "      <td>707633</td>\n",
       "      <td>0</td>\n",
       "      <td>2386</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678901</th>\n",
       "      <td>9273</td>\n",
       "      <td>0</td>\n",
       "      <td>2579</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678902</th>\n",
       "      <td>707642</td>\n",
       "      <td>0</td>\n",
       "      <td>2620</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678903</th>\n",
       "      <td>377365</td>\n",
       "      <td>0</td>\n",
       "      <td>3173</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678904</th>\n",
       "      <td>9258</td>\n",
       "      <td>37</td>\n",
       "      <td>3694</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678905</th>\n",
       "      <td>154856</td>\n",
       "      <td>8</td>\n",
       "      <td>3951</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678906</th>\n",
       "      <td>306188</td>\n",
       "      <td>0</td>\n",
       "      <td>4302</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          node  in edges  out edges  decile_incoming_edges  \\\n",
       "678897  970034         0       2280                      0   \n",
       "678898   16115         4       2336                      0   \n",
       "678899  598952         0       2351                      0   \n",
       "678900  707633         0       2386                      0   \n",
       "678901    9273         0       2579                      0   \n",
       "678902  707642         0       2620                      0   \n",
       "678903  377365         0       3173                      0   \n",
       "678904    9258        37       3694                      0   \n",
       "678905  154856         8       3951                      0   \n",
       "678906  306188         0       4302                      0   \n",
       "\n",
       "        decile_outgoing_edges  \n",
       "678897                      5  \n",
       "678898                      5  \n",
       "678899                      5  \n",
       "678900                      5  \n",
       "678901                      5  \n",
       "678902                      6  \n",
       "678903                      7  \n",
       "678904                      8  \n",
       "678905                      9  \n",
       "678906                      9  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_outgoing_links = outgoing_edges_top_1.iloc[-10:]\n",
    "top10_outgoing_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node:  970034 with longest shortest path of  18  among its large number of successors\n",
      "node:  16115 with longest shortest path of  18  among its large number of successors\n",
      "node:  598952 with longest shortest path of  17  among its large number of successors\n",
      "node:  707633 with longest shortest path of  18  among its large number of successors\n",
      "node:  9273 with longest shortest path of  18  among its large number of successors\n",
      "node:  707642 with longest shortest path of  18  among its large number of successors\n"
     ]
    }
   ],
   "source": [
    "for node in list(top10_outgoing_links.node):\n",
    "    longest_shortest_path_found = longest_shortest_path(G, node)\n",
    "    print(\"node: \", node, \"with longest shortest path of \", longest_shortest_path_found, \" among its large number of successors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(longest_shortest_path(G, '394')) # longest shortest path of a few random nodes as source\n",
    "print(longest_shortest_path(G, '300'))\n",
    "print(longest_shortest_path(G, '7'))\n",
    "print(longest_shortest_path(G, '42'))\n",
    "print(longest_shortest_path(G, '9643'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This (evaluation of the nodes with the largest out-degree) should give us a good insight on the longest shortest path found in the graph, even though it can be of course that the actual longest shortest path of the graph is found by exploring the successors of other nodes with a lower number of outgoing edges on the first 'level'. There is, however, a high probability that these maximum of these values is the actual longest shortest path found in the graph and thus the actual diameter of the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this network propert is an intensively researched field in the world of network science. Searching content in the world-wide-web is related to the diameter of this network. One can grasp this content by imagining it as the number of clicks one would have to make through all the links or the amount of links a search-bot has to explore. The diameter of the network cannot simply be computed by an exhaustive brute-force search of such large networks ss explained in the paper <a href=\"http://people.math.sc.edu/lu/papers/pdiam.pdf\">The Diameter of Random Massive Graphs, Linyuan Lu, Oct 2000\"</a>, many massive graphs (i.e. networks) share certain universal characteristics which can be used to describe these networks in term of so-called power-laws. The actual implications of the found values in this network shed light on how many 'clicks' a potential visitor can though at maximum when visitin a certain topic. It can, for example, shed light on the number of clicks that can be done by exploring the links that go from one (sub-)topic to another (sub-)topic, by following the minimum path possible in the network, and without revisiting the same node twice. This is just a thought and has to be supported by further analysis with page meta-data if one actually would like to evaluate such a hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"darkgreen\">3. Static Network Analysis:</font> Dyads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might be an uncommon measure in this course, but it can have quite interesting implications for the network in context. We wanted to go beyond the suggested measures and have, therefore, done some reading on networks science ourselves. One of the papers we came accross was an elaboration on Dyads and Triads found in Directed Graphs. It boils down to classifying each pair of nodes $u$ and $v$ in the network (i.e. a directed graph in our context) into three categories, which are:\n",
    "\n",
    "1. <b>Mutual:</b> There is an edge from $u$ to $v$ and also an edge frome $v$ to $u$\n",
    "2. <b>Asymmetric:</b> There is either an edge from $u$ to $v$ or an edge from $v$ to $u$\n",
    "3. <b>Null:</b> There is no edge from $u$ to $v$ and also no edge frome $v$ to $u$\n",
    "\n",
    "The actual implications for our network should be quite evident. We can measure how many pages have a symmetric link between each other, how many pages have a one way link to each other and how many pages have no link between each other. We are going to  elaborate on this further on after some calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph_dyad_census = G_i.dyad_census()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(graph_dyad_census.as_dict().items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, however, that this includes nodes with self-loops and parallel edges as explained before that deterioriate any observations that can be made about the measures, so before we actually place it in the problem context, let's remove those edges and recalcuate the measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_i = G_i.simplify(multiple = True, loops = True, combine_edges = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph_dyad_census = G_i.dyad_census()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(graph_dyad_census.as_dict().items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To put this in better perspective it makes sense to look at the percentages of the total $u \\times v$ pairs which are possible in the network. And even more common is to look at this number compared to the total number of edges, as we will also see in the evalauation of another metric in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count = sum(list(graph_dyad_census))\n",
    "number_edges = len(G_i.es)\n",
    "\n",
    "for metric in sorted(graph_dyad_census.as_dict().items())[:2]:\n",
    "    if(metric[0] == 'mutual'): # only one of the edges is counted for mutual connnections\n",
    "        print(\"percentage of total possible combinations for \", metric[0], \" edges, is: \", round(((metric[1] * 2 / total_count) * 100), 4), \"%\")\n",
    "        print(\"percentage of total number of edges for \", metric[0], \" edges, is: \", round(((metric[1] * 2/ number_edges) * 100), 4), \"%\\n\")\n",
    "    else :\n",
    "        print(\"percentage of total possible combinations for \", metric[0], \" edges, is: \", round(((metric[1] / total_count) * 100), 4), \"%\")\n",
    "        print(\"percentage of total number of edges for \", metric[0], \" edges, is: \", round(((metric[1] / number_edges) * 100), 4), \"%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are thus 1) a lot of pages which do not have an (asymmetric) link to each other, and the number of pages that link to each other (i.e. mutual) are even less common. This actually does make sense when one considers the context of a network of a website/domain. One would not expect that every page has a link to every other page in the network, especially considering the size of this particular network. In addition, having mutual edges on a website depends entirely on the type of webpages one is considering. For some webpages it makes sense considering the navigation of the website. Or consider pages on WikiPedia which refer to a sub-topic of certain topic. This sub-topic is likely to have also a link back to the main topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider, for example, the WikiPedia page on Network Science. Several links to sub-topics and/or related topics have a link on the page back to the page of Network Science. This is not only due to reference links in the text (i.e. information) on that page, but also due to the navigation lay-out of wikipedia which enhances this type of navigation by suggesting similar / related topics and classifiying (sub-)topics into groups (see the Wiki page on Complex Networks for example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One could thus consider the measure to be an indicator of how related certain pages are if one considers this context. This can be interesting to evaulate over time (i.e task 2). We can test this hypothesis of the relation between mutual edges and relations between (sub)-topics by analyzing both the relative and absolute changes of these measures. Note, however, that we cannot confirm these hypotheses by the lack of context (i.e. metadata about the pages). But first, we can go into a little more depth about the implications of these measures and also consider another, related, measure in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment, nodes with no incoming edges are included. The same goes for pages with no outgoing links. The question is, however, if we want to include these pages in our results. If we place the network in question again in the context of its origin one would assume that these pages can be considered as 'entry'-pages to the domain of the network while the nodes with no outgoing links can be pages with only links to pages outside of the domain. Wikipedia has, for example, a lot of pages with media (i.e. pictures) that only have a link to the source of the content (i.e. links to twitter, wikimediafoundation, google images etc.). These pages are not really interesting to for the assessment of the mutuality hypotheses. Let's re-asses the values once more after the removal of these nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_delete_ids = [v.index for v in G_i.vs if ((v.indegree() == 0) | (v.outdegree == 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_i.delete_vertices(to_delete_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dyad_census = G_i.dyad_census()\n",
    "print(sorted(graph_dyad_census.as_dict().items())[:3])\n",
    "total_count = sum(list(graph_dyad_census))\n",
    "number_edges = len(G_i.es)\n",
    "\n",
    "for metric in sorted(graph_dyad_census.as_dict().items())[:2]:\n",
    "    if(metric[0] == 'mutual'): # only one of the edges is counted for mutual connnections\n",
    "        print(\"percentage of total possible combinations for \", metric[0], \" edges, is: \", round(((metric[1] * 2 / total_count) * 100), 4), \"%\")\n",
    "        print(\"percentage of total number of edges for \", metric[0], \" edges, is: \", round(((metric[1] * 2/ number_edges) * 100), 4), \"%\\n\")\n",
    "    else :\n",
    "        print(\"percentage of total possible combinations for \", metric[0], \" edges, is: \", round(((metric[1] / total_count) * 100), 4), \"%\")\n",
    "        print(\"percentage of total number of edges for \", metric[0], \" edges, is: \", round(((metric[1] / number_edges) * 100), 4), \"%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which gives a better representation of the measures in our particular network. In conclusion, we can consider the 'dyad classification' as a representation of the cohesion of the network (i.e. how strong is the tendency to have a returning link on when visiting a succesive node in the network)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"darkgreen\">4. Static Network Analysis:</font> Reciprocity and Transitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, dyad measures were introduced and we had a look at the percentage of the mutual  and asymmetric edges in the graph compared to the total number of possible combinations in the graph (i.e. $(n-1)^2$ where $n$ is the number of vertices (no self-loops)) and compared to the number of edges in the graph. This last measure is often refered to as the dyad-based reciprocity of the network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
