{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PageRank Stability and Community Structure on Graphs\n",
    "### <i>Abdel K. Bokharouss, Bart van Helvert, Joris Rombouts, Remco Surtel - January 2018</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: PageRank Stability on Evolving Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and general set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(98)\n",
    "random.seed(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def display_df_sbs(*args):\n",
    "    html_str=''\n",
    "    for df in args:\n",
    "        html_str+=df.to_html()\n",
    "    display_html(html_str.replace('table','table style=\"display:inline\"'),raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load edge list and create a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fh = open(\"canvas/hamster.edgelist\", 'rb')\n",
    "G = nx.read_edgelist(fh, create_using=nx.DiGraph())\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we run the pagerank algorithm with a dampening parameter of 0.85. The dampening parameter represents the likelyhood of clicking a link on the webpage. With a dampening parameter of 0.85 we indicate that there is a 85% of clicking a link on the webpage and 15% of going to a random other node in the graph. We calculate the page rank using the power iteration method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pr = nx.pagerank(G, alpha=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rank</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>404</td>\n",
       "      <td>0.042793</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195</td>\n",
       "      <td>0.019961</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>0.018628</td>\n",
       "      <td>121</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>728</td>\n",
       "      <td>0.015530</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36</td>\n",
       "      <td>0.011117</td>\n",
       "      <td>168</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>135</td>\n",
       "      <td>0.009544</td>\n",
       "      <td>49</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>192</td>\n",
       "      <td>0.009365</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>281</td>\n",
       "      <td>0.009304</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>136</td>\n",
       "      <td>0.008853</td>\n",
       "      <td>85</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>184</td>\n",
       "      <td>0.008296</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rank</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>469</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>26</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>1406</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>610</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>972</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>129</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>834</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>1266</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>27</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>480</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>1335</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rank</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>708</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>896</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>270</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>799</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>811</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>56</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>290</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>142</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>944</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>695</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rank</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>1597</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>1908</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>1442</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>1702</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>1048</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>1259</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>2172</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>1771</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>2035</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>2131</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rank</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>2327</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>2091</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>2329</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>2330</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>2335</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>2309</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>1359</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>2006</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>1501</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>1148</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rank</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2417</th>\n",
       "      <td>1739</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418</th>\n",
       "      <td>918</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419</th>\n",
       "      <td>1743</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2420</th>\n",
       "      <td>1744</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2421</th>\n",
       "      <td>1745</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2422</th>\n",
       "      <td>1746</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2423</th>\n",
       "      <td>1748</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2424</th>\n",
       "      <td>1749</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2425</th>\n",
       "      <td>1751</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2426</th>\n",
       "      <td>2426</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_edge_in = pd.DataFrame(list(G.in_degree), columns=['node', 'in edges'])\n",
    "df_edge_out = pd.DataFrame(list(G.out_degree), columns=['node', 'out edges'])\n",
    "df_rank = pd.DataFrame(list(pr.items()), columns=['node', 'score']).sort_values(by=['score'], ascending=False)\n",
    "df_temp = pd.merge(df_rank, df_edge_in, on='node')\n",
    "df_total = pd.merge(df_temp, df_edge_out, on='node')\n",
    "df_total.index = df_total.index + 1\n",
    "df_total.columns.name = 'rank'\n",
    "\n",
    "display_df_sbs(df_total.head(10), df_total.iloc[500 : 510], df_total.iloc[1000 : 1010], \n",
    "                        df_total.iloc[1500 : 1510], df_total.iloc[2000 : 2010], df_total.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the higher ranked pages have more incoming edges than the lower ranked pages on average. It is important to note that a page being linked by a lot of other pages doesn't imply that it will rank high on the pagerank. The rank of a page is mainly influenced by the quality links directed to the page. A page which is linked on many other pages however is still far more likely to end up higher in the pagerank than a page which is linked less frequently. This is also shown in the data from the pagerank calculation above. The lower the pagerank the fewer incoming edges those pages have. There are however some exceptions in the data. One of them is the number 1 ranked page. The rank of that page far exceeds the other pages having a score of 0.042793 = 4.3% while the second best ranked page only has a score of 0.019961 = 2.0%. We will analyze this page by looking at the quality of the pages that link to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_df(node):\n",
    "    df_pred = pd.DataFrame(list(G.predecessors(node)), columns=['node'])\n",
    "    scores = {}\n",
    "    out_edges = {}\n",
    "    for n in G.predecessors(node):\n",
    "        out_edges[n] = len(G.out_edges(n))\n",
    "        scores[n] = pr.get(n)\n",
    "    df_out_edges = pd.DataFrame(list(out_edges.items()), columns=['node', 'out edges'])     \n",
    "    df_score = pd.DataFrame(list(scores.items()), columns=['node', 'score']).sort_values(by=['score'], ascending=False)\n",
    "    df_temp = pd.merge(df_score, df_pred, on='node')\n",
    "    df_total = pd.merge(df_temp, df_out_edges, on='node')\n",
    "    df_total.index = df_total.index + 1\n",
    "    df_total.columns.name = node\n",
    "    return df_total\n",
    "\n",
    "def gen_sum_inc(node):\n",
    "    summation = 0\n",
    "    for n in G.predecessors(node):\n",
    "        summation += pr.get(n)\n",
    "    return summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>404</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>195</td>\n",
       "      <td>0.019961</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77</td>\n",
       "      <td>0.018628</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192</td>\n",
       "      <td>0.009365</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126</td>\n",
       "      <td>0.008144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>346</td>\n",
       "      <td>0.005487</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>403</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24</td>\n",
       "      <td>0.003894</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>246</td>\n",
       "      <td>0.002964</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>882</td>\n",
       "      <td>0.002327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>775</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>195</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77</td>\n",
       "      <td>0.018628</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>0.011117</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192</td>\n",
       "      <td>0.009365</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>181</td>\n",
       "      <td>0.005597</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>346</td>\n",
       "      <td>0.005487</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>182</td>\n",
       "      <td>0.004905</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>116</td>\n",
       "      <td>0.004715</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>125</td>\n",
       "      <td>0.003839</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>115</td>\n",
       "      <td>0.003329</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>101</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>195</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2019</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>618</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2195</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>684</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2135</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2097</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2018</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>855</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>911</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2352</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summation incoming node score for node 404: 0.07603158841472238\n",
      "Summation incoming node score for node 195: 0.1244965540211601\n"
     ]
    }
   ],
   "source": [
    "display_df_sbs(gen_df('404'), pd.DataFrame(), gen_df('195').head(10), gen_df('195').tail(10))\n",
    "print(\"Summation incoming node score for node 404: {sum}\".format(sum=gen_sum_inc('404')))\n",
    "print(\"Summation incoming node score for node 195: {sum}\".format(sum=gen_sum_inc('195')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data clearly shows that there are a lot more links to 195 than 404. Also does the data show that the sum of the score of all the pages that link to 195 is almost twice as high as the sum of the score of all pages that link to 404. Even though this is the case the score of 404 is way higher than the score of 195. The reason for this is that the pages that link to 195 also link to a lot of other pages while this is not the case for 404. The amount of outgoing edges for the pages that link to 404 is lower than for 195. Also do links from low scoring pages not affect the score of a page by a lot. Most of the score that both pages 404 and 195 get is from a few pages with high scores and low amount of links."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We now compare node 404 and 728. They look very similar in terms of both links to and from the page. Both have 10 links going to that particular page and both pages contain no links. Except for them looking the same in terms of connected edges, the score of node 404 is a lot higher than the score of 728. The only explanation for this is that the quality of the incoming edges of 404 must be better than the quality of the incoming edges of 728. We confirm this by looking at the nodes with edges directed to both pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>404</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>195</td>\n",
       "      <td>0.019961</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77</td>\n",
       "      <td>0.018628</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192</td>\n",
       "      <td>0.009365</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126</td>\n",
       "      <td>0.008144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>346</td>\n",
       "      <td>0.005487</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>403</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24</td>\n",
       "      <td>0.003894</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>246</td>\n",
       "      <td>0.002964</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>882</td>\n",
       "      <td>0.002327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>775</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>728</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>697</td>\n",
       "      <td>0.007044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>724</td>\n",
       "      <td>0.004799</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>222</td>\n",
       "      <td>0.003467</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>727</td>\n",
       "      <td>0.003348</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>726</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>170</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>221</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>725</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>723</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>220</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summation incoming node score for node 404: 0.07603158841472238\n",
      "Summation incoming node score for node 195: 0.030253764353088613\n"
     ]
    }
   ],
   "source": [
    "display_df_sbs(gen_df('404'), pd.DataFrame(), gen_df('728'))\n",
    "print(\"Summation incoming node score for node 404: {sum}\".format(sum=gen_sum_inc('404')))\n",
    "print(\"Summation incoming node score for node 195: {sum}\".format(sum=gen_sum_inc('728')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the summation of the incoming node score we see that 404 scores better. However in the comparison between 404 and 195 it was already shown that this doesn't necessarily imply that 404 will score better than 195. If we take a look at the number of outgoing edges of the incoming nodes we see that 728 has slightly more in total. This also doesn't necessarily mean that the score of 728 should be lower than 404. The impact of an high amount of outgoing edges a node that has an high score is way more influential than when a node with a low score has an high amount of outgoing edges. The total score and amount of summations are a good indicator but not always right. In this case however it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph evolution and PageRank values comparison\n",
    "### Joris & Abdel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load edge list and create a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fh = open(\"canvas/hamster.edgelist\", 'rb')\n",
    "G = nx.read_edgelist(fh, create_using=nx.DiGraph())\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_pagerank(G_in, alpha = 0.85):\n",
    "    return nx.pagerank(G_in, alpha=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pr_origin = calc_pagerank(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_dataframe(pr, G_in):\n",
    "    df_edge_in = pd.DataFrame(list(G_in.in_degree()), columns=['node', 'in edges'])\n",
    "    df_edge_out = pd.DataFrame(list(G_in.out_degree()), columns=['node', 'out edges'])\n",
    "    df_rank = pd.DataFrame(list(pr.items()), columns=['node', 'score']).sort_values(by=['score'], ascending=False)\n",
    "    df_temp = pd.merge(df_rank, df_edge_in, on='node')\n",
    "    df_total = pd.merge(df_temp, df_edge_out, on='node')\n",
    "    df_total.index = df_total.index + 1\n",
    "    df_total.columns.name = 'rank'\n",
    "    return df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rank</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>404</td>\n",
       "      <td>0.042793</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195</td>\n",
       "      <td>0.019961</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>0.018628</td>\n",
       "      <td>121</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>728</td>\n",
       "      <td>0.015530</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36</td>\n",
       "      <td>0.011117</td>\n",
       "      <td>168</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>135</td>\n",
       "      <td>0.009544</td>\n",
       "      <td>49</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>192</td>\n",
       "      <td>0.009365</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>281</td>\n",
       "      <td>0.009304</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>136</td>\n",
       "      <td>0.008853</td>\n",
       "      <td>85</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>184</td>\n",
       "      <td>0.008296</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rank node     score  in edges  out edges\n",
       "1     404  0.042793        10          0\n",
       "2     195  0.019961        80          1\n",
       "3      77  0.018628       121          2\n",
       "4     728  0.015530        10          0\n",
       "5      36  0.011117       168          5\n",
       "6     135  0.009544        49          8\n",
       "7     192  0.009365        57          3\n",
       "8     281  0.009304        32          0\n",
       "9     136  0.008853        85          6\n",
       "10    184  0.008296        80          3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_origin = create_dataframe(pr_origin, G)\n",
    "df_origin.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b. Graph Evolution and Pagerank values comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section the effects of graph evolutions are going to be studied in relation to an evaluation of the stability of PageRank. In particular, various methodologies are going to be devised and exploited in which graphical represesentations of a social network are going to be altered by the removal and/or addition of nodes and edges in these graphs. The original graph $G$, represents a social network of friendships and familylinks between users of the website <a>hamsterster.com</a>. Various functions which make it possible to change this graph are going to be given and explained. Some of these functions focus on the addition or removal of edges, while other focus on nodes. Some of these functions are going to do make choices at random, while others are also going to exploit randomness, but proporotional to the node degree and other statistics. The choice is made to analyze the effects of the functions which evolve the graphs on the original graph $G$. So the evaluation of the various functions which add/remove graphs is going to be done starting from the full and original graph $G$ for each of the given functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Note: A social network would naturally be described with an undirected graph. The social network data is, however, treated as a combination of target and source id's which faciliate the usage of this data as a directed graph for the sake of implementing and testing graph evolutions methods to evaluate the stability of PageRank. No implications or conclusions should be directly related to the actual structure of the social networks of the website</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Removing and adding edges uniformly at random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $n$ number of nodes do the following:\n",
    "* select 1 node uniformly at random\n",
    "* add or remove an incoming/outgoing at random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add/remove edges for all the nodes uniformly at random\n",
    "def random_edges_uniform_random(G_in, number_of_nodes = 1, choice_given = False, choice = False):\n",
    "    nr_of_edges_added = 0\n",
    "    nr_of_edges_removed = 0\n",
    "    \n",
    "    list_of_nodes = list(G_in) # all the nodes\n",
    "    # select uniformly at random nodes of which we are going to add/remove edges\n",
    "    selected_nodes = list(np.random.choice(list_of_nodes, size = number_of_nodes, replace = False)) # default probability p is an uniform distribution\n",
    "    \n",
    "    for node in selected_nodes: \n",
    "        successors = list(G_in.successors(str(node))) # find the successors of this nodes\n",
    "        predecessors = list(G_in.predecessors(str(node))) # find the predecessors of this node\n",
    "        #find candidates for new edges\n",
    "        unconnected_to = [n for n in list(G_in.nodes()) if not n in successors] # no outgoing edge to these nodes\n",
    "        unconnected_from = [n for n in list(G_in.nodes()) if not n in predecessors] # no incoming edge from these nodes\n",
    "        \n",
    "        if (choice_given):\n",
    "            add = choice\n",
    "        else:\n",
    "            add = bool(random.getrandbits(1)) # randomly add or remove an edge of this node\n",
    "        \n",
    "        incoming =  bool(random.getrandbits(1)) # randomly add an outgoing/incoming edge\n",
    "        if(add): # add an incoming/outgoing edge to node\n",
    "            if(incoming): # add incoming edge\n",
    "                if len(unconnected_from): #only add when unconnected_from is not empty\n",
    "                    new = random.choice(unconnected_from)\n",
    "                    G_in.add_edge(new, node)\n",
    "                    print(\"\\tnew edge:\\t {} --> {}\".format(new, node))\n",
    "                    unconnected_from.remove(new)\n",
    "                    predecessors.append(new)\n",
    "            else: # add outgoing edge:\n",
    "                if len(unconnected_to): #only add when unconnected_to is not empty\n",
    "                    new = random.choice(unconnected_to)\n",
    "                    G_in.add_edge(node, new)\n",
    "                    print(\"\\tnew edge:\\t {} --> {}\".format(node, new))\n",
    "                    unconnected_to.remove(new)    \n",
    "                    successors.append(new)\n",
    "            nr_of_edges_added += 1\n",
    "        else: # remove\n",
    "            if(incoming): # remove incoming edge\n",
    "                if len(predecessors): #only remove when predecessors is not empty\n",
    "                    new = random.choice(predecessors)\n",
    "                    G_in.remove_edge(new, node)\n",
    "                    print(\"\\tremove edge:\\t {} --> {}\".format(new, node))\n",
    "                    predecessors.remove(new)\n",
    "                    unconnected_from.append(new)\n",
    "            else: # remove outgoing edge:\n",
    "                if len(successors): #only remove when successors is not empty\n",
    "                    new = random.choice(successors)\n",
    "                    G_in.remove_edge(node, new)\n",
    "                    print(\"\\tremove edge:\\t {} --> {}\".format(node, new))\n",
    "                    successors.remove(new)    \n",
    "                    unconnected_to.append(new)\n",
    "            nr_of_edges_removed += 1\n",
    "            \n",
    "    print(\"number of edges added: \" + str(nr_of_edges_added))\n",
    "    print(\"number of edges removed \" + str(nr_of_edges_removed))\n",
    "    \n",
    "    return G_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`random_edges_uniform_random` selects one node uniformly at random, and then for that specific node it uniformly at random adds or removes one outgoing or ingoing edge, which is also determined uniformly at random. Because the choice is made to analyze the effects of the functions which evolve the graphs on the original graph $G$, we call the function `random_edges_uniform_random` parameterized with a copy of $G$ and `number_of_nodes`$ = 100$. In other words, `random_edges_uniform_random` will either add or remove either an incoming or outgoing edge for each node of `number_of_nodes`. The result graph is stored in `G_random_edges_uniform_random`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tremove edge:\t 1612 --> 817\n",
      "\tremove edge:\t 301 --> 303\n",
      "\tnew edge:\t 709 --> 1036\n",
      "\tnew edge:\t 1653 --> 2179\n",
      "\tnew edge:\t 2207 --> 1376\n",
      "\tremove edge:\t 2412 --> 2413\n",
      "\tremove edge:\t 648 --> 845\n",
      "\tnew edge:\t 889 --> 909\n",
      "\tnew edge:\t 1532 --> 2107\n",
      "\tnew edge:\t 541 --> 877\n",
      "\tremove edge:\t 2384 --> 2354\n",
      "\tremove edge:\t 2248 --> 305\n",
      "\tremove edge:\t 522 --> 523\n",
      "\tremove edge:\t 1887 --> 1889\n",
      "\tremove edge:\t 697 --> 728\n",
      "\tremove edge:\t 1801 --> 308\n",
      "\tnew edge:\t 2192 --> 1863\n",
      "\tremove edge:\t 1631 --> 1638\n",
      "\tnew edge:\t 2328 --> 1903\n",
      "\tnew edge:\t 1292 --> 1467\n",
      "\tremove edge:\t 1300 --> 249\n",
      "\tnew edge:\t 1810 --> 717\n",
      "\tnew edge:\t 728 --> 1889\n",
      "\tnew edge:\t 721 --> 1112\n",
      "\tremove edge:\t 1123 --> 421\n",
      "\tremove edge:\t 37 --> 60\n",
      "\tnew edge:\t 1234 --> 333\n",
      "\tnew edge:\t 189 --> 359\n",
      "\tremove edge:\t 1724 --> 1725\n",
      "\tremove edge:\t 964 --> 967\n",
      "\tnew edge:\t 1934 --> 825\n",
      "\tnew edge:\t 227 --> 460\n",
      "\tnew edge:\t 2049 --> 1817\n",
      "\tremove edge:\t 470 --> 958\n",
      "\tnew edge:\t 522 --> 736\n",
      "\tremove edge:\t 2094 --> 303\n",
      "\tremove edge:\t 54 --> 121\n",
      "\tremove edge:\t 830 --> 838\n",
      "\tnew edge:\t 1673 --> 1975\n",
      "\tremove edge:\t 1409 --> 1410\n",
      "\tremove edge:\t 588 --> 589\n",
      "\tnew edge:\t 1800 --> 1680\n",
      "\tremove edge:\t 1673 --> 1674\n",
      "\tnew edge:\t 1308 --> 1503\n",
      "\tnew edge:\t 1062 --> 959\n",
      "\tnew edge:\t 1987 --> 482\n",
      "\tnew edge:\t 1580 --> 77\n",
      "\tremove edge:\t 1246 --> 1247\n",
      "\tremove edge:\t 78 --> 165\n",
      "\tremove edge:\t 1283 --> 1285\n",
      "\tremove edge:\t 539 --> 19\n",
      "\tremove edge:\t 1574 --> 613\n",
      "\tnew edge:\t 436 --> 762\n",
      "\tnew edge:\t 836 --> 1539\n",
      "\tnew edge:\t 1633 --> 2255\n",
      "\tnew edge:\t 955 --> 943\n",
      "\tremove edge:\t 574 --> 13\n",
      "\tnew edge:\t 1275 --> 1024\n",
      "\tremove edge:\t 1738 --> 63\n",
      "\tnew edge:\t 2197 --> 896\n",
      "\tnew edge:\t 1025 --> 877\n",
      "\tremove edge:\t 1377 --> 1379\n",
      "\tnew edge:\t 329 --> 1855\n",
      "\tnew edge:\t 1448 --> 1730\n",
      "\tnew edge:\t 1052 --> 849\n",
      "\tremove edge:\t 1610 --> 1611\n",
      "\tnew edge:\t 1314 --> 1578\n",
      "\tnew edge:\t 1027 --> 2186\n",
      "\tnew edge:\t 941 --> 1770\n",
      "\tnew edge:\t 1410 --> 1678\n",
      "\tnew edge:\t 658 --> 440\n",
      "\tremove edge:\t 2280 --> 197\n",
      "\tnew edge:\t 1803 --> 2038\n",
      "\tremove edge:\t 138 --> 33\n",
      "\tnew edge:\t 2145 --> 1420\n",
      "\tremove edge:\t 2408 --> 2409\n",
      "\tnew edge:\t 792 --> 1808\n",
      "\tnew edge:\t 704 --> 1329\n",
      "\tnew edge:\t 1071 --> 678\n",
      "\tnew edge:\t 2397 --> 950\n",
      "\tremove edge:\t 1294 --> 1295\n",
      "\tnew edge:\t 1310 --> 15\n",
      "\tremove edge:\t 1933 --> 2154\n",
      "\tremove edge:\t 890 --> 892\n",
      "\tnew edge:\t 686 --> 1671\n",
      "\tnew edge:\t 1821 --> 385\n",
      "\tnew edge:\t 741 --> 1117\n",
      "\tnew edge:\t 1708 --> 1613\n",
      "\tremove edge:\t 1499 --> 1500\n",
      "\tremove edge:\t 2416 --> 2417\n",
      "\tnew edge:\t 866 --> 1270\n",
      "\tremove edge:\t 1697 --> 1698\n",
      "\tnew edge:\t 524 --> 1711\n",
      "\tremove edge:\t 740 --> 741\n",
      "\tnew edge:\t 2414 --> 637\n",
      "\tnew edge:\t 926 --> 797\n",
      "number of edges added: 54\n",
      "number of edges removed 46\n"
     ]
    }
   ],
   "source": [
    "G_random_edges_uniform_random = random_edges_uniform_random(G.copy(), 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we run `calc_pagerank` to calculate the new pagerank scores of `G_random_edges_uniform_random`. Thereafter a dataframe is created of the pagerank scores, together with for each node the number of incoming edges and outcoming edges. The nodes are sorted on the pagerank score, in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rank</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>404</td>\n",
       "      <td>0.042988</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195</td>\n",
       "      <td>0.020129</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>0.018712</td>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>0.011565</td>\n",
       "      <td>168</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>192</td>\n",
       "      <td>0.009662</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>135</td>\n",
       "      <td>0.009649</td>\n",
       "      <td>49</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>728</td>\n",
       "      <td>0.009423</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>281</td>\n",
       "      <td>0.009182</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>136</td>\n",
       "      <td>0.008851</td>\n",
       "      <td>85</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>184</td>\n",
       "      <td>0.008165</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rank node     score  in edges  out edges\n",
       "1     404  0.042988        10          0\n",
       "2     195  0.020129        80          1\n",
       "3      77  0.018712       122          2\n",
       "4      36  0.011565       168          5\n",
       "5     192  0.009662        57          3\n",
       "6     135  0.009649        49          8\n",
       "7     728  0.009423         9          1\n",
       "8     281  0.009182        32          0\n",
       "9     136  0.008851        85          6\n",
       "10    184  0.008165        80          3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_random_edges_uniform_random = calc_pagerank(G_random_edges_uniform_random)\n",
    "df_random_edges_uniform_random = create_dataframe(pr_random_edges_uniform_random, G_random_edges_uniform_random)\n",
    "df_random_edges_uniform_random.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the results are analyzed, lets first talk about some intuition what could happen when edges are added or removed uniformly at random. The original graph $G$ is a scale-free network, i.e. its degree distribution follows a power law, at least asymptiotically. This means that in this type of network structure, there will be many nodes with very low level of connectivity. And very few or except one node with exceptionally high degree of connectivity. So the nodes are very unequal in terms of how connected and influential the different nodes in the network are. Scale free networks describes a power or exponential relationship between the degree of connectivity a node has and the frequency of its occurence. This results in a highly centralized network. In the social network that is loaded from hamsterster.com, we have some people who have very many links into them, but there are also many people that have very few links into them. The power law distribution is often explained with reference to preferential attachment. Preferential attachment describes how a new node is linked amongst a number of nodes according to how much they already have. So those who already have a lot of links will receive more than those who have litte: the so called \"rich get richer model\". In the paragraphs D-E-F-G, preferential attachment proporional to some statistical measures is elaborated and analyzed. Paragraphs A-B-C will analyze the effects of adding/removing nodes/adges uniformly at random. In paragraph A, we add or remove only edges uniformly at random. In paragraph B nodes and corresponding edges are added uniformly at random. In paragraph C nodes and corresponding edges are removed uniformly at random. All modifications that will take place in paragraph A-B-C are determined uniformly at random, i.e. all nodes have equal probability to be chosen or to be removed. Scale free networks can be very robust or very fragile, depending on how we remove nodes (randomly or strategically). If we remove nodes uniformly at random, the network will be very robust to failure. This is because the vast majority of nodes have a very low degree of connectivity. Therefore, it is very likely that we will modify one of these insignificant nodes with little effect on the overall network.\n",
    "So real word networks, like the network from hamsterster.com, are resilient to random attacks.  \n",
    "\n",
    "When we add or remove only edges, we expect a constant average degree, i.e. the number of edges grows linearly with the number of nodes. Also, we expect that as the network grows, the distances between nodes grow. From the output of the function above, we see that $54$ edges are added, and $46$ edges are removed. When we look at the top ten nodes, we see that the top ten of `G_random_edges_uniform_random` exactly matches the top ten of the original graph $G$. Let's dive deeper into both graphs to look if there changed else.\n",
    "\n",
    "First, we compare the $density$ between the original graph G and the graph `G_random_edges_uniform_random`. The density for directed graphs is: $d = \\frac{E}{V(V-1)}$, where $E$ denotes the total number of edges and $V$ denotes the total number of nodes in the particular graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: \\nType: DiGraph\\nNumber of nodes: 2426\\nNumber of edges: 16631\\nAverage in degree:   6.8553\\nAverage out degree:   6.8553'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.info(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: \\nType: DiGraph\\nNumber of nodes: 2426\\nNumber of edges: 16643\\nAverage in degree:   6.8603\\nAverage out degree:   6.8603'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.info(G_random_edges_uniform_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.002826935008201528, 0.002828974766490171)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.density(G), nx.density(G_random_edges_uniform_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we determine inside the function whether we add or remove an edge, the top ten of nodes are equal to the top ten nodes. This makes totally sense. The purpose of the function is adding or removing edges uniformaly at random to `number_of_nodes` nodes. These selected nodes all have the same probability to be selected. As explained earlier, there are a lot of nodes in the network that have a low connectivity and only a few nodes with a very high connectivity. It is very likely that we will modify one of these insignificant nodes with little effect on the overall network and therefore we can explain that the top ten ranked nodes are not changed after adding or removing only nodes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### only edges added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tnew edge:\t 411 --> 2046\n",
      "\tnew edge:\t 1620 --> 714\n",
      "\tnew edge:\t 1273 --> 708\n",
      "\tnew edge:\t 996 --> 1888\n",
      "\tnew edge:\t 2208 --> 531\n",
      "\tnew edge:\t 536 --> 2138\n",
      "\tnew edge:\t 1830 --> 1848\n",
      "\tnew edge:\t 1594 --> 1670\n",
      "\tnew edge:\t 1140 --> 2302\n",
      "\tnew edge:\t 733 --> 829\n",
      "\tnew edge:\t 1821 --> 1030\n",
      "\tnew edge:\t 2310 --> 1126\n",
      "\tnew edge:\t 492 --> 2347\n",
      "\tnew edge:\t 1568 --> 1933\n",
      "\tnew edge:\t 755 --> 1978\n",
      "\tnew edge:\t 1956 --> 1742\n",
      "\tnew edge:\t 705 --> 374\n",
      "\tnew edge:\t 311 --> 762\n",
      "\tnew edge:\t 982 --> 1329\n",
      "\tnew edge:\t 1885 --> 1525\n",
      "\tnew edge:\t 67 --> 658\n",
      "\tnew edge:\t 1553 --> 1353\n",
      "\tnew edge:\t 2024 --> 2260\n",
      "\tnew edge:\t 115 --> 1421\n",
      "\tnew edge:\t 17 --> 951\n",
      "\tnew edge:\t 2307 --> 118\n",
      "\tnew edge:\t 1900 --> 50\n",
      "\tnew edge:\t 1307 --> 2096\n",
      "\tnew edge:\t 226 --> 1078\n",
      "\tnew edge:\t 681 --> 568\n",
      "\tnew edge:\t 195 --> 2231\n",
      "\tnew edge:\t 67 --> 160\n",
      "\tnew edge:\t 393 --> 1424\n",
      "\tnew edge:\t 942 --> 1138\n",
      "\tnew edge:\t 1217 --> 16\n",
      "\tnew edge:\t 2423 --> 1800\n",
      "\tnew edge:\t 729 --> 1713\n",
      "\tnew edge:\t 373 --> 776\n",
      "\tnew edge:\t 1574 --> 1999\n",
      "\tnew edge:\t 1674 --> 1122\n",
      "\tnew edge:\t 2404 --> 1496\n",
      "\tnew edge:\t 515 --> 2297\n",
      "\tnew edge:\t 812 --> 316\n",
      "\tnew edge:\t 2298 --> 215\n",
      "\tnew edge:\t 2150 --> 1449\n",
      "\tnew edge:\t 2193 --> 1345\n",
      "\tnew edge:\t 1550 --> 467\n",
      "\tnew edge:\t 515 --> 842\n",
      "\tnew edge:\t 561 --> 1793\n",
      "\tnew edge:\t 1729 --> 2236\n",
      "\tnew edge:\t 1100 --> 136\n",
      "\tnew edge:\t 2101 --> 2412\n",
      "\tnew edge:\t 1554 --> 2235\n",
      "\tnew edge:\t 137 --> 1474\n",
      "\tnew edge:\t 949 --> 1160\n",
      "\tnew edge:\t 660 --> 1177\n",
      "\tnew edge:\t 197 --> 245\n",
      "\tnew edge:\t 1404 --> 1176\n",
      "\tnew edge:\t 1787 --> 2077\n",
      "\tnew edge:\t 620 --> 1270\n",
      "\tnew edge:\t 61 --> 475\n",
      "\tnew edge:\t 1415 --> 2037\n",
      "\tnew edge:\t 2138 --> 1110\n",
      "\tnew edge:\t 52 --> 2326\n",
      "\tnew edge:\t 739 --> 1553\n",
      "\tnew edge:\t 399 --> 870\n",
      "\tnew edge:\t 965 --> 1189\n",
      "\tnew edge:\t 1821 --> 2082\n",
      "\tnew edge:\t 329 --> 934\n",
      "\tnew edge:\t 662 --> 848\n",
      "\tnew edge:\t 682 --> 1139\n",
      "\tnew edge:\t 1827 --> 229\n",
      "\tnew edge:\t 1386 --> 1038\n",
      "\tnew edge:\t 1639 --> 2416\n",
      "\tnew edge:\t 1870 --> 2400\n",
      "\tnew edge:\t 2026 --> 84\n",
      "\tnew edge:\t 1939 --> 655\n",
      "\tnew edge:\t 1298 --> 47\n",
      "\tnew edge:\t 1195 --> 419\n",
      "\tnew edge:\t 2312 --> 257\n",
      "\tnew edge:\t 924 --> 1191\n",
      "\tnew edge:\t 1632 --> 2019\n",
      "\tnew edge:\t 878 --> 301\n",
      "\tnew edge:\t 65 --> 1469\n",
      "\tnew edge:\t 495 --> 1319\n",
      "\tnew edge:\t 1371 --> 1722\n",
      "\tnew edge:\t 1340 --> 1750\n",
      "\tnew edge:\t 142 --> 1963\n",
      "\tnew edge:\t 25 --> 1117\n",
      "\tnew edge:\t 931 --> 73\n",
      "\tnew edge:\t 618 --> 1039\n",
      "\tnew edge:\t 76 --> 2233\n",
      "\tnew edge:\t 1185 --> 999\n",
      "\tnew edge:\t 1637 --> 1974\n",
      "\tnew edge:\t 1560 --> 2100\n",
      "\tnew edge:\t 934 --> 1940\n",
      "\tnew edge:\t 2365 --> 2152\n",
      "\tnew edge:\t 874 --> 229\n",
      "\tnew edge:\t 1217 --> 993\n",
      "\tnew edge:\t 1066 --> 618\n",
      "number of edges added: 100\n",
      "number of edges removed 0\n"
     ]
    }
   ],
   "source": [
    "#number_of_nodes_random = random.randint(1,  int(0.1 * nx.number_of_edges(G.copy()))) #max 10% of edges to add\n",
    "#print(\"number of nodes: \" + str(number_of_nodes_random))\n",
    "G_random_add_edges_uniform_random = random_edges_uniform_random(G.copy(), 100, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rank</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>404</td>\n",
       "      <td>0.035454</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195</td>\n",
       "      <td>0.020621</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>0.019237</td>\n",
       "      <td>121</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>728</td>\n",
       "      <td>0.015491</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36</td>\n",
       "      <td>0.011451</td>\n",
       "      <td>168</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>192</td>\n",
       "      <td>0.010375</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>135</td>\n",
       "      <td>0.009399</td>\n",
       "      <td>49</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>281</td>\n",
       "      <td>0.009180</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2231</td>\n",
       "      <td>0.008848</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>136</td>\n",
       "      <td>0.008765</td>\n",
       "      <td>86</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rank  node     score  in edges  out edges\n",
       "1      404  0.035454        10          0\n",
       "2      195  0.020621        80          2\n",
       "3       77  0.019237       121          2\n",
       "4      728  0.015491        10          0\n",
       "5       36  0.011451       168          5\n",
       "6      192  0.010375        57          3\n",
       "7      135  0.009399        49          8\n",
       "8      281  0.009180        32          0\n",
       "9     2231  0.008848         1          9\n",
       "10     136  0.008765        86          6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_random_add_edges_uniform_random = calc_pagerank(G_random_add_edges_uniform_random)\n",
    "df_random_add_edges_uniform_random = create_dataframe(pr_random_add_edges_uniform_random, G_random_add_edges_uniform_random)\n",
    "df_random_add_edges_uniform_random.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see the resulting top ten dataframe after running the function `random_edges_uniform_random`, parameterized with a copy of the original graph  GG , number_of_nodes = 248 and choice = True. In other words, the function adds 248 new edges (incoming or outgoing) to the network. The output is exaclty what we expect: the top ten is not changed that much. The only new node is node 281, which replaced node 184 of the original graph. Indeed, the new nodes that are added uniformly at random don't have a preferential attachment to the highly connected, because the number of incoming edges and outcoming edges for the remaining top nine nodes are exactly the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: \\nType: DiGraph\\nNumber of nodes: 2426\\nNumber of edges: 16631\\nAverage in degree:   6.8553\\nAverage out degree:   6.8553'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.info(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: \\nType: DiGraph\\nNumber of nodes: 2426\\nNumber of edges: 16731\\nAverage in degree:   6.8965\\nAverage out degree:   6.8965'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.info(G_random_add_edges_uniform_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.002826935008201528, 0.0028439329939402183)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.density(G), nx.density(G_random_add_edges_uniform_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### only edges removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tremove edge:\t 2391 --> 328\n",
      "\tremove edge:\t 1073 --> 1074\n",
      "\tremove edge:\t 12 --> 653\n",
      "\tremove edge:\t 1126 --> 1127\n",
      "\tremove edge:\t 2300 --> 864\n",
      "\tremove edge:\t 2072 --> 908\n",
      "\tremove edge:\t 1428 --> 1427\n",
      "\tremove edge:\t 394 --> 411\n",
      "\tremove edge:\t 1779 --> 371\n",
      "\tremove edge:\t 206 --> 207\n",
      "\tremove edge:\t 2018 --> 2019\n",
      "\tremove edge:\t 2138 --> 2139\n",
      "\tremove edge:\t 1861 --> 127\n",
      "\tremove edge:\t 1410 --> 1411\n",
      "\tremove edge:\t 407 --> 109\n",
      "\tremove edge:\t 1866 --> 544\n",
      "\tremove edge:\t 689 --> 100\n",
      "\tremove edge:\t 1144 --> 1146\n",
      "\tremove edge:\t 683 --> 690\n",
      "\tremove edge:\t 489 --> 486\n",
      "\tremove edge:\t 2242 --> 2243\n",
      "\tremove edge:\t 1579 --> 603\n",
      "\tremove edge:\t 891 --> 894\n",
      "\tremove edge:\t 1666 --> 1672\n",
      "\tremove edge:\t 1956 --> 436\n",
      "\tremove edge:\t 1874 --> 410\n",
      "\tremove edge:\t 1221 --> 1223\n",
      "\tremove edge:\t 1869 --> 1870\n",
      "\tremove edge:\t 1414 --> 1416\n",
      "\tremove edge:\t 2245 --> 412\n",
      "\tremove edge:\t 889 --> 890\n",
      "\tremove edge:\t 2039 --> 2044\n",
      "\tremove edge:\t 83 --> 131\n",
      "\tremove edge:\t 1038 --> 1039\n",
      "\tremove edge:\t 637 --> 447\n",
      "\tremove edge:\t 2188 --> 326\n",
      "\tremove edge:\t 434 --> 435\n",
      "\tremove edge:\t 55 --> 57\n",
      "\tremove edge:\t 1841 --> 762\n",
      "\tremove edge:\t 1730 --> 348\n",
      "\tremove edge:\t 1930 --> 19\n",
      "\tremove edge:\t 814 --> 815\n",
      "\tremove edge:\t 2290 --> 476\n",
      "\tremove edge:\t 2199 --> 101\n",
      "\tremove edge:\t 1027 --> 1028\n",
      "\tremove edge:\t 2013 --> 21\n",
      "\tremove edge:\t 77 --> 404\n",
      "\tremove edge:\t 636 --> 721\n",
      "\tremove edge:\t 1589 --> 1590\n",
      "\tremove edge:\t 888 --> 895\n",
      "\tremove edge:\t 98 --> 106\n",
      "\tremove edge:\t 396 --> 24\n",
      "\tremove edge:\t 1026 --> 105\n",
      "\tremove edge:\t 2269 --> 101\n",
      "\tremove edge:\t 610 --> 615\n",
      "\tremove edge:\t 1842 --> 1843\n",
      "\tremove edge:\t 812 --> 540\n",
      "\tremove edge:\t 1043 --> 1044\n",
      "\tremove edge:\t 198 --> 199\n",
      "\tremove edge:\t 722 --> 46\n",
      "\tremove edge:\t 1728 --> 1729\n",
      "\tremove edge:\t 384 --> 386\n",
      "\tremove edge:\t 2338 --> 2043\n",
      "\tremove edge:\t 1791 --> 458\n",
      "\tremove edge:\t 1295 --> 1297\n",
      "\tremove edge:\t 1634 --> 335\n",
      "\tremove edge:\t 1344 --> 1345\n",
      "\tremove edge:\t 238 --> 170\n",
      "\tremove edge:\t 279 --> 173\n",
      "\tremove edge:\t 520 --> 521\n",
      "\tremove edge:\t 1710 --> 278\n",
      "\tremove edge:\t 1390 --> 369\n",
      "\tremove edge:\t 2189 --> 2191\n",
      "\tremove edge:\t 1658 --> 1659\n",
      "\tremove edge:\t 1708 --> 281\n",
      "\tremove edge:\t 1355 --> 182\n",
      "\tremove edge:\t 756 --> 117\n",
      "\tremove edge:\t 35 --> 923\n",
      "\tremove edge:\t 1732 --> 116\n",
      "\tremove edge:\t 981 --> 183\n",
      "\tremove edge:\t 2379 --> 829\n",
      "\tremove edge:\t 1258 --> 152\n",
      "\tremove edge:\t 2410 --> 131\n",
      "\tremove edge:\t 1538 --> 186\n",
      "\tremove edge:\t 138 --> 36\n",
      "\tremove edge:\t 1139 --> 1140\n",
      "number of edges added: 0\n",
      "number of edges removed 100\n"
     ]
    }
   ],
   "source": [
    "#number_of_nodes_random = random.randint(1,  int(0.1 * nx.number_of_edges(G.copy()))) #max 10% of edges to remove to select\n",
    "#print(\"number of nodes: \" + str(number_of_nodes_random))\n",
    "G_random_remove_edges_uniform_random = random_edges_uniform_random(G.copy(), 100, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rank</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>404</td>\n",
       "      <td>0.042517</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195</td>\n",
       "      <td>0.028656</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>0.019047</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>728</td>\n",
       "      <td>0.015237</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>167</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>192</td>\n",
       "      <td>0.010468</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>135</td>\n",
       "      <td>0.009435</td>\n",
       "      <td>49</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>281</td>\n",
       "      <td>0.009245</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>136</td>\n",
       "      <td>0.008725</td>\n",
       "      <td>85</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>184</td>\n",
       "      <td>0.008287</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rank node     score  in edges  out edges\n",
       "1     404  0.042517         9          0\n",
       "2     195  0.028656        80          1\n",
       "3      77  0.019047       121          1\n",
       "4     728  0.015237        10          0\n",
       "5      36  0.012024       167          5\n",
       "6     192  0.010468        57          3\n",
       "7     135  0.009435        49          8\n",
       "8     281  0.009245        31          0\n",
       "9     136  0.008725        85          6\n",
       "10    184  0.008287        80          3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_random_remove_edges_uniform_random = calc_pagerank(G_random_remove_edges_uniform_random)\n",
    "df_random_remove_edges_uniform_random = create_dataframe(pr_random_remove_edges_uniform_random, G_random_remove_edges_uniform_random)\n",
    "df_random_remove_edges_uniform_random.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see the resulting top ten dataframe after running the function `random_edges_uniform_random`, parameterized with a copy of the original graph $G$, `number_of_nodes` = 100 and choice = False. In other words, the function only removes edges for 100 nodes in the graph uniformly at random. Also in this case we see that the top ten remains the same. This means that indeed the edges are removed uniformly at random, i.e. most of the edges that are removed are of the insignificant edges. Also we see that the score of the first node, node 404, is slightly decreased, while the second and third nodes (77 and 195) are increased. This means that the function did remove some high ranked links from node 404. Removing nodes will decrease the average degree of the nodes, which is comfirmed by the two info cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: \\nType: DiGraph\\nNumber of nodes: 2426\\nNumber of edges: 16631\\nAverage in degree:   6.8553\\nAverage out degree:   6.8553'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.info(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: \\nType: DiGraph\\nNumber of nodes: 2426\\nNumber of edges: 16545\\nAverage in degree:   6.8199\\nAverage out degree:   6.8199'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.info(G_random_remove_edges_uniform_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.002826935008201528, 0.0028123167404662548)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.density(G), nx.density(G_random_remove_edges_uniform_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When edges are removed, the density of the network shrinks which is what we expected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Adding nodes uniformly at random (copying model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $n$ iterations do the following:\n",
    "* Make a new node instance $n$\n",
    "* with a uniform random distribution pick $k$ nodes in the original graph\n",
    "* copy the incoming/outgoing edges of the $k$ nodes for $n$\n",
    "* choose with an unifrom distribution another node $l$ and add its edges also to $n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>The last step might seem redundant at the moment, but later when the the $k$ nodes are going to be chosen with at random but proportional to a certain statistic, it makes sense to have a step in which you pick another node $l$ that is chosen with the opposite property so that the generation/stability of communities is ensured (i.e. power-law degree). In this implementation. This step is omitted, but it will be thus added in the functions that take statistical measures into consideration when choosing nodes at random</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#randomly add and remove nodes\n",
    "#Edge Copying Model (slide 53 of Week6-SNA-Props)\n",
    "def random_add_nodes_uniform(G_in, number_of_nodes = 1, k = 5):\n",
    "    print(\"number of edges before :\"+ str(len(G_in.edges())))\n",
    "    for _ in range(number_of_nodes):\n",
    "        #k is number of edges to be added, random integer 1 between 5\n",
    "        k = random.randint(1, k) #select k random vertices\n",
    "        #print(\"k = \" + str(k))\n",
    "        new_node = nx.number_of_nodes(G_in) + 1 #add node to graph\n",
    "        # print(\"new node = \" + str(new_node))\n",
    "        \n",
    "        list_of_nodes = list(G_in)  #create list of nodes\n",
    "        \n",
    "        G_in.add_node(str(new_node))   \n",
    "        k_random_selected_nodes = np.random.choice(list_of_nodes, size = k, replace = False) # k nodes with a uniform distribution\n",
    "        \n",
    "        for node in k_random_selected_nodes:\n",
    "            #print(\"node in k_random_selected_nodes = \" + str(node))\n",
    "            successors = list(G_in.successors(str(node)))\n",
    "            #print(\"succesors are \" + str(successors))\n",
    "            for node_to in successors:\n",
    "                G_in.add_edge(new_node, node_to) # add outgoing edges\n",
    "            predecessors = list(G_in.predecessors(str(node)))\n",
    "            for node_from in predecessors:\n",
    "                G_in.add_edge(node_from, new_node) # add incoming edges\n",
    "    print(\"number of edges after :\"+str(len(G_in.edges())))\n",
    "    return G_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of edges before :16631\n",
      "number of edges after :17756\n"
     ]
    }
   ],
   "source": [
    "#number_of_nodes_to_add_random = random.randint(1,  int(0.1 * len(list(G.copy()))))\n",
    "#print(\"number of nodes added: \" + str(number_of_nodes_to_add_random))\n",
    "G_random_add_nodes_uniform = random_add_nodes_uniform(G.copy(), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rank</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>404</td>\n",
       "      <td>0.041764</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195</td>\n",
       "      <td>0.019590</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>0.018303</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>728</td>\n",
       "      <td>0.015904</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36</td>\n",
       "      <td>0.010739</td>\n",
       "      <td>172</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>135</td>\n",
       "      <td>0.009313</td>\n",
       "      <td>52</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>281</td>\n",
       "      <td>0.009128</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>192</td>\n",
       "      <td>0.008882</td>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>136</td>\n",
       "      <td>0.008499</td>\n",
       "      <td>87</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>184</td>\n",
       "      <td>0.008190</td>\n",
       "      <td>85</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rank node     score  in edges  out edges\n",
       "1     404  0.041764        10          0\n",
       "2     195  0.019590        83          1\n",
       "3      77  0.018303       128          2\n",
       "4     728  0.015904        12          0\n",
       "5      36  0.010739       172          5\n",
       "6     135  0.009313        52          8\n",
       "7     281  0.009128        34          0\n",
       "8     192  0.008882        58          3\n",
       "9     136  0.008499        87          6\n",
       "10    184  0.008190        85          3"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_random_add_nodes_uniform = calc_pagerank(G_random_add_nodes_uniform)\n",
    "df_random_add_nodes_uniform = create_dataframe(pr_random_add_nodes_uniform, G_random_add_nodes_uniform)\n",
    "df_random_add_nodes_uniform.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`random_add_nodes_uniform` add nodes uniformly at random, while the degree distribution of the network still satisfies the power law distribution. We call the function, parameterized with `number_of_nodes` =  maximal 10% of the total number of nodes that are in $G$. What we see is that rank of some nodes in the top ten is changed. We even see a new node in top ten, node 126. This means that randomness can create new strong nodes, by adding new nodes and create new strong communities in the graph. However, since this all happens unformly at random, we can't guarantee that this happens every single run (which we can guarantee when we add proportional to some statistical measure, see D-E-F-G). The added nodes are linked, one by one, to $k$ random selected nodes. Note that every node in $G$ does have the same probability, so again, it is most likely that we select the insignificant nodes as nodes where we link the new nodes to. We see that node 126 is in the top then , but this is because node 184 has a lower pagerank score compared to the original graph $G$. This could be that the some of the new added nodes are linked to node 184, and because this nodes have a low pagerank score, it will have a negative effect on node 184. We can also look at the density of graph  `G_random_add_nodes_uniform`. Because we add nodes, the density should be lower compared to the original graph $G$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: \\nType: DiGraph\\nNumber of nodes: 2426\\nNumber of edges: 16631\\nAverage in degree:   6.8553\\nAverage out degree:   6.8553'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.info(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: \\nType: DiGraph\\nNumber of nodes: 2622\\nNumber of edges: 17756\\nAverage in degree:   6.7719\\nAverage out degree:   6.7719'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.info(G_random_add_nodes_uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.002826935008201528, 0.0025837198872801998)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.density(G), nx.density(G_random_add_nodes_uniform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Removal of nodes uniformly at random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $n$ represent the number of nodes that should be removed. If the $number\\_of\\_nodes$ parameter is givem then $n = number\\_of\\_nodes$, if this parameter is not specfied by the caller we have $n = \\lfloor(0.1 * total\\_number\\_of\\_nodes(G\\_in))\\rfloor)$\n",
    "\n",
    "For $n$ iterations do the following:\n",
    "* Select a node $m$ uniformly at random (iterations are abstracted by $np.random.choice$)\n",
    "* Remove this node and its respective edges from the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_removal_nodes_uniform(G_in, number_given = False, number_of_nodes = None):\n",
    "    if (number_given & number_of_nodes < len(list(G_in))): # check if we do not remove too much nodes\n",
    "        n = number_of_nodes\n",
    "    else:\n",
    "        n = int(0.1 * len(list(G_in)))  # max 10% of nodes\n",
    "    #remove nodes and corresponding edges\n",
    "    print(\"number of nodes before :\"+ str(len(list(G_in))))\n",
    "    list_of_nodes = list(G_in)\n",
    "    selected_nodes = np.random.choice(list_of_nodes, size = n, replace = False)\n",
    "    for m_remove in selected_nodes:\n",
    "        G_in.remove_node(m_remove)\n",
    "    print(\"number of nodes after :\"+ str(len(list(G_in))))\n",
    "    return G_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes before :2426\n",
      "number of nodes after :2326\n"
     ]
    }
   ],
   "source": [
    "G_random_removal_nodes_uniform = random_removal_nodes_uniform(G.copy(), True, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rank</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>404</td>\n",
       "      <td>0.043358</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195</td>\n",
       "      <td>0.020496</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>0.018887</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>728</td>\n",
       "      <td>0.015455</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36</td>\n",
       "      <td>0.011418</td>\n",
       "      <td>167</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>135</td>\n",
       "      <td>0.009693</td>\n",
       "      <td>47</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>192</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>281</td>\n",
       "      <td>0.009136</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>136</td>\n",
       "      <td>0.009073</td>\n",
       "      <td>83</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>184</td>\n",
       "      <td>0.008431</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rank node     score  in edges  out edges\n",
       "1     404  0.043358        10          0\n",
       "2     195  0.020496        79          1\n",
       "3      77  0.018887       119          2\n",
       "4     728  0.015455        10          0\n",
       "5      36  0.011418       167          5\n",
       "6     135  0.009693        47          8\n",
       "7     192  0.009582        56          3\n",
       "8     281  0.009136        30          0\n",
       "9     136  0.009073        83          6\n",
       "10    184  0.008431        76          3"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_random_removal_nodes_uniform = calc_pagerank(G_random_removal_nodes_uniform)\n",
    "df_random_removal_nodes_uniform = create_dataframe(pr_random_removal_nodes_uniform, G_random_removal_nodes_uniform)\n",
    "df_random_removal_nodes_uniform.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: \\nType: DiGraph\\nNumber of nodes: 2426\\nNumber of edges: 16631\\nAverage in degree:   6.8553\\nAverage out degree:   6.8553'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.info(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: \\nType: DiGraph\\nNumber of nodes: 2326\\nNumber of edges: 15504\\nAverage in degree:   6.6655\\nAverage out degree:   6.6655'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.info(G_random_removal_nodes_uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.002826935008201528, 0.0028668904113388623)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.density(G), nx.density(G_random_removal_nodes_uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.855317394888706, 6.665520206362855)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_node_degree_full_graph = df_origin[\"in edges\"].mean()\n",
    "avg_node_degree_graph_removed_nodes = df_random_removal_nodes_uniform[\"in edges\"].mean()\n",
    "avg_node_degree_full_graph, avg_node_degree_graph_removed_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`random_removal_nodes_uniform` removes nodes from the graph $G$ uniformly at random, parameterized with `number_of_nodes` = 100. It's is important to check whether the nodes that are removed are removed uniformly at random, i.e. the nodes that are removed are mostly the insignificant nodes. When we look at the output of the cell above, we see that the average degree of the nodes that are removed is slightly lower than the average degree of the full orignal graph $G$. This is good, because it means that in most of the cases only the insignificant nodes are removed. When we compare the top ten of `G_random_removal_nodes_uniform` to the top ten of $G$, we see that they contain the same items, only the order of some nodes has changed. For example, node 36 has climbed one spot, to rank 4. What happened is that `random_removal_nodes_uniform` removed some nodes that were linked to node 36 with a low pagerank score, and therefore the overall pagerank score of 36 has increased slightly. The most important conclusion that we can draw after this function call is that scale free networks are very robust against removing of nodes uniformly at random. As explained earlier, all nodes that are possible candidates to be removed have an equally probability to be chosen. Because we have only a few nodes with a very large connectivity, it is most likely that we select the nodes with a very low connectivity. Therefore the overall end result does not differ much compared to the original graph $G$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph evolution methodologies using statistical measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section is going to focus on graph evolution methodologies (e.g. node/edge removal/addition) that use statistical measures obtained from statisical measures obtained the original network and/or nodes. Like in the previous section, the effect is studied in relation to the original graph. In other words, we do not continue with the evolved graph after the evaluation of each function. In stead, we start with a new copy of the original graph for each function which enables us to compare the different type of graph evolution methodologies objectively and fair, and study their effects on the PageRank stability of the (original) network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Removal of nodes at random but proportional to the degree of the nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $n$ represent the number of nodes that should be removed. If the $number\\_of\\_nodes$ parameter is givem then $n = number\\_of\\_nodes$, if this parameter is not specfied by the caller we have $n = \\lfloor(0.1 * total\\_number\\_of\\_nodes(G\\_in))\\rfloor)$\n",
    "\n",
    "For $n$ iterations do the following:\n",
    "* Select a node $m$ at random, but proportional to the in degree's of the nodes (iterations are abstracted by $np.random.choice$)\n",
    "* Remove this node and its respective edges from the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_node_removals_proportional_degree(G_in, number_given = False, number_of_nodes = None, in_degree = True):\n",
    "    if (number_given & number_of_nodes < len(list(G_in))): # check if we do not remove too much nodes\n",
    "        n = number_of_nodes\n",
    "    else:\n",
    "        n = int(0.1 * len(list(G_in)))  # max 10% of nodes\n",
    "    #remove nodes and corresponding edges\n",
    "    print(\"number of nodes before :\"+ str(len(list(G_in))))\n",
    "    list_of_nodes = list(G_in)\n",
    "    if (in_degree):\n",
    "        degrees = dict(G_in.in_degree()).values() # in_degrees of all the nodes\n",
    "    else: # out_degree\n",
    "        degrees = dict(G_in.out_degree()).values() # in_degrees of all the nodes\n",
    "    prob_degree = [float(i)/sum(degrees) for i in degrees] # probabilities proportional to degree\n",
    "    \n",
    "    selected_nodes = np.random.choice(list_of_nodes, size = n, replace = False, p = prob_degree)\n",
    "    for m_remove in selected_nodes:\n",
    "        G_in.remove_node(m_remove)\n",
    "    print(\"number of nodes after :\"+ str(len(list(G_in))))\n",
    "    return G_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes before :2426\n",
      "number of nodes after :2326\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rank</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>404</td>\n",
       "      <td>0.027927</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>728</td>\n",
       "      <td>0.024710</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>0.019085</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.012414</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>697</td>\n",
       "      <td>0.011594</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rank node     score  in edges  out edges\n",
       "1     404  0.027927         8          0\n",
       "2     728  0.024710        10          0\n",
       "3      77  0.019085       104          1\n",
       "4       2  0.012414        33          0\n",
       "5     697  0.011594        15          1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_random_node_removals_proportional_indegree = random_node_removals_proportional_degree(G.copy(), True, 100, True)\n",
    "pr_random_node_removals_proportional_indegree = calc_pagerank(G_random_node_removals_proportional_indegree)\n",
    "df_random_node_removals_proportional_indegree = create_dataframe(pr_random_node_removals_proportional_indegree,\n",
    "                                                                 G_random_node_removals_proportional_indegree)\n",
    "df_random_node_removals_proportional_indegree.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the hundred nodes that are actually removed by the algorithm. The assumption is that the average in-degree of these 100 nodes is higher than the average node degree of the original graph $G$ since the nodes are removed at random, but proportional to their in-degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.855317, 5.33448)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_node_degree_full_graph = df_origin[\"in edges\"].mean()\n",
    "avg_node_degree_graph_removed_nodes = df_random_node_removals_proportional_indegree[\"in edges\"].mean()\n",
    "round(avg_node_degree_full_graph, 6), round(avg_node_degree_graph_removed_nodes, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the average node in-degree dropped significantly, we can indeed conclude that the function removed nodes at random, but proportional to their node degrees since th drop in the average node degree of all the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.31"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_original_graph = set(df_origin.node.values)\n",
    "nodes_evolved_graph = set(df_random_node_removals_proportional_indegree.node.values)\n",
    "removed_nodes = pd.DataFrame(list(nodes_original_graph.difference(nodes_evolved_graph)))\n",
    "removed_nodes = pd.merge(df_origin, removed_nodes, left_on = 'node', right_on = 0)\n",
    "avg_node_degree_removed_nodes = removed_nodes[\"in edges\"].mean()\n",
    "avg_node_degree_removed_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as already confirmed in the previous cell we can indeed conclude that the nodes that are removed have a significant higher node in-degree (on-average) than the average of the nodes in the original graph. We can thus indeed conclude that the function removed nodes at random, but proportional to their node degrees since th drop in the average node degree of all the nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our knowledge of the inner-workings of PageRank to state hyptothesis about the changes of PageRank of the (nodes in the) evolved graph, compared to the original graph. We know that the PageRank score of a node is influenced by the number (the set) of incoming edges, the number of outbound links of the source nodes of these edges and the score of the particular source nodes. In addition, the damping factor is used in the calculations, but this is kept the same in this PageRank stability analysis so will be left out of consideration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at what has happened to the PageRank scores after the removal of nodes at random, but proportional to the in-degree. As we have seen earlier, the nodes that were removed had on average, a much higher in-degree. Considering the PageRank formula, there is a high chance that nodes with a high number of incoming edges have a relatively high score. But this is affected by the quality of the nodes sourcing the incoming edge. In other words, even if a certain node $n_1$ has a high number of incoming edges than a node $n_2$, but the nodes connected to $n_2$ (have an outgoing edge to $n_2$ have relatively less outgoing links and a relatively higher score, it could be that the score of $n_2$ is higher than $n_1$.\n",
    "\n",
    "Let's assess whether the nodes that were removed with a relaltively high in-degree compared to the rest of the nodes, have had a negative effect on the average score of the nodes in the graph. Considering the elabaroation that is given in the previous paragraph, this is affected by the number of outgoing links of the nodes that had an edge to the removed nodes and the score of these nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.001654, 0.000412, 4.01)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_score_removed_nodes = removed_nodes.score.mean()\n",
    "avg_score_full_graph = df_origin.score.mean()\n",
    "round(avg_score_removed_nodes, 6), round(avg_score_full_graph, 6), round(avg_score_removed_nodes / avg_score_full_graph, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the the nodes that were removed indeed have a higher score (see factor) than the average score in the original graph of all the nodes.The nodes that had an outgoing edge to the nodes that were removed thus did not have such high number of total outgoing links that it affected the score of the removed nodes in such a way that the average score is not higher than that of the average node in the original graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at what happens with the PageRank scores when we remove nodes at random, but proportional to their out-degrees. When you look at the formula of PageRank, you see that an edge from a node with a lot of outoging links will make no significant contribution to the score of the particular node (when compared to a node of the same score with less outgoing links). The assumption is, therefore, that unlike in the previous case, the average PageRank score in the graph in which nodes are removed, will hardly differ from the average PageRank score in the original graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes before :2426\n",
      "number of nodes after :2326\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rank</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>404</td>\n",
       "      <td>0.042863</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195</td>\n",
       "      <td>0.020472</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>0.019070</td>\n",
       "      <td>108</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>728</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36</td>\n",
       "      <td>0.011485</td>\n",
       "      <td>152</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rank node     score  in edges  out edges\n",
       "1     404  0.042863        10          0\n",
       "2     195  0.020472        73          1\n",
       "3      77  0.019070       108          2\n",
       "4     728  0.015702        10          0\n",
       "5      36  0.011485       152          5"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_random_node_removals_proportional_outdegree = random_node_removals_proportional_degree(G.copy(), True, 100, False)\n",
    "pr_random_node_removals_proportional_outdegree = calc_pagerank(G_random_node_removals_proportional_outdegree)\n",
    "df_random_node_removals_proportional_outdegree = create_dataframe(pr_random_node_removals_proportional_outdegree,\n",
    "                                                                 G_random_node_removals_proportional_outdegree)\n",
    "df_random_node_removals_proportional_outdegree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0004299226139294739, 0.00041220115416324565, 1.04)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_score_graph_removed_nodes = df_random_node_removals_proportional_outdegree.score.mean()\n",
    "avg_score_full_graph = df_origin.score.mean()\n",
    "avg_score_graph_removed_nodes, avg_score_full_graph, round(avg_score_graph_removed_nodes / avg_score_full_graph, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And indeed, there is no significant differences in the average PageRank scores of the full network when removing nodes at random, but proportional to the out degree of the nodes (i.e. nodes with a higher out-degree have a higher probability to be removed at random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Removal of nodes at random but proportional to the hubs/authorithy measures (HITS) of nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $n$ represent the number of nodes that should be removed. If the $number\\_of\\_nodes$ parameter is givem then $n = number\\_of\\_nodes$, if this parameter is not specfied by the caller we have $n = \\lfloor(0.1 * total\\_number\\_of\\_nodes(G\\_in))\\rfloor)$\n",
    "\n",
    "For $n$ iterations do the following:\n",
    "* Select a node $m$ at random, but proportional to HITS measures (i.e. hub or authority) of the nodes (iterations are abstracted by $np.random.choice$)\n",
    "* Remove this node and its respective edges from the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_node_removals_proportional_HITS(G_in, authorithy = False, number_given = False, number_of_nodes = None):\n",
    "    print(\"number of nodes before: \" + str(len(list(G_in))))\n",
    "    if (number_given & number_of_nodes < len(list(G_in))): # check if we do not remove too much nodes\n",
    "        n = number_of_nodes\n",
    "    else:\n",
    "        n = int(0.1 * len(list(G_in)))  # max 10% of nodes\n",
    "    #remove nodes and corresponding edges\n",
    "    for i in range(0, n):\n",
    "        list_of_nodes = list(G_in)\n",
    "        #print(int((i / n) * 100), \"%\") # progress (nx.hits(Graph) takes some time depending on the graph size)\n",
    "        if (authorithy):\n",
    "            p = list(nx.hits(G_in)[1].values()) # probabilities proportional to authority of nodes\n",
    "        else: # hub\n",
    "            p = list(nx.hits(G_in)[0].values()) # probabilities proportional to hub of nodes\n",
    "        node_remove = np.random.choice(list_of_nodes, p = p)\n",
    "        G_in.remove_node(node_remove)\n",
    "    print(\"number of nodes after: \" + str(len(list(G_in))))\n",
    "    return G_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes before: 2426\n",
      "number of nodes after: 2326\n"
     ]
    }
   ],
   "source": [
    "G_random_node_removals_proportional_authority = random_node_removals_proportional_HITS(G.copy(), True, True, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rank</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>728</td>\n",
       "      <td>0.021528</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>404</td>\n",
       "      <td>0.017614</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>899</td>\n",
       "      <td>0.015640</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136</td>\n",
       "      <td>0.014771</td>\n",
       "      <td>62</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>183</td>\n",
       "      <td>0.013743</td>\n",
       "      <td>79</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rank node     score  in edges  out edges\n",
       "1     728  0.021528        10          0\n",
       "2     404  0.017614         7          0\n",
       "3     899  0.015640         7          0\n",
       "4     136  0.014771        62          4\n",
       "5     183  0.013743        79          3"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_random_node_removals_proportional_authority = calc_pagerank(G_random_node_removals_proportional_authority)\n",
    "df_random_node_removals_proportional_authority = create_dataframe(pr_random_node_removals_proportional_authority,\n",
    "                                                             G_random_node_removals_proportional_authority)\n",
    "df_random_node_removals_proportional_authority.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be a rather interesting analysis of the PageRank algorithm and its stability. Note that the previous function removes nodes at random, but proportional to algorithms acquired from the HITS algorithm. In particular, the funtion removes nodes at random proportional to their $hub$ or $authorithy$ values. Why is this interesting one may ask. A good hub reprresents a page (node) that points to many other pages, while a good authority represents a page that was linked by many different hubs. So there is definitely a relation between the HITS measures and the PageRank scores. While we could explain this relation in more detail, it is more fun to show this relation with evaluations of the node removals according to the HITS measurs, considering the avaialability of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The node removal of 100 nodes that was just executed was at random, but proportional to the authorithy values of the nodes. This means that nodes with a higher authority value will have a higher chance of being removed. In other words, nodes that were referred to by many other hubs (i.e. incoming edges) will have had a higher chance of being removed. We have seen earlier on that the in general (dependending on the explained pecularities), the average PageRank scores of nodes (when $n$ is large enough) will be higher than the average PageRank score in the original graph, when the nodes are removed at random but proportional to this measure. Let's see of the function does what it should do and whether this is indeed the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.855317, 4.765262)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_node_degree_graph_removed_nodes = df_random_node_removals_proportional_authority[\"in edges\"].mean()\n",
    "round(avg_node_degree_full_graph, 6), round(avg_node_degree_graph_removed_nodes, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, note that it seems that that function indeed removed nodes at random but proportional to the authority values since the average in-degree value has dropped significantly after removal of the nodes. Which makes sense since the authority is an indication of how many pages (i.e. nodes in our context) linked to that particular node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.96"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_evolved_graph = set(df_random_node_removals_proportional_authority.node.values)\n",
    "removed_nodes = pd.DataFrame(list(nodes_original_graph.difference(nodes_evolved_graph)))\n",
    "removed_nodes = pd.merge(df_origin, removed_nodes, left_on = 'node', right_on = 0)\n",
    "avg_node_degree_removed_nodes = removed_nodes[\"in edges\"].mean()\n",
    "avg_node_degree_removed_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And note once again that the average in degree is much higher than the average in degree of the original graph. The function does what it should do. There is a strong relation with the previous analyis due to the strong relation between the HITS measures and the in/out-degrees of the nodes. We have shown that some statistics lead to the same conclusion. Let's devise an other method to evaluate the stability of the PageRank values after removal of the nodes according to their hub values. Remember, a good hub reprresents a page (node) that points to many other pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes before: 2426\n",
      "number of nodes after: 2326\n"
     ]
    }
   ],
   "source": [
    "G_random_node_removals_proportional_hub = random_node_removals_proportional_HITS(G.copy(), False, True, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rank</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>404</td>\n",
       "      <td>0.042037</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>0.018145</td>\n",
       "      <td>95</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>728</td>\n",
       "      <td>0.015282</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36</td>\n",
       "      <td>0.010930</td>\n",
       "      <td>144</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rank node     score  in edges  out edges\n",
       "1     404  0.042037        10          0\n",
       "2     195  0.019400        65          1\n",
       "3      77  0.018145        95          2\n",
       "4     728  0.015282        10          0\n",
       "5      36  0.010930       144          5"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_random_node_removals_proportional_hub = calc_pagerank(G_random_node_removals_proportional_hub)\n",
    "df_random_node_removals_proportional_hub = create_dataframe(pr_random_node_removals_proportional_hub,\n",
    "                                                             G_random_node_removals_proportional_hub)\n",
    "df_random_node_removals_proportional_hub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like with the removal of nodes proportional to the out-degree (at random), the assumption is that removal of nodes proportional to their hub values, will have no significant effect on the PageRank values of the nodes in the the graph of the nodes that remain in the graph. We are, however, going to show this with a different method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the absolute change of the PageRank scores of the nodes that remain in the graph, once nodes are removed at random but proportional to their hub values. The hypothesis is already stated, let's see whether it holds up. We are going to form  a new DataFrame in which we have the new and old PageRank scores (i.e. before and after removal). And then going to add a new column with the %-change of the PageRank scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_random_node_removals_proportional_hub.rename(columns = {'score': 'new_score', 'in edges': 'new_in_edges',\n",
    "                                                           'out edges': 'new_out_edges'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rank</th>\n",
       "      <th>node</th>\n",
       "      <th>new_score</th>\n",
       "      <th>new_in_edges</th>\n",
       "      <th>new_out_edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>404</td>\n",
       "      <td>0.042037</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>0.018145</td>\n",
       "      <td>95</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>728</td>\n",
       "      <td>0.015282</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36</td>\n",
       "      <td>0.010930</td>\n",
       "      <td>144</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rank node  new_score  new_in_edges  new_out_edges\n",
       "1     404   0.042037            10              0\n",
       "2     195   0.019400            65              1\n",
       "3      77   0.018145            95              2\n",
       "4     728   0.015282            10              0\n",
       "5      36   0.010930           144              5"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_random_node_removals_proportional_hub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10:  3.2060444853041545 \n",
      "top 50:  7.4826313130799305 \n",
      "top 100:  7.844863838326026 \n",
      "whole graph:  8.378814306453327\n"
     ]
    }
   ],
   "source": [
    "df_compare_scores = pd.merge(df_random_node_removals_proportional_hub, df_origin, on = 'node')\n",
    "df_compare_scores[\"percentage_change\"] = df_compare_scores.apply(lambda row: ((row.new_score - row.score) / row.score) * 100, axis = 1)\n",
    "df_compare_scores[\"abs_percentage_change\"] = df_compare_scores.apply(lambda row: abs(row.percentage_change), axis = 1)\n",
    "print(\"top 10: \", df_compare_scores.head(10).abs_percentage_change.mean(),\n",
    "      \"\\ntop 50: \", df_compare_scores.head(50).abs_percentage_change.mean(), \n",
    "      \"\\ntop 100: \", df_compare_scores.head(100).abs_percentage_change.mean(), \n",
    "      \"\\nwhole graph: \", df_compare_scores.abs_percentage_change.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First note that the average change of the PageRank scores in the graph is not significant (single digit point percentage change), but what is even more interesting and scientifically interesting and explainable, is the fact that the change of the scores is on average less for nodes that had already a relatively high score to begin with. This can be seen in the previous print statement, we see that the average change of the scores (in point percentage) seems to be correlated with the original score of the node. Note that in addition, the number of total pages is reduced by 100 ($N$ in the PageRank) formula, which also has an effect on the new scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give a simplified explanation of the PageRank explanation (left out some assumptions such as no outbound edges = edge to all other nodes (pages) in the graph) let's have a look what is happening more or less under the hood. We have $PRs(n) = \\dfrac{1 - d}{N} + d \\cdot \\sum_{m \\, \\in \\, predecessors(n)} \\dfrac{PRs(m)}{\\mid\\,successors(m)\\,\\mid}$, <br>\n",
    "where $N =$ the number of pages (reduced by 100), $d$ is the damping factor (remained constant) and the notation $\\mid\\,successors(m)\\,\\mid$ is used to denote the <i>number</i> of successors of node $m$ (i.e. the number of outgoing edges of node $m$). So even if a node is not directly affected by removal of nodes (i.e. it keeps its edges as the nodes that were removed had no direct connection to it), its score will still change due to the fact that $N$ has changed and the fact that the score, or the number of outgoing edges of its predecessors could have changed. These are the things to take into consideration when looking at the changes and the statement that a single percentage change is not large for removal of 100 nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now back to the interesting correlation. It can be explained quite simply. Let us have a node $x$ with a relatively high PageRank score. If we would remove one its predecessors $y$ with a high number of outgoing edges (as is the case with the random removal of nodes proportional to the value of the hub measure), its effect on the score of node $x$ would not be significant or as high as the removal of a node $z$ with a relatively low amount of outgoing edges compared to $y$ but with the same score, its effect will be less significant as the number of outgoing edges is the denominator in the summation. And the contribtion of this node to the total sum of all the PageRank scores divided by the number of successors, of the predecessors would be small to begin with. This is a possible explanation (there can be other causes) of the correlation that has been shown. So in removal of nodes proportional to the hub values we have seen some interesting evaulations of the stability of the PageRank scores of the nodes in the graph. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. Addition of nodes at random but proportional to the degree of the nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $n$ represent the number of nodes that should be added to the network. If the $number\\_of\\_nodes$ parameter is given then $n = number\\_of\\_nodes$, if this parameter is not specfied by the caller we have $n = \\lfloor(0.1 * total\\_number\\_of\\_nodes(G\\_in))\\rfloor)$\n",
    "\n",
    "For $n$ iterations do the following:\n",
    "* Make a new node instance $n$\n",
    "* with a probability distribution proportional to the in-degree of nodes pick $k$ nodes in the original graph\n",
    "* copy the incoming/outgoing edges of the $k$ nodes for $n$\n",
    "* Pick a node $l$ (at random) in the graph in the graph which had a relatively low probability in the second step and repeat step 3 for this node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.str_"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.random.choice(list(G), size = 5, replace = False)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inspired by the Edge Copying Model (slide 53 of Week6-SNA-Props)\n",
    "def random_node_additions_proportional_in_degree(G_in, number_given = False, in_degree = True, number_of_nodes = 1, k = 5):\n",
    "    if (number_given & number_of_nodes < len(list(G_in))): # check if we do not remove too much nodes\n",
    "        n = number_of_nodes\n",
    "    else:\n",
    "        n = int(0.1 * len(list(G_in)))  # max 10% of nodes\n",
    "    print(\"number of edges before :\"+ str(len(G_in.edges())))\n",
    "    for i in range(n):\n",
    "        #k is number of edges to be added, random integer 1 between 5\n",
    "        k = random.randint(1, k) #select k random vertices\n",
    "        list_of_nodes = list(G_in)  #create list of nodes\n",
    "        if (in_degree):\n",
    "            degrees = dict(G_in.in_degree()).values() # in_degrees of all the nodes\n",
    "        else: # out-degree\n",
    "            degrees = dict(G_in.out_degree()).values() # out_degrees of all the nodes\n",
    "        prob_degree = [float(i)/sum(degrees) for i in degrees] # probabilities proportional to degree\n",
    "        k_random_selected_nodes = np.random.choice(list_of_nodes, size = k, p = prob_degree, replace = False) # selecte k nodes proportional to chosen measure\n",
    "        \n",
    "        new_node = nx.number_of_nodes(G_in) + 1 #add node to graph\n",
    "        G_in.add_node(str(new_node))\n",
    "        \n",
    "        for node in k_random_selected_nodes:\n",
    "            successors = list(G_in.successors(str(node)))\n",
    "            for node_to in successors:\n",
    "                G_in.add_edge(str(new_node), node_to) # add outgoing edges\n",
    "            predecessors = list(G_in.predecessors(str(node)))\n",
    "            for node_from in predecessors:\n",
    "                G_in.add_edge(node_from, str(new_node)) # add incoming edges\n",
    "        \n",
    "        # pick one node that has a low probability (relatively low number of incoming edges)\n",
    "        non_zero_probs = [i for i in prob_degree if i != 0.0]\n",
    "        highest_chance_nodes = np.random.choice(list_of_nodes, p = prob_degree, \n",
    "                                                size = (len(non_zero_probs) - 1), replace = False)\n",
    "        \n",
    "        node_to_add = str(random.sample(set(list_of_nodes).difference(set(highest_chance_nodes)), 1)[0]) # low prob node\n",
    "        successors = list(G_in.successors(node_to_add)) # successors of the node\n",
    "        predecessors = list(G_in.predecessors(node_to_add)) # predecessors of the node \n",
    "        \n",
    "        succ_current_node = list(G_in.successors(str(new_node))) # find the successors of the new node \n",
    "        pred_current_node = list(G_in.predecessors(str(new_node))) # find the predecessors of the new node\n",
    "                                 \n",
    "        # remove nodes to which the new node is already connected from the successors/predecessors list\n",
    "        successors = [n for n in successors if not n in succ_current_node]\n",
    "        predecessors = [n for n in predecessors if not n in pred_current_node]\n",
    "                                 \n",
    "        for node_to in successors:\n",
    "            G_in.add_edge(str(new_node), node_to) # add outgoing edges\n",
    "        for node_from in predecessors:\n",
    "            G_in.add_edge(node_from, str(new_node)) # add incoming edges\n",
    "            \n",
    "    print(\"number of edges after :\"+str(len(G_in.edges())))\n",
    "    return G_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of edges before :16631\n",
      "number of edges after :23790\n"
     ]
    }
   ],
   "source": [
    "G_random_node_additions_proportional_in_degree = random_node_additions_proportional_in_degree(G.copy(), True, True, 100, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rank</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>404</td>\n",
       "      <td>0.014269</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2475</td>\n",
       "      <td>0.014269</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2503</td>\n",
       "      <td>0.014269</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77</td>\n",
       "      <td>0.013138</td>\n",
       "      <td>146</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>195</td>\n",
       "      <td>0.011690</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rank  node     score  in edges  out edges\n",
       "1      404  0.014269        11          0\n",
       "2     2475  0.014269        11          8\n",
       "3     2503  0.014269        11         11\n",
       "4       77  0.013138       146          4\n",
       "5      195  0.011690       106          3"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_random_node_additions_proportional_in_degree = calc_pagerank(G_random_node_additions_proportional_in_degree)\n",
    "df_random_node_additions_proportional_in_degree = create_dataframe(pr_random_node_additions_proportional_in_degree,\n",
    "                                                             G_random_node_additions_proportional_in_degree)\n",
    "df_random_node_additions_proportional_in_degree.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is going to be an interesting analysis where a lot of our knowledge about the workings of PageRank is going to be combined with correlations found in the analysis of previous functions. Let us first evaluate what is happening in the function. An $n$ number of nodes are added by first selecting $k$ nodes at random, but proportional to their in degrees and we copy all its edges. And then we do the opposite and select at random one node that has a relatively low probability (acquired from its low relatively in-degree) and copy its node (inspired by the Edge Copying Model, Kleinberg et al.).\n",
    "\n",
    "We have seen in the analysis of function $D$ that in general, if we select nodes at random, but proportional to their in-degree, the average score and in-degree of this group is relatively higher than the the rest of the network when $n$ is large enough (guarrantees the insigniciance of cases where the score is affected by the number of outgoing links / score of the nodes).\n",
    "\n",
    "So if we select $k$ nodes at random, but proportional to their in-degree, there is a high chance that they have a relatively high score. The PageRank score of the new node $n$ is calculated using, among other things, the score of nodes of its incoming edges divided by the number of outgoing links of those nodes. So there is a high chance that the $n$ new nodes have also a relatively high score compared to the average in the original graph (before the addition). Note that in this case, $N$ has dropped, which also has an effect on the PageRank scores since the first term becomes smaller. Let's see whether this hypothesis holds up in the experimental evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001516"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_evolved_graph = set(df_random_node_additions_proportional_in_degree.node.values)\n",
    "added_nodes = pd.DataFrame(list(nodes_evolved_graph.difference(nodes_original_graph)))\n",
    "added_nodes = pd.merge(df_random_node_additions_proportional_in_degree, added_nodes, left_on = 'node', right_on = 0)\n",
    "avg_node_score_added_nodes = added_nodes[\"score\"].mean()\n",
    "round(avg_node_score_added_nodes, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000412\n",
      "ratio:  3.678615\n"
     ]
    }
   ],
   "source": [
    "print(round(avg_score_full_graph, 6))\n",
    "print(\"ratio: \", round(avg_node_score_added_nodes / avg_score_full_graph, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can indeed see that the scores of the average score is on average much higher than the average score in the original graph. Which is a correlation which seems to be in line with our hypothesis. Now another assumption is that the average PageRank has dropped, since we have added nodes that got incoming edges from nodes chosen at rando, but proportional to their in-degrees. This means that the nodes that were pointing to randomly selected nodes get more outgoing links, which affects the score of the selected nodes. Let's see if this is indeed the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new average score original network:  0.0003496978870114116\n",
      "ratio drop:  0.8483670738896557\n"
     ]
    }
   ],
   "source": [
    "check_new_score_original_nodes = pd.DataFrame(list(nodes_original_graph)) # omit new nodes, as this effects the results\n",
    "check_new_score_original_nodes = pd.merge(df_random_node_additions_proportional_in_degree, check_new_score_original_nodes,\n",
    "                                          left_on = 'node', right_on = 0)\n",
    "avg_score_orginal_nodes = check_new_score_original_nodes.score.mean()\n",
    "print(\"new average score original network: \", avg_score_orginal_nodes)\n",
    "print(\"ratio drop: \", avg_score_orginal_nodes / avg_score_full_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there are also othe factors which affect this drop (e.g. larger $N$ and backwards-propogation of changed scores), the PageRank scores of the nodes in the original network indeed seem to have taken a hit (no pun inteded/reference to next section)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G. Addition of nodes at random but proportional to the hubs/authorithy measures (HITS) of nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $n$ represent the number of nodes that should be added to the network. If the $number\\_of\\_nodes$ parameter is given then $n = number\\_of\\_nodes$, if this parameter is not specfied by the caller we have $n = \\lfloor(0.1 * total\\_number\\_of\\_nodes(G\\_in))\\rfloor)$\n",
    "\n",
    "For $n$ iterations do the following:\n",
    "* Make a new node instance $n$\n",
    "* with a probability distribution proportional to one of the HITS measures (hub- or authority value) of nodes pick $k$ nodes in the original graph\n",
    "* copy the incoming/outgoing edges of the $k$ nodes for $n$\n",
    "* Pick a node $l$ (at random) in the graph in the graph which had a relatively low probability (due to a low value) in the second step and repeat step 3 for this node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Edge Copying Model (slide 53 of Week6-SNA-Props)\n",
    "def random_node_additions_proportional_HITS(G_in, authority = False, number_given = False, number_of_nodes = 1, k = 5):\n",
    "    if (number_given & number_of_nodes < len(list(G_in))): # check if we do not remove too much nodes\n",
    "        n = number_of_nodes\n",
    "    else:\n",
    "        n = int(0.1 * len(list(G_in)))  # max 10% of nodes\n",
    "    print(\"number of edges before :\"+ str(len(G_in.edges())))\n",
    "    for _ in range(n):\n",
    "        #k is number of edges to be added, random integer 1 between 5\n",
    "        k = random.randint(1, k) #select k random vertices\n",
    "        list_of_nodes = list(G_in)  #create list of nodes\n",
    "        if (authority):\n",
    "            p = list(nx.hits(G_in)[0].values())\n",
    "        else: # hub\n",
    "            p = list(nx.hits(G_in)[1].values())\n",
    "        \n",
    "        k_random_selected_nodes = np.random.choice(list_of_nodes, size = k, p = p, replace = False) # selecte k nodes proportional to chosen measure\n",
    "        \n",
    "        new_node = nx.number_of_nodes(G_in) + 1 #add node to graph\n",
    "        G_in.add_node(str(new_node))\n",
    "        \n",
    "        for node in k_random_selected_nodes:\n",
    "            successors = list(G_in.successors(str(node)))\n",
    "            for node_to in successors:\n",
    "                G_in.add_edge(str(new_node), node_to) # add outgoing edges\n",
    "            predecessors = list(G_in.predecessors(str(node)))\n",
    "            for node_from in predecessors:\n",
    "                G_in.add_edge(node_from, str(new_node)) # add incoming edges\n",
    "        \n",
    "        # pick one node that has a low probability (relatively low number of incoming edges)\n",
    "        non_zero_probs = [i for i in p if i != 0.0]\n",
    "        highest_chance_nodes = np.random.choice(list_of_nodes, p = p, \n",
    "                                                size = (len(non_zero_probs) - 1), replace = False)\n",
    "        \n",
    "        node_to_add = random.sample(set(list_of_nodes).difference(set(highest_chance_nodes)), 1)[0] # low prob node\n",
    "        successors = list(G_in.successors(node_to_add)) # successors of the node\n",
    "        predecessors = list(G_in.predecessors(node_to_add)) # predecessors of the node \n",
    "        \n",
    "        succ_current_node = list(G_in.successors(str(new_node))) # find the successors of the new node \n",
    "        pred_current_node = list(G_in.predecessors(str(new_node))) # find the predecessors of the new node\n",
    "                                 \n",
    "        # remove nodes to which the new node is already connected from the successors/predecessors list\n",
    "        successors = [n for n in successors if not n in succ_current_node]\n",
    "        predecessors = [n for n in predecessors if not n in pred_current_node]\n",
    "                                 \n",
    "        for node_to in successors:\n",
    "            G_in.add_edge(str(new_node), node_to) # add outgoing edges\n",
    "        for node_from in predecessors:\n",
    "            G_in.add_edge(node_from, str(new_node)) # add incoming edges\n",
    "            \n",
    "    print(\"number of edges after :\"+str(len(G_in.edges())))\n",
    "    return G_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of edges before :16631\n",
      "number of edges after :24094\n"
     ]
    }
   ],
   "source": [
    "G_random_node_additions_proportional_authority = random_node_additions_proportional_HITS(G.copy(), True, True, 100, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rank</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>404</td>\n",
       "      <td>0.042265</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195</td>\n",
       "      <td>0.019706</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>0.018803</td>\n",
       "      <td>146</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>728</td>\n",
       "      <td>0.014965</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36</td>\n",
       "      <td>0.011123</td>\n",
       "      <td>191</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rank node     score  in edges  out edges\n",
       "1     404  0.042265        10          0\n",
       "2     195  0.019706        98          1\n",
       "3      77  0.018803       146          2\n",
       "4     728  0.014965        10          0\n",
       "5      36  0.011123       191          5"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_random_node_additions_proportional_authority = calc_pagerank(G_random_node_additions_proportional_authority)\n",
    "df_random_node_additions_proportional_authority = create_dataframe(pr_random_node_additions_proportional_authority, G_random_node_additions_proportional_authority)\n",
    "df_random_node_additions_proportional_authority.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We follow the same scheme as in the previous graph changin method.  An $n$ number of nodes are added by first selecting $k$ nodes at random, but proportional to their authority values (could also pick hub) and we copy all its edges. And then we do the opposite and select at random one node that has a relatively low probability (acquired from its low authority value) and copy its node (inspired by the Edge Copying Model, Kleinberg et al.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we copy the incoming edges of $n$ at random chosen nodes that were chosen proportionally to their authority values, we know that if we pick $n$ large enough, the average number of incoming edges of these $n$ nodes will be relatively high compared to the rest of the network, since a good authority (i.e. a relatively high authority value) represents a node that was linked by many different hubs. We, however, have to see whether the quality/scores of the nodes linking to the $m$ randomly chosen nodes are relatively high. If this is indeed the case we'll see a relatively high score of the added nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001516"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_evolved_graph = set(df_random_node_additions_proportional_authority.node.values)\n",
    "added_nodes = pd.DataFrame(list(nodes_evolved_graph.difference(nodes_original_graph)))\n",
    "added_nodes = pd.merge(df_random_node_additions_proportional_in_degree, added_nodes, left_on = 'node', right_on = 0)\n",
    "avg_node_score_added_nodes = added_nodes[\"score\"].mean()\n",
    "round(avg_node_score_added_nodes, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000412\n",
      "ratio:  3.678615\n"
     ]
    }
   ],
   "source": [
    "print(round(avg_score_full_graph, 6))\n",
    "print(\"ratio: \", round(avg_node_score_added_nodes / avg_score_full_graph, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And like with the nodes that were added that copied edges from nodes that were chosen at random but proportional to their in-degrees, we see that the usage of authority values lead to the same result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen various functions that changed the original graph $G$ by the addition and/or removal of nodes or edges. In some of these functions the eelction of the nodes or edges was done uniformly at random, while in other function it was done proportional to the node degree and other statistics. We have stated hypotheses about the nodes that were added/removed and have evaluated whether this actually happened in the experiments done with the functions using $G$. In addition, hypothesis were stated about the stability of the PageRank scores of the original nodes in $G$ when $G$ was changed according to stastical measures. We know have a rough idea of when PageRank scores will change siginificantly, and when not. This knowledge can be tested and exploited in the analysis of data of actual webpages on the Internet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More advanced evaluation methods of PageRank stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already seen several evaluation and assesments of the stability of the PageRank scores of the (orginal) graph. This next section is going to cover yet another evaluation method of the PageRank stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rank-based error\n",
    "In the analyses above the pagerank values of the different graph evolvement are compared, where only the absolute percentual change are chosen as comparison measure. For this paragraph, a more advanced method is implemented to evaluate the different evolvement on the original graph. The first measure to compare PageRank is rank-based error. For rank-based error, the error can be defined as: $$Error_{rank} = \\sum_{i=1}^{n} \\frac{|rank - rank_{baseline}|}{rank_{baseline}} $$\n",
    "\n",
    "where $rank$ is generated by the used method. Before this measure can be applied, for each function we create a new dataframe where we merge the rank score calculated on the original graph $G$ and the rank score of respectively function $A,B,C,D,E,F,G$.\n",
    "\n",
    "Before the results are analyzed, we state some hypothesis about the possible outcomes for different functions. When the difference between the new calculated rank and the original rank is high, the numerator $|rank - rank_{baseline}|$ will be high, and thus also the result of the fraction will be much higher. Therefore, the higher the $Error_{rank}$ is, the more the two graphs differ from eachother. When the highly connected nodes in the graph are have a large rank difference compared to the original graph $G$, this has a stronger effect on the outcome compared to nodes who already have a low score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_random_edges_uniform_random.rename(columns={'score': 'score_random_edges_uniform_random'}, inplace=True)\n",
    "df_random_edges_uniform_random.insert(1, 'rank_random_edges_uniform_random', range(1, 1+len(df_random_edges_uniform_random)))\n",
    "df_random_edges_uniform_random.drop(['in edges', 'out edges'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_origin.rename(columns={'score': 'score_original'}, inplace=True)\n",
    "df_origin.insert(1, 'rank_original', range(1, 1+len(df_origin))) #add rank score to dataframe, because first column 'rank'can't be accessed (actually is row number)\n",
    "df_origin.drop(['in edges', 'out edges'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_comparison_1 = pd.merge(df_random_edges_uniform_random, df_origin, on='node')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.9046458019944"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_error_based_1(row):\n",
    "    return abs(row['rank_random_edges_uniform_random'] - row['rank_original']) / row['rank_original'] \n",
    "\n",
    "df_comparison_1.apply(compute_error_based_1, axis = 1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Error_{edges-uniform-random} = 91$\n",
    "\n",
    "Function $A$ adds or removes edges from the graph uniformly at random. The function selects $k$ nodes uniformly at random, so each node in the graph has an equal probability to be chosen. For these $k$ nodes, edges are added or removed. Because it is most likely that nodes with a very low connectivity are chosen, these ranks will not much differ from the ranks in the original graph. The ranks of these nodes will not change much, because they already have a very low connectivity and adding new or removing edges from that node will not make a very large difference. Therefore the sum of all the errors is relatively low. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_random_add_edges_uniform_random.rename(columns={'score': 'score_random_add_edges_uniform_random'}, inplace=True)\n",
    "df_random_add_edges_uniform_random.insert(1, 'rank_random_add_edges_uniform_random', range(1, 1+len(df_random_add_edges_uniform_random)))\n",
    "df_random_add_edges_uniform_random.drop(['in edges', 'out edges'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126.56903995403896"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comparison_2 = pd.merge(df_origin, df_random_add_edges_uniform_random, on='node')\n",
    "def compute_error_based_2(row):\n",
    "    return abs(row['rank_random_add_edges_uniform_random'] - row['rank_original']) / row['rank_original'] \n",
    "\n",
    "df_comparison_2.apply(compute_error_based_2, axis = 1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Error_{edges-add-uniform-random} = 126$\n",
    "\n",
    "This error represents the error of a call to function $A$, where only edges are added. This score is higher than the score where edges are added and removed. This makes completely sense, because when edges are added (even when they are added uniformly at random), this will for most nodes increase the pagerank score. Therefore, for nodes that where previously had a very low connectivity, the pagerank increases because edges are edded to this node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_random_remove_edges_uniform_random.rename(columns={'score': 'score_random_remove_edges_uniform_random'}, inplace=True)\n",
    "df_random_remove_edges_uniform_random.insert(1, 'rank_random_remove_edges_uniform_random', range(1, 1+len(df_random_remove_edges_uniform_random)))\n",
    "df_random_remove_edges_uniform_random.drop(['in edges', 'out edges'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.02870932081097"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comparison_3 = pd.merge(df_origin, df_random_remove_edges_uniform_random, on='node')\n",
    "def compute_error_based_3(row):\n",
    "    return abs(row['rank_random_remove_edges_uniform_random'] - row['rank_original']) / row['rank_original'] \n",
    "\n",
    "df_comparison_3.apply(compute_error_based_3, axis = 1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Error_{edges-remove-uniform-random} = 62$\n",
    "\n",
    "The error of the graph where only edges are removed, uniformly at random, the rank of the nodes will most likely decrease. The result value of 62 completely makes sense, because it is lower than the error value when edges are added or removed and much lower than the error when only edges are added. The $k$ random edges that are selected uniformly at random, are most likely the nodes with a low connectivity. Therefore, the chance that the probability of these nodes will most likely decrease. The error value confirms this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_random_add_nodes_uniform.rename(columns={'score': 'score_random_add_nodes_uniform'}, inplace=True)\n",
    "df_random_add_nodes_uniform.insert(1, 'rank_random_add_nodes_uniform', range(1, 1+len(df_random_add_nodes_uniform)))\n",
    "df_random_add_nodes_uniform.drop(['in edges', 'out edges'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161.7265425973618"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comparison_4 = pd.merge(df_origin, df_random_add_nodes_uniform, on='node')\n",
    "def compute_error_based_4(row):\n",
    "    return abs(row['rank_random_add_nodes_uniform'] - row['rank_original']) / row['rank_original'] \n",
    "\n",
    "df_comparison_4.apply(compute_error_based_4, axis = 1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Error_{nodes-add-uniform-random} = 162$\n",
    "\n",
    "This function only adds nodes, uniformly at random. This value is somewhat higher than the previous error values. The function copies the incoming/outgoing edges of the  $k$  nodes for each $n$ node that we want to add. The error value is higher compared to the error values above, most likely because we add only nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random_removal_nodes_uniform.rename(columns={'score': 'score_random_removal_nodes_uniform'}, inplace=True)\n",
    "df_random_removal_nodes_uniform.insert(1, 'rank_random_removal_nodes_uniform', range(1, 1+len(df_random_removal_nodes_uniform)))\n",
    "df_random_removal_nodes_uniform.drop(['in edges', 'out edges'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162.86777979600367"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comparison_5 = pd.merge(df_origin, df_random_removal_nodes_uniform, on='node')\n",
    "def compute_error_based_5(row):\n",
    "    return abs(row['rank_random_removal_nodes_uniform'] - row['rank_original']) / row['rank_original'] \n",
    "\n",
    "df_comparison_5.apply(compute_error_based_5, axis = 1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Error_{nodes-removal-uniform-random} = 163$\n",
    "\n",
    "This function removes $k$ selected nodes uniformly at random. Again, each node in the graph has an equal probability to be chosen, so it's very likely that nodes are removed which have a very low connectivity and thus ranking. This value equals the error value when only nodes are added. We expect that this error value is lower than the error values that we will see for the next functions ($D,E,F,G$). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for function D-E-F-G:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_random_node_removals_proportional_indegree.rename(columns={'score': 'score_random_node_removals_proportional_indegree'}, inplace=True)\n",
    "df_random_node_removals_proportional_indegree.insert(1, 'rank_random_node_removals_proportional_indegree', range(1, 1+len(df_random_node_removals_proportional_indegree)))\n",
    "df_random_node_removals_proportional_indegree.drop(['in edges', 'out edges'], axis=1, inplace = True)\n",
    "df_comparison_6 = pd.merge(df_origin, df_random_node_removals_proportional_indegree, on='node')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "271.4626450197574"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_error_based_6(row):\n",
    "    return abs(row['rank_random_node_removals_proportional_indegree'] - row['rank_original']) / row['rank_original'] \n",
    "df_comparison_6.apply(compute_error_based_6, axis = 1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Error_{nodes-removal-proportional-indegree} = 271$\n",
    "\n",
    "Function $D$ removes nodes randomly, but proportional to the indegree. As the analysis at function $D$ already explained, when we remove nodes proportional to the indegree, the pagerank scores of the highly connected nodes are affected. This is because the algorithm will most likely select the nodes with a very high connectivity, because these nodes have a larger probability to be chosen. The $Error_{nodes-removal-proportional-indegree}$ indeed confirms this. Because lots of nodes are removed with a very high indegree, the pagerank of these nodes are also negatively affected. Therefore this error value is much higher than the ones we saw in previous cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_random_node_removals_proportional_authority.rename(columns={'score': 'score_random_node_removals_proportional_authority'}, inplace=True)\n",
    "df_random_node_removals_proportional_authority.insert(1, 'rank_random_node_removals_proportional_authority', range(1, 1+len(df_random_node_removals_proportional_authority)))\n",
    "df_random_node_removals_proportional_authority.drop(['in edges', 'out edges'], axis=1, inplace = True)\n",
    "df_comparison_7 = pd.merge(df_origin, df_random_node_removals_proportional_authority, on='node')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272.91082920081425"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_error_based_7(row):\n",
    "    return abs(row['rank_random_node_removals_proportional_authority'] - row['rank_original']) / row['rank_original'] \n",
    "df_comparison_7.apply(compute_error_based_7, axis = 1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Error_{nodes-removal-proportional-authority} = 273$\n",
    "\n",
    "This function removes nodes at random, but proportional to the authorithy values of the nodes. This means that nodes with a higher authority value will have a higher chance of being removed. In other words, nodes that were referred to by many other hubs (i.e. incoming edges) will have had a higher chance of being removed. We have seen earlier on that the in general (dependending on the explained pecularities), the average PageRank scores of nodes (when  nn  is large enough) will be higher than the average PageRank score in the original graph, when the nodes are removed at random but proportional to this measure. This error value confirms this. The error based value is very high, so this means that a lot of high connected \"important\" nodes are removed from the original graph.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_random_node_additions_proportional_in_degree.rename(columns={'score': 'score_random_node_additions_proportional_in_degree'}, inplace=True)\n",
    "df_random_node_additions_proportional_in_degree.insert(1, 'rank_random_node_additions_proportional_in_degree', range(1, 1+len(df_random_node_additions_proportional_in_degree)))\n",
    "df_random_node_additions_proportional_in_degree.drop(['in edges', 'out edges'], axis=1, inplace = True)\n",
    "df_comparison_8 = pd.merge(df_origin, df_random_node_additions_proportional_in_degree, on='node')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "463.95732855882574"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_error_based_8(row):\n",
    "    return abs(row['rank_random_node_additions_proportional_in_degree'] - row['rank_original']) / row['rank_original'] \n",
    "df_comparison_8.apply(compute_error_based_8, axis = 1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Error_{nodes-addition-proportional-indegree} = 464$\n",
    "\n",
    "Function $F$ selects $k$ nodes at random, but proportional to their in-degree. Therefore, there is a high chance that they have a relatively high score. The PageRank score of the new node  $n$  is calculated using, the score of nodes of its incoming edges divided by the number of outgoing links of those nodes. Therefore it is very likely that  new nodes have also a relatively high score compared to the average in the original graph (before the addition). We see that this error is very large, compared to the ones that we saw earlier. This is because we add nodes, that were not in the original graph. Also these nodes have a very large value, and therefore sum of the error values will increase enormously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_random_node_additions_proportional_authority.rename(columns={'score': 'score_random_node_additions_proportional_authority'}, inplace=True)\n",
    "df_random_node_additions_proportional_authority.insert(1, 'rank_random_node_additions_proportional_authority', range(1, 1+len(df_random_node_additions_proportional_authority)))\n",
    "df_random_node_additions_proportional_authority.drop(['in edges', 'out edges'], axis=1, inplace = True)\n",
    "df_comparison_9 = pd.merge(df_origin, df_random_node_additions_proportional_authority, on='node')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299.33725054497114"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_error_based_9(row):\n",
    "    return abs(row['rank_random_node_additions_proportional_authority'] - row['rank_original']) / row['rank_original'] \n",
    "df_comparison_9.apply(compute_error_based_9, axis = 1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Error_{nodes-addition-proportional-authority} = 299$\n",
    "\n",
    "Function $G$ adds nodes at random, but proportional to their authority value. As concluded in the analysis of the results of function $G$, the nodes we add have a relatively high score. This will increase the value based error, because also the score of some other nodes increase. The value of $Error_{nodes-addition-proportional-authority}$ indeed confirms this. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
