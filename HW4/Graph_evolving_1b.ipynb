{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: PageRank Stability on Evolving Graphs\n",
    "## Graph evolution and PageRank values comparison\n",
    "### Joris & Abdel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and general set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load edge list and create a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fh = open(\"canvas/hamster.edgelist\", 'rb')\n",
    "G = nx.read_edgelist(fh, create_using=nx.DiGraph())\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(98)\n",
    "random.seed(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_pagerank(G_in, alpha = 0.85):\n",
    "    return nx.pagerank(G_in, alpha=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pr_origin = calc_pagerank(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_dataframe(pr, G_in):\n",
    "    df_edge_in = pd.DataFrame(list(G_in.in_degree()), columns=['node', 'in edges'])\n",
    "    df_edge_out = pd.DataFrame(list(G_in.out_degree()), columns=['node', 'out edges'])\n",
    "    df_rank = pd.DataFrame(list(pr.items()), columns=['node', 'score']).sort_values(by=['score'], ascending=False)\n",
    "    df_temp = pd.merge(df_rank, df_edge_in, on='node')\n",
    "    df_total = pd.merge(df_temp, df_edge_out, on='node')\n",
    "    df_total.index = df_total.index + 1\n",
    "    df_total.columns.name = 'rank'\n",
    "    return df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rank</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>404</td>\n",
       "      <td>0.042793</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195</td>\n",
       "      <td>0.019961</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>0.018628</td>\n",
       "      <td>121</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>728</td>\n",
       "      <td>0.015530</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36</td>\n",
       "      <td>0.011117</td>\n",
       "      <td>168</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rank node     score  in edges  out edges\n",
       "1     404  0.042793        10          0\n",
       "2     195  0.019961        80          1\n",
       "3      77  0.018628       121          2\n",
       "4     728  0.015530        10          0\n",
       "5      36  0.011117       168          5"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_origin = create_dataframe(pr_origin, G)\n",
    "df_origin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like node 404 is the best ranked page, following by 195 and 77. This means that these pages should be shown at the top by search engines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">To do: Update the PageRank value calculation and analysis in this notebook with the extended/corrected/completed <i>(this still needs to be done)</i> version of the notebook of 1a</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b. Graph Evolution and Pagerank values comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section the effects of graph evolutions are going to be studied in relation to an evaluation of the stability of PageRank. In particular, various methodologies are going to be devised and exploited in which graphical represesentations of a social network are going to be altered by the removal and/or addition of nodes and edges in these graphs. The original graph $G$, represents a social network of friendships and familylinks between users of the website <a>hamsterster.com</a>. Various functions which make it possible to change this graph are going to be given and explained. Some of these functions focus on the addition or removal of edges, while other focus on nodes. Some of these functions are going to do make choices at random, while others are also going to exploit randomness, but proporotional to the node degree and other statistics. The choice is made to analyze the effects of the functions which evolve the graphs on the original graph $G$. So the evaluation of the various functions which add/remove graphs is going to be done starting from the full and original graph $G$ for each of the given functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Note: A social network would naturally be described with an undirected graph. The social network data is, however, treated as a combination of target and source id's which faciliate the usage of this data as a directed graph for the sake of implementing and testing graph evolutions methods to evaluate the stability of PageRank. No implications or conclusions should be directly related to the actual structure of the social networks of the website</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Removing and adding edges uniformly at random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $n$ number of nodes do the following:\n",
    "* select 1 node uniformly at random\n",
    "* add or remove an incoming/outgoing at random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add/remove edges for all the nodes uniformly at random\n",
    "def random_edges_uniform_random(G_in, number_of_nodes = 1):\n",
    "    list_of_nodes = list(G_in) # all the nodes\n",
    "    # select uniformly at random nodes of which we are going to add/remove edges\n",
    "    selected_nodes = list(np.random.choice(list_of_nodes, size = number_of_nodes, replace = False)) # default probability p is an uniform distribution\n",
    "    \n",
    "    for node in selected_nodes: \n",
    "        successors = list(G_in.successors(str(node))) # find the successors of this nodes\n",
    "        predecessors = list(G_in.predecessors(str(node))) # find the predecessors of this node\n",
    "        #find candidates for new edges\n",
    "        unconnected_to = [n for n in list(G_in.nodes()) if not n in successors] # no outgoing edge to these nodes\n",
    "        unconnected_from = [n for n in list(G_in.nodes()) if not n in predecessors] # no incoming edge from these nodes\n",
    "        \n",
    "        add = bool(random.getrandbits(1)) # randomly add or remove an edge of this node\n",
    "        incoming =  bool(random.getrandbits(1)) # randomly add an outgoing/incoming edge\n",
    "        if(add): # add an incoming/outgoing edge to node\n",
    "            if(incoming): # add incoming edge\n",
    "                if len(unconnected_from): #only add when unconnected_from is not empty\n",
    "                    new = random.choice(unconnected_from)\n",
    "                    G_in.add_edge(new, node)\n",
    "                    print(\"\\tnew edge:\\t {} --> {}\".format(new, node))\n",
    "                    unconnected_from.remove(new)\n",
    "                    predecessors.append(new)\n",
    "            else: # add outgoing edge:\n",
    "                if len(unconnected_to): #only add when unconnected_to is not empty\n",
    "                    new = random.choice(unconnected_to)\n",
    "                    G_in.add_edge(node, new)\n",
    "                    print(\"\\tnew edge:\\t {} --> {}\".format(node, new))\n",
    "                    unconnected_to.remove(new)    \n",
    "                    successors.append(new)\n",
    "        else: # remove\n",
    "            if(incoming): # remove incoming edge\n",
    "                if len(predecessors): #only remove when predecessors is not empty\n",
    "                    new = random.choice(predecessors)\n",
    "                    G_in.remove_edge(new, node)\n",
    "                    print(\"\\tremove edge:\\t {} --> {}\".format(new, node))\n",
    "                    predecessors.remove(new)\n",
    "                    unconnected_from.append(new)\n",
    "            else: # remove outgoing edge:\n",
    "                if len(successors): #only remove when successors is not empty\n",
    "                    new = random.choice(successors)\n",
    "                    G_in.remove_edge(node, new)\n",
    "                    print(\"\\tremove edge:\\t {} --> {}\".format(node, new))\n",
    "                    successors.remove(new)    \n",
    "                    unconnected_to.append(new)\n",
    "    return G_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tremove edge:\t 1612 --> 817\n",
      "\tremove edge:\t 301 --> 303\n",
      "\tnew edge:\t 709 --> 1036\n",
      "\tnew edge:\t 1653 --> 2179\n",
      "\tnew edge:\t 2207 --> 1376\n",
      "\tremove edge:\t 2412 --> 2413\n",
      "\tremove edge:\t 648 --> 845\n",
      "\tnew edge:\t 889 --> 909\n",
      "\tnew edge:\t 1532 --> 2107\n",
      "\tnew edge:\t 541 --> 877\n",
      "\tremove edge:\t 2384 --> 2354\n",
      "\tremove edge:\t 2248 --> 305\n",
      "\tremove edge:\t 522 --> 523\n",
      "\tremove edge:\t 1887 --> 1889\n",
      "\tremove edge:\t 697 --> 728\n",
      "\tremove edge:\t 1801 --> 308\n",
      "\tnew edge:\t 2192 --> 1863\n",
      "\tremove edge:\t 1631 --> 1638\n",
      "\tnew edge:\t 2328 --> 1903\n",
      "\tnew edge:\t 1292 --> 1467\n",
      "\tremove edge:\t 1300 --> 249\n",
      "\tnew edge:\t 1810 --> 717\n",
      "\tnew edge:\t 728 --> 1889\n",
      "\tnew edge:\t 721 --> 1112\n",
      "\tremove edge:\t 1123 --> 421\n",
      "\tremove edge:\t 37 --> 60\n",
      "\tnew edge:\t 1234 --> 333\n",
      "\tnew edge:\t 189 --> 359\n",
      "\tremove edge:\t 1724 --> 1725\n",
      "\tremove edge:\t 964 --> 967\n",
      "\tnew edge:\t 1934 --> 825\n",
      "\tnew edge:\t 227 --> 460\n",
      "\tnew edge:\t 2049 --> 1817\n",
      "\tremove edge:\t 470 --> 958\n",
      "\tnew edge:\t 522 --> 736\n",
      "\tremove edge:\t 2094 --> 303\n",
      "\tremove edge:\t 54 --> 121\n",
      "\tremove edge:\t 830 --> 838\n",
      "\tnew edge:\t 1673 --> 1975\n",
      "\tremove edge:\t 1409 --> 1410\n",
      "\tremove edge:\t 588 --> 589\n",
      "\tnew edge:\t 1800 --> 1680\n",
      "\tremove edge:\t 1673 --> 1674\n",
      "\tnew edge:\t 1308 --> 1503\n",
      "\tnew edge:\t 1062 --> 959\n",
      "\tnew edge:\t 1987 --> 482\n",
      "\tnew edge:\t 1580 --> 77\n",
      "\tremove edge:\t 1246 --> 1247\n",
      "\tremove edge:\t 78 --> 165\n",
      "\tremove edge:\t 1283 --> 1285\n",
      "\tremove edge:\t 539 --> 19\n",
      "\tremove edge:\t 1574 --> 613\n",
      "\tnew edge:\t 436 --> 762\n",
      "\tnew edge:\t 836 --> 1539\n",
      "\tnew edge:\t 1633 --> 2255\n",
      "\tnew edge:\t 955 --> 943\n",
      "\tremove edge:\t 574 --> 13\n",
      "\tnew edge:\t 1275 --> 1024\n",
      "\tremove edge:\t 1738 --> 63\n",
      "\tnew edge:\t 2197 --> 896\n",
      "\tnew edge:\t 1025 --> 877\n",
      "\tremove edge:\t 1377 --> 1379\n",
      "\tnew edge:\t 329 --> 1855\n",
      "\tnew edge:\t 1448 --> 1730\n",
      "\tnew edge:\t 1052 --> 849\n",
      "\tremove edge:\t 1610 --> 1611\n",
      "\tnew edge:\t 1314 --> 1578\n",
      "\tnew edge:\t 1027 --> 2186\n",
      "\tnew edge:\t 941 --> 1770\n",
      "\tnew edge:\t 1410 --> 1678\n",
      "\tnew edge:\t 658 --> 440\n",
      "\tremove edge:\t 2280 --> 197\n",
      "\tnew edge:\t 1803 --> 2038\n",
      "\tremove edge:\t 138 --> 33\n",
      "\tnew edge:\t 2145 --> 1420\n",
      "\tremove edge:\t 2408 --> 2409\n",
      "\tnew edge:\t 792 --> 1808\n",
      "\tnew edge:\t 704 --> 1329\n",
      "\tnew edge:\t 1071 --> 678\n",
      "\tnew edge:\t 2397 --> 950\n",
      "\tremove edge:\t 1294 --> 1295\n",
      "\tnew edge:\t 1310 --> 15\n",
      "\tremove edge:\t 1933 --> 2154\n",
      "\tremove edge:\t 890 --> 892\n",
      "\tnew edge:\t 686 --> 1671\n",
      "\tnew edge:\t 1821 --> 385\n",
      "\tnew edge:\t 741 --> 1117\n",
      "\tnew edge:\t 1708 --> 1613\n",
      "\tremove edge:\t 1499 --> 1500\n",
      "\tremove edge:\t 2416 --> 2417\n",
      "\tnew edge:\t 866 --> 1270\n",
      "\tremove edge:\t 1697 --> 1698\n",
      "\tnew edge:\t 524 --> 1711\n",
      "\tremove edge:\t 740 --> 741\n",
      "\tnew edge:\t 2414 --> 637\n",
      "\tnew edge:\t 926 --> 797\n"
     ]
    }
   ],
   "source": [
    "G_random_edges_uniform_random = random_edges_uniform_random(G.copy(), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rank</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>404</td>\n",
       "      <td>0.042988</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195</td>\n",
       "      <td>0.020129</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>0.018712</td>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>0.011565</td>\n",
       "      <td>168</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>192</td>\n",
       "      <td>0.009662</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rank node     score  in edges  out edges\n",
       "1     404  0.042988        10          0\n",
       "2     195  0.020129        80          1\n",
       "3      77  0.018712       122          2\n",
       "4      36  0.011565       168          5\n",
       "5     192  0.009662        57          3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_random_edges_uniform_random = calc_pagerank(G_random_edges_uniform_random)\n",
    "df_random_edges_uniform_random = create_dataframe(pr_random_edges_uniform_random, G_random_edges_uniform_random)\n",
    "df_random_edges_uniform_random.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Adding nodes uniformly at random (copying model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $n$ iterations do the following:\n",
    "* Make a new node instance $n$\n",
    "* with a uniform random distribution pick $k$ nodes in the original graph\n",
    "* copy the incoming/outgoing edges of the $k$ nodes for $n$\n",
    "* choose with an unifrom distribution another node $l$ and add its edges also to $n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>The last step might seem redundant at the moment, but later when the the $k$ nodes are going to be chosen with at random but proportional to a certain statistic, it makes sense to have a step in which you pick another node $l$ that is chosen with the opposite property so that the generation/stability of communities is ensured (i.e. power-law degree). In this implementation. This step is omitted, but it will be thus added in the functions that take statistical measures into consideration when choosing nodes at random</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#randomly add and remove nodes\n",
    "#Edge Copying Model (slide 53 of Week6-SNA-Props)\n",
    "def random_add_nodes_uniform(G_in, number_of_nodes = 1, k = 5):\n",
    "    print(\"number of edges before :\"+ str(len(G_in.edges())))\n",
    "    for _ in range(number_of_nodes):\n",
    "        #k is number of edges to be added, random integer 1 between 5\n",
    "        k = random.randint(1, k) #select k random vertices\n",
    "        #print(\"k = \" + str(k))\n",
    "        new_node = nx.number_of_nodes(G_in) + 1 #add node to graph\n",
    "        # print(\"new node = \" + str(new_node))\n",
    "        \n",
    "        list_of_nodes = list(G_in)  #create list of nodes\n",
    "        \n",
    "        G_in.add_node(str(new_node))   \n",
    "        k_random_selected_nodes = np.random.choice(list_of_nodes, size = k, replace = False) # k nodes with a uniform distribution\n",
    "        \n",
    "        for node in k_random_selected_nodes:\n",
    "            #print(\"node in k_random_selected_nodes = \" + str(node))\n",
    "            successors = list(G_in.successors(str(node)))\n",
    "            #print(\"succesors are \" + str(successors))\n",
    "            for node_to in successors:\n",
    "                G_in.add_edge(new_node, node_to) # add outgoing edges\n",
    "            predecessors = list(G_in.predecessors(str(node)))\n",
    "            for node_from in predecessors:\n",
    "                G_in.add_edge(node_from, new_node) # add incoming edges\n",
    "    print(\"number of edges after :\"+str(len(G_in.edges())))\n",
    "    return G_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of edges before :16631\n",
      "number of edges after :17882\n"
     ]
    }
   ],
   "source": [
    "G_random_add_nodes_uniform = random_add_nodes_uniform(G.copy(), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rank</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>404</td>\n",
       "      <td>0.040974</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195</td>\n",
       "      <td>0.019240</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>0.018008</td>\n",
       "      <td>124</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>728</td>\n",
       "      <td>0.015021</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>135</td>\n",
       "      <td>0.010939</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rank node     score  in edges  out edges\n",
       "1     404  0.040974        10          0\n",
       "2     195  0.019240        82          1\n",
       "3      77  0.018008       124          2\n",
       "4     728  0.015021        10          0\n",
       "5     135  0.010939        53          8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_random_add_nodes_uniform = calc_pagerank(G_random_add_nodes_uniform)\n",
    "df_random_add_nodes_uniform = create_dataframe(pr_random_add_nodes_uniform, G_random_add_nodes_uniform)\n",
    "df_random_add_nodes_uniform.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Removal of nodes uniformly at random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $n$ represent the number of nodes that should be removed. If the $number\\_of\\_nodes$ parameter is givem then $n = number\\_of\\_nodes$, if this parameter is not specfied by the caller we have $n = \\lfloor(0.1 * total\\_number\\_of\\_nodes(G\\_in))\\rfloor)$\n",
    "\n",
    "For $n$ iterations do the following:\n",
    "* Select a node $m$ uniformly at random (iterations are abstracted by $np.random.choice$)\n",
    "* Remove this node and its respective edges from the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_removal_nodes_uniform(G_in, number_given = False, number_of_nodes = None):\n",
    "    if (number_given & number_of_nodes < len(list(G_in))): # check if we do not remove too much nodes\n",
    "        n = number_of_nodes\n",
    "    else:\n",
    "        n = int(0.1 * len(list(G_in)))  # max 10% of nodes\n",
    "    #remove nodes and corresponding edges\n",
    "    print(\"number of nodes before :\"+ str(len(list(G_in))))\n",
    "    list_of_nodes = list(G_in)\n",
    "    selected_nodes = np.random.choice(list_of_nodes, size = n, replace = False)\n",
    "    for m_remove in selected_nodes:\n",
    "        G_in.remove_node(m_remove)\n",
    "    print(\"number of nodes after :\"+ str(len(list(G_in))))\n",
    "    return G_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes before :2426\n",
      "number of nodes after :2326\n"
     ]
    }
   ],
   "source": [
    "G_random_removal_nodes_uniform = random_removal_nodes_uniform(G.copy(), True, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rank</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>404</td>\n",
       "      <td>0.042501</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195</td>\n",
       "      <td>0.020760</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>0.019746</td>\n",
       "      <td>117</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>728</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36</td>\n",
       "      <td>0.011739</td>\n",
       "      <td>167</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rank node     score  in edges  out edges\n",
       "1     404  0.042501         9          0\n",
       "2     195  0.020760        78          1\n",
       "3      77  0.019746       117          2\n",
       "4     728  0.017544        10          0\n",
       "5      36  0.011739       167          5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_random_removal_nodes_uniform = calc_pagerank(G_random_removal_nodes_uniform)\n",
    "df_random_removal_nodes_uniform = create_dataframe(pr_random_removal_nodes_uniform, G_random_removal_nodes_uniform)\n",
    "df_random_removal_nodes_uniform.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph evolution methodologies using statistical measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Removal of nodes at random but proportional to the degree of the nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $n$ represent the number of nodes that should be removed. If the $number\\_of\\_nodes$ parameter is givem then $n = number\\_of\\_nodes$, if this parameter is not specfied by the caller we have $n = \\lfloor(0.1 * total\\_number\\_of\\_nodes(G\\_in))\\rfloor)$\n",
    "\n",
    "For $n$ iterations do the following:\n",
    "* Select a node $m$ at random, but proportional to the in degree's of the nodes (iterations are abstracted by $np.random.choice$)\n",
    "* Remove this node and its respective edges from the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_node_removals_proportional_degree(G_in, number_given = False, number_of_nodes = None, in_degree = True):\n",
    "    if (number_given & number_of_nodes < len(list(G_in))): # check if we do not remove too much nodes\n",
    "        n = number_of_nodes\n",
    "    else:\n",
    "        n = int(0.1 * len(list(G_in)))  # max 10% of nodes\n",
    "    #remove nodes and corresponding edges\n",
    "    print(\"number of nodes before :\"+ str(len(list(G_in))))\n",
    "    list_of_nodes = list(G_in)\n",
    "    if (in_degree):\n",
    "        degrees = dict(G_in.in_degree()).values() # in_degrees of all the nodes\n",
    "    else: # out_degree\n",
    "        degrees = dict(G_in.out_degree()).values() # in_degrees of all the nodes\n",
    "    prob_degree = [float(i)/sum(degrees) for i in degrees] # probabilities proportional to degree\n",
    "    \n",
    "    selected_nodes = np.random.choice(list_of_nodes, size = n, replace = False, p = prob_degree)\n",
    "    for m_remove in selected_nodes:\n",
    "        G_in.remove_node(m_remove)\n",
    "    print(\"number of nodes after :\"+ str(len(list(G_in))))\n",
    "    return G_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes before :2426\n",
      "number of nodes after :2326\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rank</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>404</td>\n",
       "      <td>0.032206</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>728</td>\n",
       "      <td>0.020527</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>0.013388</td>\n",
       "      <td>122</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>181</td>\n",
       "      <td>0.012316</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>126</td>\n",
       "      <td>0.012174</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rank node     score  in edges  out edges\n",
       "1     404  0.032206         8          0\n",
       "2     728  0.020527        10          0\n",
       "3      34  0.013388       122          4\n",
       "4     181  0.012316        87         10\n",
       "5     126  0.012174        45          1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_random_node_removals_proportional_indegree = random_node_removals_proportional_degree(G.copy(), True, 100, True)\n",
    "pr_random_node_removals_proportional_indegree = calc_pagerank(G_random_node_removals_proportional_indegree)\n",
    "df_random_node_removals_proportional_indegree = create_dataframe(pr_random_node_removals_proportional_indegree,\n",
    "                                                                 G_random_node_removals_proportional_indegree)\n",
    "df_random_node_removals_proportional_indegree.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the hundred nodes that are actually removed by the algorithm. The assumption is that the average in-degree of these 100 nodes is higher than the average node degree of the original graph $G$ since the nodes are removed at random, but proportional to their in-degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.855317, 5.036543)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_node_degree_full_graph = df_origin[\"in edges\"].mean()\n",
    "avg_node_degree_graph_removed_nodes = df_random_node_removals_proportional_indegree[\"in edges\"].mean()\n",
    "round(avg_node_degree_full_graph, 6), round(avg_node_degree_graph_removed_nodes, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the average node in-degree dropped significantly, we can indeed conclude that the function removed nodes at random, but proportional to their node degrees since th drop in the average node degree of all the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_original_graph = set(df_origin.node.values)\n",
    "nodes_evolved_graph = set(df_random_node_removals_proportional_indegree.node.values)\n",
    "removed_nodes = pd.DataFrame(list(nodes_original_graph.difference(nodes_evolved_graph)))\n",
    "removed_nodes = pd.merge(df_origin, removed_nodes, left_on = 'node', right_on = 0)\n",
    "avg_node_degree_removed_nodes = removed_nodes[\"in edges\"].mean()\n",
    "avg_node_degree_removed_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as already confirmed in the previous cell we can indeed conclude that the nodes that are removed have a significant higher node in-degree (on-average) than the average of the nodes in the original graph. We can thus indeed conclude that the function removed nodes at random, but proportional to their node degrees since th drop in the average node degree of all the nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our knowledge of the inner-workings of PageRank to state hyptothesis about the changes of PageRank of the (nodes in the) evolved graph, compared to the original graph. We know that the PageRank score of a node is influenced by the number (the set) of incoming edges, the number of outbound links of the source nodes of these edges and the score of the particular source nodes. In addition, the damping factor is used in the calculations, but this is kept the same in this PageRank stability analysis so will be left out of consideration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at what has happened to the PageRank scores after the removal of nodes at random, but proportional to the in-degree. As we have seen earlier, the nodes that were removed had on average, a much higher in-degree. Considering the PageRank formula, there is a high chance that nodes with a high number of incoming edges have a relatively high score. But this is affected by the quality of the nodes sourcing the incoming edge. In other words, even if a certain node $n_1$ has a high number of incoming edges than a node $n_2$, but the nodes connected to $n_2$ (have an outgoing edge to $n_2$ have relatively less outgoing links and a relatively higher score, it could be that the score of $n_2$ is higher than $n_1$.\n",
    "\n",
    "Let's assess whether the nodes that were removed with a relaltively high in-degree compared to the rest of the nodes, have had a negative effect on the average score of the nodes in the graph. Considering the elabaroation that is given in the previous paragraph, this is affected by the number of outgoing links of the nodes that had an edge to the removed nodes and the score of these nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.001643, 0.000412, 3.99)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_score_removed_nodes = removed_nodes.score.mean()\n",
    "avg_score_full_graph = df_origin.score.mean()\n",
    "round(avg_score_removed_nodes, 6), round(avg_score_full_graph, 6), round(avg_score_removed_nodes / avg_score_full_graph, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the the nodes that were removed indeed have a higher score (see factor) than the average score in the original graph of all the nodes.The nodes that had an outgoing edge to the nodes that were removed thus did not have such high number of total outgoing links that it affected the score of the removed nodes in such a way that the average score is not higher than that of the average node in the original graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at what happens with the PageRank scores when we remove nodes at random, but proportional to their out-degrees. When you look at the formula of PageRank, you see that an edge from a node with a lot of outoging links will make no significant contribution to the score of the particular node (when compared to a node of the same score with less outgoing links). The assumption is, therefore, that unlike in the previous case, the average PageRank score in the graph in which nodes are removed, will hardly differ from the average PageRank score in the original graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes before :2426\n",
      "number of nodes after :2326\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rank</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>404</td>\n",
       "      <td>0.043407</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195</td>\n",
       "      <td>0.020449</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>108</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>728</td>\n",
       "      <td>0.015592</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36</td>\n",
       "      <td>0.011427</td>\n",
       "      <td>151</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rank node     score  in edges  out edges\n",
       "1     404  0.043407        10          0\n",
       "2     195  0.020449        73          1\n",
       "3      77  0.018800       108          2\n",
       "4     728  0.015592        10          0\n",
       "5      36  0.011427       151          5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_random_node_removals_proportional_outdegree = random_node_removals_proportional_degree(G.copy(), True, 100, False)\n",
    "pr_random_node_removals_proportional_outdegree = calc_pagerank(G_random_node_removals_proportional_outdegree)\n",
    "df_random_node_removals_proportional_outdegree = create_dataframe(pr_random_node_removals_proportional_outdegree,\n",
    "                                                                 G_random_node_removals_proportional_outdegree)\n",
    "df_random_node_removals_proportional_outdegree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0004299226139295095, 0.00041220115416324565, 1.04)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_score_graph_removed_nodes = df_random_node_removals_proportional_outdegree.score.mean()\n",
    "avg_score_full_graph = df_origin.score.mean()\n",
    "avg_score_graph_removed_nodes, avg_score_full_graph, round(avg_score_graph_removed_nodes / avg_score_full_graph, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And indeed, there is no significant differences in the average PageRank scores of the full network when removing nodes at random, but proportional to the out degree of the nodes (i.e. nodes with a higher out-degree have a higher probability to be removed at random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Removal of nodes at random but proportional to the hubs/authorithy measures (HITS) of nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $n$ represent the number of nodes that should be removed. If the $number\\_of\\_nodes$ parameter is givem then $n = number\\_of\\_nodes$, if this parameter is not specfied by the caller we have $n = \\lfloor(0.1 * total\\_number\\_of\\_nodes(G\\_in))\\rfloor)$\n",
    "\n",
    "For $n$ iterations do the following:\n",
    "* Select a node $m$ at random, but proportional to HITS measures (i.e. hub or authority) of the nodes (iterations are abstracted by $np.random.choice$)\n",
    "* Remove this node and its respective edges from the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_node_removals_proportional_HITS(G_in, authorithy = False, number_given = False, number_of_nodes = None):\n",
    "    print(\"number of nodes before: \" + str(len(list(G_in))))\n",
    "    if (number_given & number_of_nodes < len(list(G_in))): # check if we do not remove too much nodes\n",
    "        n = number_of_nodes\n",
    "    else:\n",
    "        n = int(0.1 * len(list(G_in)))  # max 10% of nodes\n",
    "    #remove nodes and corresponding edges\n",
    "    for i in range(0, n):\n",
    "        list_of_nodes = list(G_in)\n",
    "        #print(int((i / n) * 100), \"%\") # progress (nx.hits(Graph) takes some time depending on the graph size)\n",
    "        if (authorithy):\n",
    "            p = list(nx.hits(G_in)[1].values()) # probabilities proportional to authority of nodes\n",
    "        else: # hub\n",
    "            p = list(nx.hits(G_in)[0].values()) # probabilities proportional to hub of nodes\n",
    "        node_remove = np.random.choice(list_of_nodes, p = p)\n",
    "        G_in.remove_node(node_remove)\n",
    "    print(\"number of nodes after: \" + str(len(list(G_in))))\n",
    "    return G_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes before: 2426\n",
      "number of nodes after: 2326\n"
     ]
    }
   ],
   "source": [
    "G_random_node_removals_proportional_authority = random_node_removals_proportional_HITS(G.copy(), True, True, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rank</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>404</td>\n",
       "      <td>0.029291</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77</td>\n",
       "      <td>0.016805</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>728</td>\n",
       "      <td>0.016235</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>923</td>\n",
       "      <td>0.013499</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>899</td>\n",
       "      <td>0.012292</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rank node     score  in edges  out edges\n",
       "1     404  0.029291         7          0\n",
       "2      77  0.016805        94          1\n",
       "3     728  0.016235         9          0\n",
       "4     923  0.013499         6          0\n",
       "5     899  0.012292         8          0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_random_node_removals_proportional_authority = calc_pagerank(G_random_node_removals_proportional_authority)\n",
    "df_random_node_removals_proportional_authority = create_dataframe(pr_random_node_removals_proportional_authority,\n",
    "                                                             G_random_node_removals_proportional_authority)\n",
    "df_random_node_removals_proportional_authority.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be a rather interesting analysis of the PageRank algorithm and its stability. Note that the previous function removes nodes at random, but proportional to algorithms acquired from the HITS algorithm. In particular, the funtion removes nodes at random proportional to their $hub$ or $authorithy$ values. Why is this interesting one may ask. A good hub reprresents a page (node) that points to many other pages, while a good authority represents a page that was linked by many different hubs. So there is definitely a relation between the HITS measures and the PageRank scores. While we could explain this relation in more detail, it is more fun to show this relation with evaluations of the node removals according to the HITS measurs, considering the avaialability of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The node removal of 100 nodes that was just executed was at random, but proportional to the authorithy values of the nodes. This means that nodes with a higher authority value will have a higher chance of being removed. In other words, nodes that were referred to by many other hubs (i.e. incoming edges) will have had a higher chance of being removed. We have seen earlier on that the in general (dependending on the explained pecularities), the average PageRank scores of nodes (when $n$ is large enough) will be higher than the average PageRank score in the original graph, when the nodes are removed at random but proportional to this measure. Let's see of the function does what it should do and whether this is indeed the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.855317, 5.088994)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_node_degree_graph_removed_nodes = df_random_node_removals_proportional_authority[\"in edges\"].mean()\n",
    "round(avg_node_degree_full_graph, 6), round(avg_node_degree_graph_removed_nodes, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, note that it seems that that function indeed removed nodes at random but proportional to the authority values since the average in-degree value has dropped significantly after removal of the nodes. Which makes sense since the authority is an indication of how many pages (i.e. nodes in our context) linked to that particular node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_evolved_graph = set(df_random_node_removals_proportional_authority.node.values)\n",
    "removed_nodes = pd.DataFrame(list(nodes_original_graph.difference(nodes_evolved_graph)))\n",
    "removed_nodes = pd.merge(df_origin, removed_nodes, left_on = 'node', right_on = 0)\n",
    "avg_node_degree_removed_nodes = removed_nodes[\"in edges\"].mean()\n",
    "avg_node_degree_removed_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And note once again that the average in degree is much higher than the average in degree of the original graph. The function does what it should do. There is a strong relation with the previous analyis due to the strong relation between the HITS measures and the in/out-degrees of the nodes. We have shown that some statistics lead to the same conclusion. Let's devise an other method to evaluate the stability of the PageRank values after removal of the nodes according to their hub values. Remember, a good hub reprresents a page (node) that points to many other pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes before: 2426\n",
      "number of nodes after: 2326\n"
     ]
    }
   ],
   "source": [
    "G_random_node_removals_proportional_hub = random_node_removals_proportional_HITS(G.copy(), False, True, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rank</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>404</td>\n",
       "      <td>0.041081</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195</td>\n",
       "      <td>0.019682</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>0.017496</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>728</td>\n",
       "      <td>0.016139</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36</td>\n",
       "      <td>0.011072</td>\n",
       "      <td>137</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rank node     score  in edges  out edges\n",
       "1     404  0.041081        10          0\n",
       "2     195  0.019682        72          1\n",
       "3      77  0.017496       107          2\n",
       "4     728  0.016139        10          0\n",
       "5      36  0.011072       137          5"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_random_node_removals_proportional_hub = calc_pagerank(G_random_node_removals_proportional_hub)\n",
    "df_random_node_removals_proportional_hub = create_dataframe(pr_random_node_removals_proportional_hub,\n",
    "                                                             G_random_node_removals_proportional_hub)\n",
    "df_random_node_removals_proportional_hub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like with the removal of nodes proportional to the out-degree (at random), the assumption is that removal of nodes proportional to their hub values, will have no significant effect on the PageRank values of the nodes in the the graph of the nodes that remain in the graph. We are, however, going to show this with a different method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the absolute change of the PageRank scores of the nodes that remain in the graph, once nodes are removed at random but proportional to their hub values. The hypothesis is already stated, let's see whether it holds up. We are going to form  a new DataFrame in which we have the new and old PageRank scores (i.e. before and after removal). And then going to add a new column with the %-change of the PageRank scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_random_node_removals_proportional_hub.rename(columns = {'score': 'new_score', 'in edges': 'new_in_edges',\n",
    "                                                           'out edges': 'new_out_edges'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rank</th>\n",
       "      <th>node</th>\n",
       "      <th>new_score</th>\n",
       "      <th>new_in_edges</th>\n",
       "      <th>new_out_edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>404</td>\n",
       "      <td>0.041081</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195</td>\n",
       "      <td>0.019682</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>0.017496</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>728</td>\n",
       "      <td>0.016139</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36</td>\n",
       "      <td>0.011072</td>\n",
       "      <td>137</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rank node  new_score  new_in_edges  new_out_edges\n",
       "1     404   0.041081            10              0\n",
       "2     195   0.019682            72              1\n",
       "3      77   0.017496           107              2\n",
       "4     728   0.016139            10              0\n",
       "5      36   0.011072           137              5"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_random_node_removals_proportional_hub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10:  2.9011196235737113 \n",
      "top 50:  5.342112970287124 \n",
      "top 100:  8.706663303998335 \n",
      "whole graph:  8.077092153256247\n"
     ]
    }
   ],
   "source": [
    "df_compare_scores = pd.merge(df_random_node_removals_proportional_hub, df_origin, on = 'node')\n",
    "df_compare_scores[\"percentage_change\"] = df_compare_scores.apply(lambda row: ((row.new_score - row.score) / row.score) * 100, axis = 1)\n",
    "df_compare_scores[\"abs_percentage_change\"] = df_compare_scores.apply(lambda row: abs(row.percentage_change), axis = 1)\n",
    "print(\"top 10: \", df_compare_scores.head(10).abs_percentage_change.mean(),\n",
    "      \"\\ntop 50: \", df_compare_scores.head(50).abs_percentage_change.mean(), \n",
    "      \"\\ntop 100: \", df_compare_scores.head(100).abs_percentage_change.mean(), \n",
    "      \"\\nwhole graph: \", df_compare_scores.abs_percentage_change.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First note that the average change of the PageRank scores in the graph is not significant (single digit point percentage change), but what is even more interesting and scientifically interesting and explainable, is the fact that the change of the scores is on average less for nodes that had already a relatively high score to begin with. This can be seen in the previous print statement, we see that the average change of the scores (in point percentage) seems to be correlated with the original score of the node. Note that in addition, the number of total pages is reduced by 100 ($N$ in the PageRank) formula, which also has an effect on the new scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give a simplified explanation of the PageRank explanation (left out some assumptions such as no outbound edges = edge to all other nodes (pages) in the graph) let's have a look what is happening more or less under the hood. We have $PRs(n) = \\dfrac{1 - d}{N} + d \\cdot \\sum_{m \\, \\in \\, predecessors(n)} \\dfrac{PRs(m)}{\\mid\\,successors(m)\\,\\mid}$, <br>\n",
    "where $N =$ the number of pages (reduced by 100), $d$ is the damping factor (remained constant) and the notation $\\mid\\,successors(m)\\,\\mid$ is used to denote the <i>number</i> of successors of node $m$ (i.e. the number of outgoing edges of node $m$). So even if a node is not directly affected by removal of nodes (i.e. it keeps its edges as the nodes that were removed had no direct connection to it), its score will still change due to the fact that $N$ has changed and the fact that the score, or the number of outgoing edges of its predecessors could have changed. These are the things to take into consideration when looking at the changes and the statement that a single percentage change is not large for removal of 100 nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now back to the interesting correlation. It can be explained quite simply. Let us have a node $x$ with a relatively high PageRank score. If we would remove one its predecessors $y$ with a high number of outgoing edges (as is the case with the random removal of nodes proportional to the value of the hub measure), its effect on the score of node $x$ would not be significant or as high as the removal of a node $z$ with a relatively low amount of outgoing edges compared to $y$ but with the same score, its effect will be less significant as the number of outgoing edges is the denominator in the summation. And the contribtion of this node to the total sum of all the PageRank scores divided by the number of successors, of the predecessors would be small to begin with. This is a possible explanation (there can be other causes) of the correlation that has been shown. So in removal of nodes proportional to the hub values we have seen some interesting evaulations of the stability of the PageRank scores of the nodes in the graph. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. Addition of nodes at random but proportional to the degree of the nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $n$ represent the number of nodes that should be added to the network. If the $number\\_of\\_nodes$ parameter is given then $n = number\\_of\\_nodes$, if this parameter is not specfied by the caller we have $n = \\lfloor(0.1 * total\\_number\\_of\\_nodes(G\\_in))\\rfloor)$\n",
    "\n",
    "For $n$ iterations do the following:\n",
    "* Make a new node instance $n$\n",
    "* with a probability distribution proportional to the in-degree of nodes pick $k$ nodes in the original graph\n",
    "* copy the incoming/outgoing edges of the $k$ nodes for $n$\n",
    "* Pick a node $l$ (at random) in the graph in the graph which had a relatively low probability in the second step and repeat step 3 for this node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.str_"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.random.choice(list(G), size = 5, replace = False)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inspired by the Edge Copying Model (slide 53 of Week6-SNA-Props)\n",
    "def random_node_additions_proportional_in_degree(G_in, number_given = False, in_degree = True, number_of_nodes = 1, k = 5):\n",
    "    if (number_given & number_of_nodes < len(list(G_in))): # check if we do not remove too much nodes\n",
    "        n = number_of_nodes\n",
    "    else:\n",
    "        n = int(0.1 * len(list(G_in)))  # max 10% of nodes\n",
    "    print(\"number of edges before :\"+ str(len(G_in.edges())))\n",
    "    for i in range(n):\n",
    "        #k is number of edges to be added, random integer 1 between 5\n",
    "        k = random.randint(1, k) #select k random vertices\n",
    "        list_of_nodes = list(G_in)  #create list of nodes\n",
    "        if (in_degree):\n",
    "            degrees = dict(G_in.in_degree()).values() # in_degrees of all the nodes\n",
    "        else: # out-degree\n",
    "            degrees = dict(G_in.out_degree()).values() # out_degrees of all the nodes\n",
    "        prob_degree = [float(i)/sum(degrees) for i in degrees] # probabilities proportional to degree\n",
    "        k_random_selected_nodes = np.random.choice(list_of_nodes, size = k, p = prob_degree, replace = False) # selecte k nodes proportional to chosen measure\n",
    "        \n",
    "        new_node = nx.number_of_nodes(G_in) + 1 #add node to graph\n",
    "        G_in.add_node(str(new_node))\n",
    "        \n",
    "        for node in k_random_selected_nodes:\n",
    "            successors = list(G_in.successors(str(node)))\n",
    "            for node_to in successors:\n",
    "                G_in.add_edge(str(new_node), node_to) # add outgoing edges\n",
    "            predecessors = list(G_in.predecessors(str(node)))\n",
    "            for node_from in predecessors:\n",
    "                G_in.add_edge(node_from, str(new_node)) # add incoming edges\n",
    "        \n",
    "        # pick one node that has a low probability (relatively low number of incoming edges)\n",
    "        non_zero_probs = [i for i in prob_degree if i != 0.0]\n",
    "        highest_chance_nodes = np.random.choice(list_of_nodes, p = prob_degree, \n",
    "                                                size = (len(non_zero_probs) - 1), replace = False)\n",
    "        \n",
    "        node_to_add = str(random.sample(set(list_of_nodes).difference(set(highest_chance_nodes)), 1)[0]) # low prob node\n",
    "        successors = list(G_in.successors(node_to_add)) # successors of the node\n",
    "        predecessors = list(G_in.predecessors(node_to_add)) # predecessors of the node \n",
    "        \n",
    "        succ_current_node = list(G_in.successors(str(new_node))) # find the successors of the new node \n",
    "        pred_current_node = list(G_in.predecessors(str(new_node))) # find the predecessors of the new node\n",
    "                                 \n",
    "        # remove nodes to which the new node is already connected from the successors/predecessors list\n",
    "        successors = [n for n in successors if not n in succ_current_node]\n",
    "        predecessors = [n for n in predecessors if not n in pred_current_node]\n",
    "                                 \n",
    "        for node_to in successors:\n",
    "            G_in.add_edge(str(new_node), node_to) # add outgoing edges\n",
    "        for node_from in predecessors:\n",
    "            G_in.add_edge(node_from, str(new_node)) # add incoming edges\n",
    "            \n",
    "    print(\"number of edges after :\"+str(len(G_in.edges())))\n",
    "    return G_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of edges before :16631\n",
      "number of edges after :23960\n"
     ]
    }
   ],
   "source": [
    "G_random_node_additions_proportional_in_degree = random_node_additions_proportional_in_degree(G.copy(), True, True, 100, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rank</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>404</td>\n",
       "      <td>0.025541</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>728</td>\n",
       "      <td>0.012130</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195</td>\n",
       "      <td>0.010145</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2484</td>\n",
       "      <td>0.010145</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2452</td>\n",
       "      <td>0.009196</td>\n",
       "      <td>161</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rank  node     score  in edges  out edges\n",
       "1      404  0.025541        17          0\n",
       "2      728  0.012130        12          0\n",
       "3      195  0.010145       103          1\n",
       "4     2484  0.010145       103          3\n",
       "5     2452  0.009196       161         15"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_random_node_additions_proportional_in_degree = calc_pagerank(G_random_node_additions_proportional_in_degree)\n",
    "df_random_node_additions_proportional_in_degree = create_dataframe(pr_random_node_additions_proportional_in_degree,\n",
    "                                                             G_random_node_additions_proportional_in_degree)\n",
    "df_random_node_additions_proportional_in_degree.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is going to be an interesting analysis where a lot of our knowledge about the workings of PageRank is going to be combined with correlations found in the analysis of previous functions. Let us first evaluate what is happening in the function. An $n$ number of nodes are added by first selecting $k$ nodes at random, but proportional to their in degrees and we copy all its edges. And then we do the opposite and select at random one node that has a relatively low probability (acquired from its low relatively in-degree) and copy its node (inspired by the Edge Copying Model, Kleinberg et al.).\n",
    "\n",
    "We have seen in the analysis of function $D$ that in general, if we select nodes at random, but proportional to their in-degree, the average score and in-degree of this group is relatively higher than the the rest of the network when $n$ is large enough (guarrantees the insigniciance of cases where the score is affected by the number of outgoing links / score of the nodes).\n",
    "\n",
    "So if we select $k$ nodes at random, but proportional to their in-degree, there is a high chance that they have a relatively high score. The PageRank score of the new node $n$ is calculated using, among other things, the score of nodes of its incoming edges divided by the number of outgoing links of those nodes. So there is a high chance that the $n$ new nodes have also a relatively high score compared to the average in the original graph (before the addition). Note that in this case, $N$ has dropped, which also has an effect on the PageRank scores since the first term becomes smaller. Let's see whether this hypothesis holds up in the experimental evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001649"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_evolved_graph = set(df_random_node_additions_proportional_in_degree.node.values)\n",
    "added_nodes = pd.DataFrame(list(nodes_evolved_graph.difference(nodes_original_graph)))\n",
    "added_nodes = pd.merge(df_random_node_additions_proportional_in_degree, added_nodes, left_on = 'node', right_on = 0)\n",
    "avg_node_score_added_nodes = added_nodes[\"score\"].mean()\n",
    "round(avg_node_score_added_nodes, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000412\n",
      "ratio:  4.00093\n"
     ]
    }
   ],
   "source": [
    "print(round(avg_score_full_graph, 6))\n",
    "print(\"ratio: \", round(avg_node_score_added_nodes / avg_score_full_graph, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can indeed see that the scores of the average score is on average much higher than the average score in the original graph. Which is a correlation which seems to be in line with our hypothesis. Now another assumption is that the average PageRank has dropped, since we have added nodes that got incoming edges from nodes chosen at rando, but proportional to their in-degrees. This means that the nodes that were pointing to randomly selected nodes get more outgoing links, which affects the score of the selected nodes. Let's see if this is indeed the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new average score original network:  0.0003442214381636475\n",
      "ratio drop:  0.8350812089849804\n"
     ]
    }
   ],
   "source": [
    "check_new_score_original_nodes = pd.DataFrame(list(nodes_original_graph)) # omit new nodes, as this effects the results\n",
    "check_new_score_original_nodes = pd.merge(df_random_node_additions_proportional_in_degree, check_new_score_original_nodes,\n",
    "                                          left_on = 'node', right_on = 0)\n",
    "avg_score_orginal_nodes = check_new_score_original_nodes.score.mean()\n",
    "print(\"new average score original network: \", avg_score_orginal_nodes)\n",
    "print(\"ratio drop: \", avg_score_orginal_nodes / avg_score_full_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there are also othe factors which affect this drop (e.g. larger $N$ and backwards-propogation of changed scores), the PageRank scores of the nodes in the original network indeed seem to have taken a hit (no pun inteded/reference to next section)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G. Addition of nodes at random but proportional to the hubs/authorithy measures (HITS) of nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $n$ represent the number of nodes that should be added to the network. If the $number\\_of\\_nodes$ parameter is given then $n = number\\_of\\_nodes$, if this parameter is not specfied by the caller we have $n = \\lfloor(0.1 * total\\_number\\_of\\_nodes(G\\_in))\\rfloor)$\n",
    "\n",
    "For $n$ iterations do the following:\n",
    "* Make a new node instance $n$\n",
    "* with a probability distribution proportional to one of the HITS measures (hub- or authority value) of nodes pick $k$ nodes in the original graph\n",
    "* copy the incoming/outgoing edges of the $k$ nodes for $n$\n",
    "* Pick a node $l$ (at random) in the graph in the graph which had a relatively low probability (due to a low value) in the second step and repeat step 3 for this node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Edge Copying Model (slide 53 of Week6-SNA-Props)\n",
    "def random_node_additions_proportional_HITS(G_in, authority = False, number_given = False, number_of_nodes = 1, k = 5):\n",
    "    if (number_given & number_of_nodes < len(list(G_in))): # check if we do not remove too much nodes\n",
    "        n = number_of_nodes\n",
    "    else:\n",
    "        n = int(0.1 * len(list(G_in)))  # max 10% of nodes\n",
    "    print(\"number of edges before :\"+ str(len(G_in.edges())))\n",
    "    for _ in range(n):\n",
    "        #k is number of edges to be added, random integer 1 between 5\n",
    "        k = random.randint(1, k) #select k random vertices\n",
    "        list_of_nodes = list(G_in)  #create list of nodes\n",
    "        if (authority):\n",
    "            p = list(nx.hits(G_in)[0].values())\n",
    "        else: # hub\n",
    "            p = list(nx.hits(G_in)[1].values())\n",
    "        \n",
    "        k_random_selected_nodes = np.random.choice(list_of_nodes, size = k, p = p, replace = False) # selecte k nodes proportional to chosen measure\n",
    "        \n",
    "        new_node = nx.number_of_nodes(G_in) + 1 #add node to graph\n",
    "        G_in.add_node(str(new_node))\n",
    "        \n",
    "        for node in k_random_selected_nodes:\n",
    "            successors = list(G_in.successors(str(node)))\n",
    "            for node_to in successors:\n",
    "                G_in.add_edge(str(new_node), node_to) # add outgoing edges\n",
    "            predecessors = list(G_in.predecessors(str(node)))\n",
    "            for node_from in predecessors:\n",
    "                G_in.add_edge(node_from, str(new_node)) # add incoming edges\n",
    "        \n",
    "        # pick one node that has a low probability (relatively low number of incoming edges)\n",
    "        non_zero_probs = [i for i in p if i != 0.0]\n",
    "        highest_chance_nodes = np.random.choice(list_of_nodes, p = p, \n",
    "                                                size = (len(non_zero_probs) - 1), replace = False)\n",
    "        \n",
    "        node_to_add = random.sample(set(list_of_nodes).difference(set(highest_chance_nodes)), 1)[0] # low prob node\n",
    "        successors = list(G_in.successors(node_to_add)) # successors of the node\n",
    "        predecessors = list(G_in.predecessors(node_to_add)) # predecessors of the node \n",
    "        \n",
    "        succ_current_node = list(G_in.successors(str(new_node))) # find the successors of the new node \n",
    "        pred_current_node = list(G_in.predecessors(str(new_node))) # find the predecessors of the new node\n",
    "                                 \n",
    "        # remove nodes to which the new node is already connected from the successors/predecessors list\n",
    "        successors = [n for n in successors if not n in succ_current_node]\n",
    "        predecessors = [n for n in predecessors if not n in pred_current_node]\n",
    "                                 \n",
    "        for node_to in successors:\n",
    "            G_in.add_edge(str(new_node), node_to) # add outgoing edges\n",
    "        for node_from in predecessors:\n",
    "            G_in.add_edge(node_from, str(new_node)) # add incoming edges\n",
    "            \n",
    "    print(\"number of edges after :\"+str(len(G_in.edges())))\n",
    "    return G_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of edges before :16631\n",
      "number of edges after :21239\n"
     ]
    }
   ],
   "source": [
    "G_random_node_additions_proportional_authority = random_node_additions_proportional_HITS(G.copy(), True, True, 100, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rank</th>\n",
       "      <th>node</th>\n",
       "      <th>score</th>\n",
       "      <th>in edges</th>\n",
       "      <th>out edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>404</td>\n",
       "      <td>0.040836</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195</td>\n",
       "      <td>0.020556</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>0.018731</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>728</td>\n",
       "      <td>0.015167</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36</td>\n",
       "      <td>0.011156</td>\n",
       "      <td>189</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rank node     score  in edges  out edges\n",
       "1     404  0.040836        10          0\n",
       "2     195  0.020556       100          1\n",
       "3      77  0.018731       150          2\n",
       "4     728  0.015167        10          0\n",
       "5      36  0.011156       189          6"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_random_node_additions_proportional_authority = calc_pagerank(G_random_node_additions_proportional_authority)\n",
    "df_random_node_additions_proportional_authority = create_dataframe(pr_random_node_additions_proportional_authority, G_random_node_additions_proportional_authority)\n",
    "df_random_node_additions_proportional_authority.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We follow the same scheme as in the previous graph changin method.  An $n$ number of nodes are added by first selecting $k$ nodes at random, but proportional to their authority values (could also pick hub) and we copy all its edges. And then we do the opposite and select at random one node that has a relatively low probability (acquired from its low authority value) and copy its node (inspired by the Edge Copying Model, Kleinberg et al.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we copy the incoming edges of $n$ at random chosen nodes that were chosen proportionally to their authority values, we know that if we pick $n$ large enough, the average number of incoming edges of these $n$ nodes will be relatively high compared to the rest of the network, since a good authority (i.e. a relatively high authority value) represents a node that was linked by many different hubs. We, however, have to see whether the quality/scores of the nodes linking to the $m$ randomly chosen nodes are relatively high. If this is indeed the case we'll see a relatively high score of the added nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001649"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_evolved_graph = set(df_random_node_additions_proportional_authority.node.values)\n",
    "added_nodes = pd.DataFrame(list(nodes_evolved_graph.difference(nodes_original_graph)))\n",
    "added_nodes = pd.merge(df_random_node_additions_proportional_in_degree, added_nodes, left_on = 'node', right_on = 0)\n",
    "avg_node_score_added_nodes = added_nodes[\"score\"].mean()\n",
    "round(avg_node_score_added_nodes, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000412\n",
      "ratio:  4.00093\n"
     ]
    }
   ],
   "source": [
    "print(round(avg_score_full_graph, 6))\n",
    "print(\"ratio: \", round(avg_node_score_added_nodes / avg_score_full_graph, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And like with the nodes that were added that copied edges from nodes that were chosen at random but proportional to their in-degrees, we see that the usage of authority values lead to the same result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen various functions that changed the original graph $G$ by the addition and/or removal of nodes or edges. In some of these functions the eelction of the nodes or edges was done uniformly at random, while in other function it was done proportional to the node degree and other statistics. We have stated hypotheses about the nodes that were added/removed and have evaluated whether this actually happened in the experiments done with the functions using $G$. In addition, hypothesis were stated about the stability of the PageRank scores of the original nodes in $G$ when $G$ was changed according to stastical measures. We know have a rough idea of when PageRank scores will change siginificantly, and when not. This knowledge can be tested and exploited in the analysis of data of actual webpages on the Internet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
