{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Temporal Pagerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pagerank is a method to rank pages by their importance based on how pages link to eachother. PageRank is defined by a steady state of which implies that the underlying network needs to be fixed and static. In previous sections we solved this problem by taking all the edges over a timespan as the static state. This however wasn't the best approach since short lived edges would have the same influence on the pagerank as long lived edges. In addition to that it also ignored time specific influence of edges on the pagerank. To solve this problem Polina Rozenshtein and Aristides Gionis created a temporal pagerank algorithm. This algorithm is a generalization of PageRank for temporal networks. By highlighting the actual information flow in the network, this temporal pagerank algorithm captures more accurately the network dynamics. More information about the temporal pagerank can be found here: https://users.ics.aalto.fi/gionis/temporal-pagerank.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we are going to run this temporal pagerank algorithm on the wiki dataset and compare it to the findings generated by the static pagerank in previous sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import networkx as nx\n",
    "import community as cm\n",
    "import copy\n",
    "import os.path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by reformating our data. For temporal pagerank we only require the time on which the edge originally arrived. Therefore we can remove the time where the edge gets removed from our data. We store the data in a .txt file so it can be loaded by the temporal-pagerank API which we got from: https://github.com/polinapolina/temporal-pagerank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_table(\"./data/tgraph_real_wikiedithyperlinks.txt\", header = None, sep = \" \", names = [\"src\", \"trg\", \"start\", \"end\"])\n",
    "df['start'] = pd.to_datetime(df['start'], unit = 's') #convert Unix timestamps to date time, utc = 0\n",
    "df['start'] = df['start'].astype('str') \n",
    "del df['end']\n",
    "df_ord = df[['start', 'src', 'trg']]\n",
    "np.savetxt('./data/wike_temporal_pr.txt', df_ord.values, fmt=['%s', '%d', '%d'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define some utility methods imported from https://github.com/polinapolina/temporal-pagerank:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From https://github.com/polinapolina/temporal-pagerank/edit/master/allutils/graph_generator.py\n",
    "def getToy():\n",
    "    G = nx.DiGraph()\n",
    "    G.add_edges_from([(1,2,{'weight': 1.0}), (3,2, {'weight': 1.0})])\n",
    "    nrm = float(sum(G.degree(weight = 'weight').values()))\n",
    "    for i in G.edges(data=True):\n",
    "        G[i[0]][i[1]]['weight'] = i[-1]['weight']/nrm\n",
    "    return G\n",
    "\n",
    "# From https://github.com/polinapolina/temporal-pagerank/edit/master/allutils/graph_generator.py\n",
    "def getSubgraph(G, N = 1000):\n",
    "    Gcc = sorted(nx.connected_component_subgraphs(G.to_undirected()), key = len, reverse=True)\n",
    "    nodes = set()\n",
    "    i = 0\n",
    "\n",
    "    while len(nodes) < N:\n",
    "        s = np.random.choice(Gcc[i].nodes())\n",
    "        i += 1\n",
    "        nodes.add(s)\n",
    "        for edge in nx.bfs_edges(G.to_undirected(), s):\n",
    "            nodes.add(edge[1])\n",
    "            if len(nodes) == N:\n",
    "                break\n",
    "    return G.subgraph(nodes)\n",
    "\n",
    "# From https://github.com/polinapolina/temporal-pagerank/edit/master/allutils/graph_generator.py\n",
    "def getGraph(edgesTS):\n",
    "    G = nx.DiGraph()\n",
    "    edges = {}\n",
    "    for item in edgesTS:\n",
    "        edge = item[1]\n",
    "        edges[edge] = edges.get(edge, 0.0) + 1.0\n",
    "    G.add_edges_from([(k[0],k[1], {'weight': v}) for k,v in edges.items()])\n",
    "    return G\n",
    "\n",
    "# From https://github.com/polinapolina/temporal-pagerank/edit/master/allutils/graph_generator.py\n",
    "# (Modified to suit our needs)\n",
    "def readRealGraph(filepath):\n",
    "    edgesTS = []\n",
    "    nodes = set()\n",
    "    edges = set()\n",
    "    lookup = {}\n",
    "    c = 0\n",
    "    with open(filepath,'r') as fd:\n",
    "        for line in fd.readlines():\n",
    "            line = line.strip()\n",
    "            items = line.split(' ')\n",
    "            tstamp = ' '.join(items[0 : 2])\n",
    "            tstamp = datetime.strptime(tstamp, '%Y-%m-%d %H:%M:%S')\n",
    "            t = items[2 : 4]\n",
    "            if t[0] == t[1]:\n",
    "                continue\n",
    "            if tuple(t) in lookup.keys():\n",
    "                num = lookup[tuple(t)]\n",
    "            else:\n",
    "                num = c\n",
    "                lookup[tuple(t)] = c\n",
    "                c += 1\n",
    "            edgesTS.append((tstamp, tuple(t), num ))\n",
    "            nodes.add(t[0])\n",
    "            nodes.add(t[1])\n",
    "            edges.add(tuple([t[0],t[1]]))\n",
    "    fd.close()\n",
    "    return edgesTS, nodes, edges\n",
    "\n",
    "# From https://github.com/polinapolina/temporal-pagerank/edit/master/allutils/graph_generator.py\n",
    "# (Modified to suit our needs)\n",
    "def weighted_DiGraph(n, path, seed = 1.0, weights='random'):\n",
    "    edgesTS, _, _ = readRealGraph(path)\n",
    "    G = getGraph(edgesTS)\n",
    "    G = nx.DiGraph(G)\n",
    "    G.remove_edges_from(G.selfloop_edges())\n",
    "    G = getSubgraph(G, n)\n",
    "    for i in G.nodes():\n",
    "        if G.out_degree(i) == 0:\n",
    "            for j in G.nodes():\n",
    "                if i != j:\n",
    "                    G.add_edge(i, j, weight=1.0)\n",
    "    if weights == 'random':\n",
    "        w = np.random.uniform(1e-5, 1.0, G.number_of_edges())\n",
    "        w /= sum(w)\n",
    "        c = 0\n",
    "        for i in G.edges():\n",
    "            G[i[0]][i[1]]['weight'] = w[c]\n",
    "            c += 1\n",
    "    elif weights == 'uniform':\n",
    "        w = 1.0/G.number_of_edges()\n",
    "        for i in G.edges():\n",
    "            G[i[0]][i[1]]['weight'] = w\n",
    "    else:\n",
    "        nrm = float(sum(G.out_degree(weight = 'weight').values()))\n",
    "        for i in G.edges(data=True):\n",
    "            G[i[0]][i[1]]['weight'] = i[-1]['weight']/nrm\n",
    "    return G\n",
    "\n",
    "# From https://github.com/polinapolina/temporal-pagerank/edit/master/allutils/graph_generator.py\n",
    "def change_weights(G):\n",
    "    #w = np.random.uniform(1e-5, 1.0, G.number_of_edges())\n",
    "    w = np.random.uniform(0.0, 1.0, G.number_of_edges())\n",
    "    w /= sum(w)\n",
    "    c = 0\n",
    "    for i in G.edges():\n",
    "        G[i[0]][i[1]]['weight'] = w[c]\n",
    "        c += 1\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The page rank algorithm imported from https://github.com/polinapolina/temporal-pagerank:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flowPR(p_prime_nodes, ref_pr, stream, RS, current, iters = 1000000, alpha = 0.85, beta=0.001, gamma=0.9999, normalization = 1.0, padding = 0):\n",
    "    if beta == 1.0:\n",
    "        beta = 0.0\n",
    "        \n",
    "    tau = []\n",
    "    pearson = []\n",
    "    spearman = []\n",
    "    error = []\n",
    "    x = []\n",
    "    i = 0\n",
    "\n",
    "    rank_order = [key for (key, value) in sorted(ref_pr.items(), key=operator.itemgetter(1), reverse=True)]\n",
    "    ordered_pr = np.array([ref_pr[k] for k in rank_order])\n",
    "\n",
    "    for e in stream:\n",
    "        i += 1\n",
    "\n",
    "        RS[e[0]] = RS.get(e[0], 0.0) * gamma + 1.0 * (1.0 - alpha) * p_prime_nodes[e[0]] * normalization\n",
    "        RS[e[1]] = RS.get(e[1], 0.0) * gamma + (current.get(e[0], 0.0) + 1.0 * (1.0 - alpha) * p_prime_nodes[e[0]]) * alpha * normalization\n",
    "        current[e[1]] = current.get(e[1], 0.0) + (current.get(e[0], 0.0) + 1.0 * (1.0 - alpha)* p_prime_nodes[e[0]]) * alpha * (1 - beta)\n",
    "        current[e[0]] = current.get(e[0], 0.0) * beta\n",
    "\n",
    "\n",
    "        if (i % 100 == 0 or i == len(stream)) and len(RS) == len(ordered_pr):\n",
    "            sorted_RS4 = np.array([RS[k] / sum(RS.values()) for k in rank_order])\n",
    "            tau.append(scipy.stats.kendalltau(sorted_RS4, ordered_pr)[0])\n",
    "            pearson.append(scipy.stats.pearsonr(sorted_RS4, ordered_pr)[0])\n",
    "            spearman.append(scipy.stats.spearmanr(sorted_RS4, ordered_pr)[0])\n",
    "            error.append(np.linalg.norm(sorted_RS4 - ordered_pr))\n",
    "            x.append(i+padding)\n",
    "\n",
    "    sorted_RS4 = np.array([RS[k] / sum(RS.values()) for k in rank_order])\n",
    "\n",
    "    return RS, current, tau, spearman, pearson, error, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the pagerank with the code segments from https://github.com/polinapolina/temporal-pagerank:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NetworkXError",
     "evalue": "SubGraph Views are readonly. Mutations not allowed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNetworkXError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-82b37661b520>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'random'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweighted_DiGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./data/wike_temporal_pr.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;31m#nodes = G.nodes()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-51-76861d50c8c8>\u001b[0m in \u001b[0;36mweighted_DiGraph\u001b[1;34m(n, path, seed, weights)\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m                     \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_edge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'random'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1e-5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber_of_edges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\networkx\\classes\\coreviews.py\u001b[0m in \u001b[0;36mnot_allowed\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnot_allowed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"SubGraph Views are readonly. Mutations not allowed\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNetworkXError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[0madd_node\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnot_allowed\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNetworkXError\u001b[0m: SubGraph Views are readonly. Mutations not allowed"
     ]
    }
   ],
   "source": [
    "p = 0.1\n",
    "\n",
    "iters = 100000\n",
    "alpha = 0.85\n",
    "\n",
    "beta = 0.0\n",
    "gamma = 1.0\n",
    "\n",
    "weights = 'random'\n",
    "\n",
    "G = weighted_DiGraph(n = 100, path = './data/wike_temporal_pr.txt', seed = 1.0, weights = weights)\n",
    "#nodes = G.nodes()\n",
    "\n",
    "# basic\n",
    "norm = sum(G.out_degree(weight='weight').values())\n",
    "sampling_edges = {e[:-1]: e[-1]['weight']/norm for e in G.edges(data=True)}\n",
    "personalization = {k: v / norm for k, v in G.out_degree(weight='weight').items()}\n",
    "p_prime_nodes = {i: personalization[i]/G.out_degree(i, weight='weight') for i in G.nodes()}\n",
    "pr = nx.pagerank(G, alpha=alpha, personalization=personalization, weight='weight')\n",
    "\n",
    "rank_order = [key for (key, value) in sorted(pr.items(), key=operator.itemgetter(1), reverse=True)]\n",
    "ordered_pr = np.array([pr[k] for k in rank_order])\n",
    "\n",
    "stream = [sampling_edges.keys()[i] for i in np.random.choice(range(len(sampling_edges)), size=iters, p=sampling_edges.values())]\n",
    "sorted_RS4, tau, spearman, pearson, error, epochs, top_k = flowPR(p_prime_nodes, pr, stream, iters = iters, beta = beta, \n",
    "                                                                  gamma = gamma)\n",
    "\n",
    "for i in xrange(len(epochs)):\n",
    "    plt.plot(top_k, tau[i][:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We unfortunately couldn't get the code to work. The reason for that is that it's is made in Python 2 and networkx 1. We tried converting it to Python 3 and networkx 2.0 but this failed since from networkx 1 on networkx 2 the subgraph class has become immutable. The algorithm uses this subgraph class to make changes to the main graph. We haven't find a networkx 2 alternative for this subgraph class. A solution for this would be to run this in a python 2 environment with networkx 1 but we just didn't have the time to try this."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
