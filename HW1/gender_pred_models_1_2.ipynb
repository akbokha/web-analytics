{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed dating data-set\n",
    "#### Abdel K. Bokharouss - November 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Seperate model per gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">imports, preparation and configuration</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree, preprocessing, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports needed for the visualization and exportation of visualizations\n",
    "import graphviz as gv # not included in the standard anaconda installer (can be found in the Anaconda Navigator)\n",
    "import pydotplus # not included in anaconda at all (use pip/conda install pydotplus in cmd/conda prompt etc)\n",
    "import io\n",
    "from scipy import misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.text_cell_render h1 {\n",
       "font-size: 1.6em;\n",
       "line-height:1.2em;\n",
       "}\n",
       "\n",
       "div.text_cell_render h2 { \n",
       "margin-bottom: -0.4em;\n",
       "}\n",
       "\n",
       "div.text_cell_render { \n",
       "font-size:1.2em;\n",
       "line-height:1.2em;\n",
       "font-weight:500;\n",
       "}\n",
       "\n",
       "div.text_cell_render p, li {\n",
       "color:Navy;\n",
       "}\n",
       "\n",
       "</style>\n",
       "\n",
       "<script>\n",
       "code_show_err=false; \n",
       "function code_toggle_err() {\n",
       " if (code_show_err){\n",
       " $('div.output_stderr').hide();\n",
       " } else {\n",
       " $('div.output_stderr').show();\n",
       " }\n",
       " code_show_err = !code_show_err\n",
       "} \n",
       "$( document ).ready(code_toggle_err);\n",
       "</script>\n",
       "To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>.\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML # markdown cell styling and enabling/disabling warning messages\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    "div.text_cell_render h1 {\n",
    "font-size: 1.6em;\n",
    "line-height:1.2em;\n",
    "}\n",
    "\n",
    "div.text_cell_render h2 { \n",
    "margin-bottom: -0.4em;\n",
    "}\n",
    "\n",
    "div.text_cell_render { \n",
    "font-size:1.2em;\n",
    "line-height:1.2em;\n",
    "font-weight:500;\n",
    "}\n",
    "\n",
    "div.text_cell_render p, li {\n",
    "color:Navy;\n",
    "}\n",
    "\n",
    "</style>\n",
    "\n",
    "<script>\n",
    "code_show_err=false; \n",
    "function code_toggle_err() {\n",
    " if (code_show_err){\n",
    " $('div.output_stderr').hide();\n",
    " } else {\n",
    " $('div.output_stderr').show();\n",
    " }\n",
    " code_show_err = !code_show_err\n",
    "} \n",
    "$( document ).ready(code_toggle_err);\n",
    "</script>\n",
    "To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>.\n",
    "\"\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>idg</th>\n",
       "      <th>condtn</th>\n",
       "      <th>wave</th>\n",
       "      <th>round</th>\n",
       "      <th>position</th>\n",
       "      <th>positin1</th>\n",
       "      <th>order</th>\n",
       "      <th>...</th>\n",
       "      <th>attr3_3</th>\n",
       "      <th>sinc3_3</th>\n",
       "      <th>intel3_3</th>\n",
       "      <th>fun3_3</th>\n",
       "      <th>amb3_3</th>\n",
       "      <th>attr5_3</th>\n",
       "      <th>sinc5_3</th>\n",
       "      <th>intel5_3</th>\n",
       "      <th>fun5_3</th>\n",
       "      <th>amb5_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   iid   id  gender  idg  condtn  wave  round  position  positin1  order  \\\n",
       "0    1  1.0       0    1       1     1     10         7       NaN      4   \n",
       "1    1  1.0       0    1       1     1     10         7       NaN      3   \n",
       "2    1  1.0       0    1       1     1     10         7       NaN     10   \n",
       "3    1  1.0       0    1       1     1     10         7       NaN      5   \n",
       "4    1  1.0       0    1       1     1     10         7       NaN      7   \n",
       "\n",
       "    ...    attr3_3  sinc3_3  intel3_3  fun3_3 amb3_3  attr5_3 sinc5_3  \\\n",
       "0   ...        5.0      7.0       7.0     7.0    7.0      NaN     NaN   \n",
       "1   ...        5.0      7.0       7.0     7.0    7.0      NaN     NaN   \n",
       "2   ...        5.0      7.0       7.0     7.0    7.0      NaN     NaN   \n",
       "3   ...        5.0      7.0       7.0     7.0    7.0      NaN     NaN   \n",
       "4   ...        5.0      7.0       7.0     7.0    7.0      NaN     NaN   \n",
       "\n",
       "  intel5_3 fun5_3  amb5_3  \n",
       "0      NaN    NaN     NaN  \n",
       "1      NaN    NaN     NaN  \n",
       "2      NaN    NaN     NaN  \n",
       "3      NaN    NaN     NaN  \n",
       "4      NaN    NaN     NaN  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = pd.read_csv(\"speed_dating_assignment.csv\")\n",
    "dates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there are a lot of attributes which can be exploited to build a predictive model. The model should be trained to build the class attribute <i>dec</i>. Considering the fact that a performance metric (e.g. accuracy) should be optimized and evaluated, it makes sense to have sufficient records to actually train the model well enough. An attribute with a lot of missing values (NaN) is, therefore, not a very good candidate since many models require non-NaN values for the feature attributes of the models. Data mining methods can be used to fill in these NaN values, but this will be very error-prone considering the small size of the datasets. \n",
    "\n",
    "The next step is, therefore, an assesment of the attributes which are considered to be of use in the predictive model, and an assesment of the completeness of these attributes in the two datasets. In this part of the assignment (1.2) the attributes that are going to be used will not be constructed ourselves. Feature engineering (e.g. age difference (1.1)) will be exploited in the models of sub-task 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation of possibly useful attributes is not done by scripting, but by an evaluation of the speed dating data key document and a lot of deductive reasoning. The following attributes are considered to be possible candidates:\n",
    "\n",
    "<i>(The text in italics is the explanation giving by the official data key)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <b>order:</b> <i>The number of date that night when met partner.</i> One can image that subjects whom are desperately looking for a partner lower their standards by the end of the night. So if the first x persons were not exactly a success, the subject might (subcounsiously) lower their standard for the next (round - x) persons and this could lead more easily to a decision (dec) to meet the person again\n",
    "* <b>field:</b> <i>field of study.</i> There could be differences in the cognitive process that is decision making between subjects from different field of studies\n",
    "* <b>imprace and imprelig:</b> <i>How important is it to you (on a scale of 1-10) that a person you date be of the same racial/ethnic or religious background?</i> There could be differences in the cognitive process that is decision making between subjects whom rate the importance of being of the same racial and/or religious background higher.\n",
    "* <b>goal, date and go_out:</b> <i>primary goal event, date frequency, going out freuqency (all categorical)</i> There could be differences in the cognitive process that is decision making between subjects who live a different lifestyle and/or have a different primary goal (not focussing on the differences (posibility for 1.3), but on the subject's answer)\n",
    "* <b>satis_2:</b> <i>Overall how satisfied were you with the people you met (1 = not at all satisfied, 10 = extremely satisfied.</i> If a subject is satisfied with the people he/she met, the likelihood of a match (and thus a dec = 1) will be higher, if one would think logically. This attributes is, therefore, definitely worth an evaluation.\n",
    "[comment]: <> (from)\n",
    "Note that if one would use the attribute <i>match</i> it would probably improve the accuracy (or other performance metric which is assed) of the model significantly, but this would be against the main idea of the predictive model. The model should asses whether the subject decides that he/she wants to see date partner in question again. Using the <i>match</i> attribute would be illogical since this attribute would tell us immediately whether <i>dec = 1</i> if <i>match = 1</i> and if <i>match = 0</i>, it can still be that <i>dec = 1</i>, but this is less-likely since this would imply that the date partner in question would not like to see the subject again, which often implies that the date did not go well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8378, 175)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8378 entries, 0 to 8377\n",
      "Data columns (total 10 columns):\n",
      "gender      8378 non-null int64\n",
      "order       8378 non-null int64\n",
      "goal        8299 non-null float64\n",
      "field_cd    8296 non-null float64\n",
      "date        8281 non-null float64\n",
      "age         8283 non-null float64\n",
      "go_out      8299 non-null float64\n",
      "imprace     8299 non-null float64\n",
      "imprelig    8299 non-null float64\n",
      "dec         8378 non-null int64\n",
      "dtypes: float64(7), int64(3)\n",
      "memory usage: 654.6 KB\n"
     ]
    }
   ],
   "source": [
    "dates_model = dates[['gender', 'order','goal', 'field_cd', 'date', 'age', 'go_out', 'imprace', 'imprelig', 'dec']]\n",
    "print(dates.shape) # to asses the number of NaN values per column\n",
    "dates_model.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the attributs <i>gender, order</i> and <i>dec</i> have no NaN values as one would expect, <i>goal</i>, <i>go_out</i>, <i>imprelig</i>, <i>imprace</i> have (8378 - 8299 =) 79 NaN values, <i>date</i> has (8378 - 8281 =) 97 NaN values, field_cd has (8378 - 8296) = 82 NaN values, and age has (8378 - 8283) = 95 NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could fill in most of these numeric values with the median/mean of the column. But considering the nature of the attributes it makes only sense to do this for the age attribute without affecting the correctness of the model too much (<i>\"all models are wrong, some are useful\"</i>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8378 entries, 0 to 8377\n",
      "Data columns (total 10 columns):\n",
      "gender      8378 non-null int64\n",
      "order       8378 non-null int64\n",
      "goal        8299 non-null float64\n",
      "field_cd    8296 non-null float64\n",
      "date        8281 non-null float64\n",
      "age         8378 non-null float64\n",
      "go_out      8299 non-null float64\n",
      "imprace     8299 non-null float64\n",
      "imprelig    8299 non-null float64\n",
      "dec         8378 non-null int64\n",
      "dtypes: float64(7), int64(3)\n",
      "memory usage: 654.6 KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4355: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "dates_model.age.fillna(dates_model.age.median(), inplace = True)\n",
    "dates_model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dates_model.apply(lambda x: sum(x.isnull().values), axis = 1) > 0) # number of rows with NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can by the result of the previous statement, the number of rows with NaN values in any column is 116. This means that a lot of rows with a NaN value in one of the columns, often have also another NaN value in one of the other columns (we could also have 4 * 79 + 97 + 95 + 82 rows with NaN values in the absolute worst case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the relatively low number of NaN's compared to the total record count of the dataset it would not hurt to drop those rows. Dropping those 116 records won't hurt the training of the model by much. In addition, exploiting data mining methods to fill the NaN values would be error-prone considering the nature of the attributes. The choice is, therefore, made to drop these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates_model = dates_model.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since a predictive model needs to be trained for two separate genders (males and females) it makes sense to separate the data into a data frame for the male daters (subject in the instance) and a data frame for the female daters. Male and female subjects are classified by a value of 1 or 0 in the gender column, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4137, 10), (4125, 10))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_subjects = dates_model[dates_model.gender == 1]\n",
    "female_subjects = dates_model[dates_model.gender == 0]\n",
    "male_subjects.shape, female_subjects.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_subjects = male_subjects.apply(preprocessing.LabelEncoder().fit_transform) # encoding categorical data\n",
    "female_subjects = female_subjects.apply(preprocessing.LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4137 records in the data set of the male subjects and 4125 records in the data set of the female subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Training the models</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_subjects_shuffle = male_subjects.sample(frac=1).reset_index(drop=True) # shuffle rows\n",
    "female_subjects_shuffle = female_subjects.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rows are shuffled to ensure a fair split into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_x_data = male_subjects_shuffle.drop('dec', axis = 1) # dec is target attribute\n",
    "female_x_data = female_subjects_shuffle.drop('dec', axis = 1)\n",
    "male_labels = male_subjects_shuffle['dec']\n",
    "female_labels = female_subjects_shuffle['dec']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The choice is made to split the data into 80% training data and 20% test data. This ratio should ensure enough training data for the model and enough data to asses and evaluate the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_x_train, male_x_test, male_y_train, male_y_test = train_test_split(male_x_data, male_labels, test_size = 0.2)\n",
    "female_x_train, female_x_test, female_y_train, female_y_test = train_test_split(female_x_data, female_labels, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there are various training methods which can be exploited. One could go as far as building and training a neural-network model (e.g. using the TensorFlow library), but considering the fact that  there are not a lot of records in the dataset it would be probably overkill for the prediction in question. It would probably result in overfitting. In addition, complicated models are hard to reason about. Visualizing or explaining what goes on in a neural network is very hard considering one has to comprehend and somehow visualize the post-order traversals, numerous optmization steps, batch-sizes (if exploited), the activitation functions, the various layers, cost functions etc. In short, it is simply too much for the human brain to handle once there are a lot of layers and features. \n",
    "\n",
    "The choice is, therefore, made to simply go for a simple model which facilitates a comprehensive evulaution and comparison. Decision tree learning is going to be used to train the models. Classification trees are going to be used to be more specific, considering the fact that the the target variable <i>dec</i> can only take a discrete set of values ({0, 1}). Decision trees facilitate a comprehensible visualization of the decision making in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=8,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=12,\n",
       "            min_samples_split=50, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_tree_male = tree.DecisionTreeClassifier(criterion = \"gini\", max_depth = 8, min_samples_split = 50, min_samples_leaf = 12)\n",
    "dec_tree_female = tree.DecisionTreeClassifier(criterion = \"gini\", max_depth = 8, min_samples_split = 50, min_samples_leaf = 12)\n",
    "# build decision tree classifiers from the training sets\n",
    "dec_tree_male.fit(male_x_train, male_y_train)\n",
    "dec_tree_female.fit(female_x_train, female_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Visualizing the models</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please do not pay a lot attention to the next function. This function is just written and used to visualize the decision trees in a pleasant way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_tree(dec_tree, path, classnames, feat_names):\n",
    "    dfile = io.StringIO()\n",
    "    tree.export_graphviz(dec_tree, out_file = dfile, feature_names = feat_names)\n",
    "    pydotplus.graph_from_dot_data(dfile.getvalue()).write_png(path)\n",
    "    i = misc.imread(path)\n",
    "    plt.imshow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAB6CAYAAACx15gkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28a3b7c1588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "male_col_names = dec_tree_male.classes_\n",
    "male_feature_names = male_subjects.columns[0:(male_subjects.shape[1] - 1)] # the features (attributes) used in the model\n",
    "visualize_tree(dec_tree_male, \"male_decision_tree.png\", male_col_names, male_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See Appendix A.1 for the full image (uncropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAABhCAYAAADYxmp8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28a3e220f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "female_col_names = dec_tree_female.classes_\n",
    "female_feature_names = female_subjects.columns[0:(female_subjects.shape[1] - 1)] # the features (attributes) used in the model\n",
    "visualize_tree(dec_tree_female, \"female_decision_tree.png\", female_col_names, female_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See Appendix A.2 for the full image (uncropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Evaluating the performance of the models</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.618357487923\n"
     ]
    }
   ],
   "source": [
    "pred_male = dec_tree_male.predict(male_x_test) # predicting 'dec' for data which the model has not seen yet\n",
    "print(\"Accuracy score: \", metrics.accuracy_score(male_y_test, pred_male))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.652121212121\n"
     ]
    }
   ],
   "source": [
    "pred_female = dec_tree_female.predict(female_x_test) # predicting 'dec' for data which the model has not seen yet\n",
    "print(\"Accuracy score: \", metrics.accuracy_score(female_y_test, pred_female))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the accuracy of a predictive model should always be taken with a grain of salt. It depends on the randomness, distribution of the target attribute in the train and test splits and many other factors. It is, therefore, always recommended to take also other performance metrics into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.69      0.66       445\n",
      "          1       0.60      0.53      0.56       383\n",
      "\n",
      "avg / total       0.62      0.62      0.62       828\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(male_y_test, pred_male))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage \"dec = 0\" in the male data set:  52.12 %\n",
      "percentage \"dec = 1\" in the male data set:  47.88 %\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD3CAYAAAAT+Z8iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnAXpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28a3e3e1fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('percentage \"dec = 0\" in the male data set: ', round((male_subjects_shuffle.loc[male_subjects_shuffle.dec == 0].shape[0] / male_subjects_shuffle.dec.values.shape[0]) * 100, 2), \"%\")\n",
    "print('percentage \"dec = 1\" in the male data set: ', round((male_subjects_shuffle.loc[male_subjects_shuffle.dec == 1].shape[0] / male_subjects_shuffle.dec.values.shape[0]) * 100, 2), \"%\")\n",
    "plt.hist(male_subjects_shuffle.dec)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of the binary values 0 and 1 in the <i>dec</i> column is relatively fair for the male subjects as can be seen in the histogram. In conclusive, the male subjects expressed in approximately 48% of the dates their wish to see the particular date partner again, and in 52% of the dates they did not see a future with the respective date partner.  The next step is to make some well-tought statements about the performance metrics depicted in the previous set of cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Male model</b><br> Four metrics have been reported per binary value of the <i>dec</i> attribute. Let's start with the most straight forward metric: <i>support</i>.  <i>Support</i> simply tells us the number of occurences of the target attribute in the test data set: (445 / (445 + 383) * 100% = 53.74% for dec = 0. This is in line with the distribution of the dec attribute in the complete male data set as can be seen in the last output cell. The train and test splits are, therefore, assesed to be decent representatives of the sample that is the original data set.\n",
    "The next metrics which is going to be evaluated is the <i>precision</i> metric. The precions metric tells us the ratio between the true positives and the sum of the true positives and false positives. Intuitively, this is an assessment of the ability of the predictive classifier not to label a record as postive, which is actualy negative. So in other words not predicting that a subject decides not to see the the date partner again (dec = 0), when it is actually the case that the subject does want to see the date partner again (dec = 1). The recall is the ratio between the true positives and the sum of the true positves and false negatives. In other words, it is an assessment of the classifier's ability to find all the positive samples. This logic applies to both values of the binary target attribute. Now let's asses the actual values of the report in the context of the data-set.\n",
    "\n",
    "* <b>for dec = 0</b> the classifier has a precision of 0.63 and a recall of 0.69. In other words, it was able not to label a record with dec = 0, when the record origininaly had dec = 1 in 63% of the particular cases. And it was able to classify 69% of the records which had originally the value 0 for dec, with the correct value of 0. So the classifier does a pretty good job in recognizing records which should have dec = 0 (0.69) since it thus only misses 31% of the records and it does ok in not classifying dec = 1 records with dec = 0 (but it still happens in 37% of the records with dec = 1 in the original data set.)\n",
    "* <b>for dec = 1</b> the classifier has a precision of 0.60 and a recall of 0.53. Note the significantly lower recall compared to dec = 0.  It was able not to label a record with dec = 1, when the record orginally had dec = 0 in 60% of the particular cases which is in line with the precision of the previus values. But it was only able to classify 53% of the records which had originally the value 1 for dec, with the correct value of 1. This means that the model has a significantyl harder time recognizing records (i.e. subjects) whom want to see their date partner again, compared to recognizing records (subjects) whom do not want to see their date partner again.\n",
    "\n",
    "Considering the even distribution of decision in the male subjects datasets, one can conlcude that the classifier is significantly better in recognizing cases (records/subjects) that lead to a decision not to see the date partner again, compared to cases that lead to a decision which expresses the subjects wish to see the date partner again. Both classifications come at a relatively same 'cost' (the misclassifcations which is denoted by the precision metric).\n",
    "The f1-score is left out of this evaluation since the evaluation of the previous mentioned metrics for the perforance assesment of the classifier is more than adequate for this particular assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.84      0.75       510\n",
      "          1       0.57      0.35      0.43       315\n",
      "\n",
      "avg / total       0.64      0.65      0.63       825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(female_y_test, pred_female))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage \"dec = 0\" in the female data set:  63.32 %\n",
      "percentage \"dec = 1\" in the female data set:  36.68 %\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD3CAYAAAAT+Z8iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28a3e3ec898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('percentage \"dec = 0\" in the female data set: ', round((female_subjects_shuffle.loc[female_subjects_shuffle.dec == 0].shape[0] / female_subjects_shuffle.dec.values.shape[0]) * 100, 2), \"%\")\n",
    "print('percentage \"dec = 1\" in the female data set: ', round((female_subjects_shuffle.loc[female_subjects_shuffle.dec == 1].shape[0] / female_subjects_shuffle.dec.values.shape[0]) * 100, 2), \"%\")\n",
    "plt.hist(female_subjects_shuffle.dec)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of the binary values 0 and 1 in the <i>dec</i> column is noteworthy as can be seen in the histogram. In conclusive, the female subjects expressed in approximately 37% of the dates their wish to see the particular date partner again, and in 63% of the dates they did not see a future with the respective date partner. So unlike the male subjects, the female subjects epressed relatively (and on average) less often the wish to see their date partner again. The next step is to make some well-tought statements about the performance metrics depicted in the previous set of cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Female model</b><br> The same four performance metrics are going to be evaluated for the female classifier. Let's start with the most straight forward metric: <i>support</i>.  <i>Support</i> simply tells us the number of occurences of the target attribute in the test data set: (510 / (510 + 315) * 100% = 61.82 % for dec = 0. This is in line with the distribution of the dec attribute in the complete female data set as can be seen in the last output cell. The train and test splits are, therefore, assesed to be decent representatives of the sample that is the original data set. But unlike the male classifier, we should pay some extra attention to what hte performance metrics are telling us considering the uneven distribution of decisions.\n",
    "The next metrics which is going to be evaluated is the <i>precision</i> metric. The precions metric tells us the ratio between the true positives and the sum of the true positives and false positives. Intuitively, this is an assessment of the ability of the predictive classifier not to label a record as postive, which is actualy negative. So in other words not predicting that a subject decides expresses it wish to see the the date partner again (dec = 1), when it is actually the case that the subject does want to see the date partner again (dec = 0). The recall is the ratio between the true positives and the sum of the true positves and false negatives. In other words, it is an assessment of the classifier's ability to find all the positive samples. This logic applies to both values of the binary target attribute. Now let's asses the actual values of the report in the context of the data-set.\n",
    "\n",
    "* <b>for dec = 0</b> the classifier has a precision of 0.68 and a recall of 0.84. In other words, it was able not to label a record with dec = 0, when the record origininaly had dec = 1 in 68% of the particular cases. And it was able to classify 84% of the records which had originally the value 0 for dec, with the correct value of 0. So the classifier does a very good job in recognizing records which should have dec = 0 (0.84) since it thus only misses 16% of the records and it does ok in not classifying dec = 1 records with dec = 0 (but it still happens in 32% of the records with dec = 1 in the original data set.)\n",
    "* <b>for dec = 1</b> the classifier has a precision of 0.57 and a recall of 0.35. Note, again, the significantly lower recall compared to dec = 0. It was able not to label a record with dec = 1, when the record orginally had dec = 0 in 57% of the particular cases which is noteably lower than for dec = 0 cases. In addition, it was only able to classify 35% of the records which had originally the value 1 for dec, with the correct value of 1. This means that the model has a significantly hard(er) time recognizing records (i.e. subjects) whom want to see their date partner again, compared to recognizing records (subjects) whom do not want to see their date partner again.\n",
    "\n",
    "Considering the fact that there are significantly more cases (i.e. subjects on dates) that lead to the decision not to see the date partner again than cases in which the subjects has expressed her wish to see the date partner again one has to be a bit more careful in the conclusive remarks. The classifier is significantly better in recognizing cases (records/subjects) that lead to a decision not to see the date partner again, compared to cases that lead to a decision which expresses the subjects wish to see the date partner again (0.84 > 0.35), but one has to note that there are simply less records in the training set with dec = 1, which leads to relatively less records to learn from for the classifier. In addition, the presence of dec = 1 records will also be less in the test set, which means that a low precision will relatively quickly lead to a lower recal. The precision of the dec = 0 records is significantly better than for the dec = 1 records, which means that the classifier mislabels dec = 1 less often with dec = 0, than the other way around."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Comparing the differences among the models</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the visualization of the models before getting into the (significant) differences of the performance metrics. Classification trees are used as classifier in both models. Note that the depth of both trees has been limited. Experimental evaluation has shown (setting max_depth to None) that a higher accuracy can be achieved with the same model, but without a limitation to the depth of the tree. The choice was, however, made to limit the depth of the tree to be able to reason about the (sequence) of decisions that are made in the tree. Not limiting the depth leads thus to better results in this context, but it becomes much harder to visualize the tree in a human comprehensible way. The most important things that should be concluded from a visualization of a decision tree is the attribute significance, and in some cases the attribute values of those significant attributes.\n",
    "\n",
    "Before explaining what can be concluded from the visualizations and the differences among the models let's evaluate first how a decision tree is made. Most decision (classification) tree algorithms work in more or less the same manner. They ussualy exploiy a recursive binary split approach by checking for every featured attribute and every possibly split, which one results in the best optimization of the metric which is used as a function (metric) to asses the qualtiy of a particular split. The criterion (metric) Gini impurity is used in both classifiers. The other option is to use information gain (entropy) as metric. Generally, there are no significant differences between the criterions/metrics, but using entropy as criterion often leads to a heavier and thus longer compuation, considering the logarithmic functions which appear in the function of entropy (summation). But this should only be considered with very large datasets or applications which are time-critical.\n",
    "\n",
    "From this explanation, one can conclude that first split in the decision tree is going to be a split which evaluates the value of the most significant attribute. We see that this is the attribute <i>imprace</i> for the classifier of the male subjects and <i>goal</i> for the classifier of the female models. In the male model the next two splits in the hierarchy are made on the attributes <i>age</i> and <i>imprelig</i>, and in the female model it is the attribute <i>go_out</i>. Now this tells us a difference between the decision making process which the classifieres have learned from the data of ~3300 subjects (per gender 80%).\n",
    "\n",
    "First note that the decision tree classifiers of sklearn treat all the attributes as numeric values (unlike some R libraries). This does not mean that the categories need to be ordinal to reason about it. One has to just put a little bit more thought on what assessment is used in the splits. In addition, the values are scaled (take into account minimum and maximum) and categorised numerically. This can sometimes lead to statements which would not make sense with numeric values of the original dataset.\n",
    "\n",
    "In the male model the first split is made on <i>imprace</i> and for all the males who have rated to find it important that their partner is of the same ehtnic/racial background with 1-5 the next split is going to be on the <i>age</i> attribute, and for all the males who give a rating of 6-10 for <i>imprace</i> the next split is going to be on the <i>imprelig</i> attribute. This tells us something about males who think that being of the same ethnic/racial background is relatively important in comparison to males who do not think it is that important. The males who care more about the ethnic/racial background care also more about the partner's religion (<i>impreg</i> attribute is more important in the decision making process). And for the males who do not care about ethnic/racial background their age is more of importance in the decision making process. Note, however, that these statements are only generalized from the learning rules of the classifier. This does not need to be true in any sense. It is well known that correlation does not imply causation, but if one would could speculate about the cause of this split. One could, for example, argue that males who find ethnic and racial background of their partner important are relatively more consverative than males who do not care about racial background of their partner. This conservatism leads to significance of also the partner's religious background in the classification process. But again, correlation does not imply causation and this is, therefore, nothing more than speculations.\n",
    "\n",
    "In the female model the first split is made on the <i>goal</i> attribute. And the next two splits are both on the <i>go_out</i> attribute. When looking at the next several splits in the trees we can conclude that the classifier believes that ethnic/racial background is not that important, while this was the most significant attribute for the male subjects. Again, correlation does not imply causation but one could speculate that females who are present at the speed dating event with other goals (e.g. meet new people, looking for a serious relationship etc) put significance in different set of attributes (can be found by exploring the branches/specific tree-traversals). This makes sense of course; a woman looking for a serious relationship looks in general for other traits in a partner than a person who is looking to meet new people or someone who is just there to have a fun night out. But again, correlation does not imply causation and this is, therefore, just a speculative generalistic idea.\n",
    "\n",
    "When looking at the performance metrics one can also spot some significant differences between the two classifiers. The recall for dec = 0 in the classifier of the female subjects is significantly higher than the recall of the male subject classifier. The classifier of the female subjects does, therefore, a better job in recognizing cases (subjects that do not want to see the partner again) than the female classifier. The difference in precision for dec = 0 is not worth mentioning. In additiom, one can see that the recall dec = 1 is relatively low for both classifiers, but also significantly lower for the classifier of the femal subjects than the classifier of the male subjects. In other words, both classifiers have a hard time recognizing the situations in which the subjects would express his/her wish to see the date partner again, but the female subject classifier has even a harder time than the male subject classifier, considering its significantly lower recall (0.35 < 0.53) which means that it is even harder to recognize the case for female subjects.\n",
    "\n",
    "The last thing worth noting is the need for other performance metrics than (just) the accuracy of the classifiers. Take the classifier for female subjects for example. If we would have a classifier which fills in dec = 0 for all the records without even taken into account any attributes, this classifier would achieve an accuracy of 61.82 considering the fact that this is the percentage of records with dec = 0 in the test split set. This model would be useless and unarguably wrong, but an accuracy of 61.82 would give the impression that it somehow still does a pretty good job. This is why take into account metrics such as precision, recalll and support provided by the classification report. These metrics take false/true positives/negatives into account which give a better overview of the performance of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Evaluating a third model for the female gender</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new different (and random) 80/20 split is going to used to for the third model (second model for female subjects). The intention is to asses and evaluate the previous model by assesing the model (is it the same as the previous model) and to check whether the perfomance meausures and internals are the same using the new 20% test cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "female_subjects_shuffle_2 = female_subjects.sample(frac=1).reset_index(drop=True)\n",
    "female_x_data_2 = female_subjects_shuffle_2.drop('dec', axis = 1)\n",
    "female_labels_2 = female_subjects_shuffle_2['dec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "female_x_train_2, female_x_test_2, female_y_train_2, female_y_test_2 = train_test_split(female_x_data_2, female_labels_2, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some statements/variables could actually be re-used, but the choice was made to ensure the randomness of the new train (80%) and test data (20%) by executing the statements again. This is also prevents mix-ups between variables if one would re-execute one of the cells that are related to the previous model (which is possible in Jupyter notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=8,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=12,\n",
       "            min_samples_split=50, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same set of parameters as the previous female model to ensure the reliability of the stability assesment.\n",
    "dec_tree_female_2 = tree.DecisionTreeClassifier(criterion = \"gini\", max_depth = 8, min_samples_split = 50, min_samples_leaf = 12)\n",
    "# build the new decision tree classifier from the new training set\n",
    "dec_tree_female_2.fit(female_x_train_2, female_y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAABkCAYAAACIC/vPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8/8RzCY6Xvnv7gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28a3dcd5048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "female_col_names_2 = dec_tree_female_2.classes_\n",
    "female_feature_names_2 = female_subjects_shuffle_2.columns[0:(female_subjects_shuffle_2.shape[1] - 1)] # the features (attributes) used in the model\n",
    "visualize_tree(dec_tree_female_2, \"female_decision_tree_2.png\", female_col_names_2, female_feature_names_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See Appendix A.3 for the full image (uncropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.643636363636\n"
     ]
    }
   ],
   "source": [
    "pred_female_2 = dec_tree_female_2.predict(female_x_test_2) # predicting 'dec' for data which the model has not seen yet\n",
    "print(\"Accuracy score: \", metrics.accuracy_score(female_y_test_2, pred_female_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.86      0.76       526\n",
      "          1       0.52      0.26      0.35       299\n",
      "\n",
      "avg / total       0.62      0.64      0.61       825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(female_y_test_2, pred_female_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at the visualization of the decision tree one can immediately see that the model is different from the previous model build by and for female subjects. In the new model, <i>order</i> is the most significant attribute and the next two splits are on the <i>age</i> and <i>go_out</i> attributes. In the previous model the first split was on the <i>goal</i> attribute followed by splits on the <i>go_out</i> attribute. It is, therefore, not the most stable model. This was expected when building the initial model. The model could only learn from ~ 3300 cases. This may seem a lot, but random shuffling of this dataset can easily lead to (small) changes of the model since it has to learn from such a low number of cases, as can be seen in the new decision tree visualization. If there were real patterns in the decision making process of female subjects and we would have hundreds of thousands of cases to learn from, re-shuffling the dataset at random at re-splitting it should have a significantly lower effect on the learning process of the classifier and thus the rules (splits) it produces. But there is no proof for clear patterns (not considering outlier cases) in the decision making process of female subjects (correlation $\\neq$ causation) and there is not such a dataset available of the same research with those number of cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no extreme differences between the performances of the models. First note that are no noteworthy difference in the support (occcurences of the values in the test set). The recall of dec = 0 improved by 2%, while the precision dropped by 1%. The only significant change in the performance metrics is the even lower value of recall for dec = 1. This model has thus even a harder time in recognizing the cases in the test set in which the female subject would express her wish to see the date partner again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the new model and the male model and check which one is closer to the first female model. When evaluating the differences in the performancem etrics, one would say that the two female models are closer to each oter. But there is one tiny difference that affects the comparability of the models. There are significant differences between the support of the male model and the two female mdoels. It is hard to give a solid reasoning behind the implications of these differences and behind the scope of the question / this assignment.\n",
    "If one owuld asses the decions trees themselves one would also conclude that the two female models are close to each oter than the old female model and male model. The decision tree of the male model puts a heavy emphasis on the difference between male subjects who find ethnic/racial and religious backgrounds important and those who don't. While both female models, aside from the importance of the order in the new model, put emphasis on the importance of the goal and frequency of going attributes. There are, however, differences are present between both female models and the initial female and male model. The female models are closer to together performance- and visual-wise, but definitely not identical. As explained in the previous paragraph, the stability of the model is affected by the characteristics of the dataset which is used to train the model(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>This concludes task 1.2 Some final remarks about the models and results: <br></i>\n",
    "Note that one could consider these models as weak learners. These weak learners could be utilized in an ensemble learner (e.g. Random Forest of decision trees) and the classifier (result from ensemble learner) would probably yield better results than these models, but it would be more difficuly to explain the logic of the model. The choice was, therefore, made to not use ensemble learners to improbe the performance. \n",
    "\n",
    "Another thing worth noting is that a lot of performance metrics were assesed, but the choice was made to leave out any costs matrix. A possible application of the predictive model might be to\n",
    "use them to suggest which participants should be matched, to optimize for the number of successful matches w.r.t. the number of speed dates. The construction of a cost matrix would entail making the choice of what decision should 'weigh' heavier: a wrong decision that could result in a future date (classify dec = 0 case with dec = 1) or the miss of a date, when the subject actually wants to date the partner again (classify dec = 1 case with dec = 0). It would be difficult to asses which of these decisions would be less favorable. One could, in future questionnaires formulate this as another question which the participants have to answer. Analysis of these answers will then tell us what the participants thinks \"weights\" heavier, and this could then be exploited in a cost matrix.\n",
    "\n",
    "And lastly note that the in a more extensive research/analysis, model validation techniques such as (k-fold) cross validation would be no frivolous luxury considering the instablility of the model. It would also result in a better recognition of overfitting models. The choice was, however, made not to include these model validation techniques as this analyis is already more extensive than the evaluators probably anticipated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
