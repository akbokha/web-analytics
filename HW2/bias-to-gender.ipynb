{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed dating data-set\n",
    "## Discrimination-aware classification\n",
    "#### <i>Abdel K. Bokharouss, Bart van Helvert, Joris Rombouts & Remco Surtel</i>   -   December 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"darkred\"><b><i>Important note: a concrete goal of this assignment is, among other things, to give an extensive and qualitative comparison between a model which includes sensitive attributes and a model which excludes these sensitive attributes. Whether or not attributes are considered to be sensitive is subjective, and any decisions should, therefore, be supported by well-grounded arguments.</i></b>\n",
    "<br>\n",
    "<b><i>This brings us to our next important point: This assignment was discussed during the instruction of Wednesday (29-11). The conclusion was made that the models of our first assignment used no significant amount of sensitive attributes (this was no requirement of the first assignment) to facilitate a qualitve comparison. In consultation with the instructors present during that instruction, the choice is made to re-make the same model which was used in assignment 1, but with more sensitive attributes. This will facilitate a better comparison with the discrimination-aware model which uses no sensitive attributes</i></b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">imports, preparation and configuration</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree, preprocessing, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports needed for the visualization and exportation of visualizations\n",
    "import graphviz as gv # not included in the standard anaconda installer (can be found in the Anaconda Navigator)\n",
    "import pydotplus # not included in anaconda at all (use pip/conda install pydotplus in cmd/conda prompt etc)\n",
    "import io\n",
    "from scipy import misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.text_cell_render h1 {\n",
       "font-size: 1.6em;\n",
       "line-height:1.2em;\n",
       "}\n",
       "\n",
       "div.text_cell_render h2 { \n",
       "margin-bottom: -0.4em;\n",
       "}\n",
       "\n",
       "div.text_cell_render { \n",
       "font-size:1.2em;\n",
       "line-height:1.2em;\n",
       "font-weight:500;\n",
       "}\n",
       "\n",
       "div.text_cell_render p, li {\n",
       "color:Navy;\n",
       "}\n",
       "\n",
       "</style>\n",
       "\n",
       "<script>\n",
       "code_show_err=false; \n",
       "function code_toggle_err() {\n",
       " if (code_show_err){\n",
       " $('div.output_stderr').hide();\n",
       " } else {\n",
       " $('div.output_stderr').show();\n",
       " }\n",
       " code_show_err = !code_show_err\n",
       "} \n",
       "$( document ).ready(code_toggle_err);\n",
       "</script>\n",
       "To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>.\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML # markdown cell styling and enabling/disabling warning messages\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    "div.text_cell_render h1 {\n",
    "font-size: 1.6em;\n",
    "line-height:1.2em;\n",
    "}\n",
    "\n",
    "div.text_cell_render h2 { \n",
    "margin-bottom: -0.4em;\n",
    "}\n",
    "\n",
    "div.text_cell_render { \n",
    "font-size:1.2em;\n",
    "line-height:1.2em;\n",
    "font-weight:500;\n",
    "}\n",
    "\n",
    "div.text_cell_render p, li {\n",
    "color:Navy;\n",
    "}\n",
    "\n",
    "</style>\n",
    "\n",
    "<script>\n",
    "code_show_err=false; \n",
    "function code_toggle_err() {\n",
    " if (code_show_err){\n",
    " $('div.output_stderr').hide();\n",
    " } else {\n",
    " $('div.output_stderr').show();\n",
    " }\n",
    " code_show_err = !code_show_err\n",
    "} \n",
    "$( document ).ready(code_toggle_err);\n",
    "</script>\n",
    "To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>.\n",
    "\"\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(88) # seed the generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous model used the following attributes:\n",
    "* <b>order</b>\n",
    "* <b>field</b>\n",
    "* <b>imprace</b> and <b>imprelig</b>\n",
    "* <b>goal</b>, <b>date</b> and <b>go_out</b>\n",
    "\n",
    "And in 1.3 the following attributes were \"engineered\" from existing attributes:\n",
    "* <b>age_diff</b>: The absolute difference between the subject's age and partner's age\n",
    "* <b>attr_o</b>: ating by partner the night of the event, for all six attributes (attr, sinc, intel, fun, amb, and shar)\n",
    "* <b>race_equals</b>:  boolean value, which is True if the race of the partner is the same as the race of the participant, and False otherwise.\n",
    "* <b>goal_equals</b>: boolean value, which is True if the goal of the partner is the same as the goal of the participant, and False otherwise.\n",
    "\n",
    "<font color=\"darkred\">The attributes <b>imprace</b>, <b>imprelig</b>, <b>age_diff</b> and <b>race_equals</b> are considered to be sensitive attributes</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"darkred\">The choice was made to feed the model one more sensitive attribute: <b>race</b>. Other attributes that were considered sensitive is the <b>income</b> attribute. This attribute has, however, a lot of missing values. Which is why the choice was made to not include it in the model. In addition to adding one sensitive attribute to the model the goal of re-making the model is to decrease the <b>height</b> of the decision tree. The height of the decision trees in the first assignment was chosen to be eight. A tree with a lower height would ease the visualization evaluation process. The height is going to be decreased in steps while checking the performance of the models. The goal is to find the right trade-off between the height and the performance of the model.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Gender models with sensitive attributes</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>idg</th>\n",
       "      <th>condtn</th>\n",
       "      <th>wave</th>\n",
       "      <th>round</th>\n",
       "      <th>position</th>\n",
       "      <th>positin1</th>\n",
       "      <th>order</th>\n",
       "      <th>...</th>\n",
       "      <th>attr3_3</th>\n",
       "      <th>sinc3_3</th>\n",
       "      <th>intel3_3</th>\n",
       "      <th>fun3_3</th>\n",
       "      <th>amb3_3</th>\n",
       "      <th>attr5_3</th>\n",
       "      <th>sinc5_3</th>\n",
       "      <th>intel5_3</th>\n",
       "      <th>fun5_3</th>\n",
       "      <th>amb5_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   iid   id  gender  idg  condtn  wave  round  position  positin1  order  \\\n",
       "0    1  1.0       0    1       1     1     10         7       NaN      4   \n",
       "1    1  1.0       0    1       1     1     10         7       NaN      3   \n",
       "2    1  1.0       0    1       1     1     10         7       NaN     10   \n",
       "3    1  1.0       0    1       1     1     10         7       NaN      5   \n",
       "4    1  1.0       0    1       1     1     10         7       NaN      7   \n",
       "\n",
       "    ...    attr3_3  sinc3_3  intel3_3  fun3_3 amb3_3  attr5_3 sinc5_3  \\\n",
       "0   ...        5.0      7.0       7.0     7.0    7.0      NaN     NaN   \n",
       "1   ...        5.0      7.0       7.0     7.0    7.0      NaN     NaN   \n",
       "2   ...        5.0      7.0       7.0     7.0    7.0      NaN     NaN   \n",
       "3   ...        5.0      7.0       7.0     7.0    7.0      NaN     NaN   \n",
       "4   ...        5.0      7.0       7.0     7.0    7.0      NaN     NaN   \n",
       "\n",
       "  intel5_3 fun5_3  amb5_3  \n",
       "0      NaN    NaN     NaN  \n",
       "1      NaN    NaN     NaN  \n",
       "2      NaN    NaN     NaN  \n",
       "3      NaN    NaN     NaN  \n",
       "4      NaN    NaN     NaN  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = pd.read_csv(\"speed_dating_assignment.csv\")\n",
    "dates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next few cells are for preprocessing purposes (filtering, construction of new attributes etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates_new = dates.copy()\n",
    "dates_new = dates_new.filter(items = ['iid', 'age', 'race', 'goal'])\n",
    "dates_new.rename(columns={'iid': 'pid', 'age': 'age_o', 'race': 'race_partner', 'goal':'goal_partner'}, inplace = True)\n",
    "dates_new = dates_new.drop_duplicates()\n",
    "dates_new_merge = pd.merge(dates, dates_new, on=['pid'], how = 'left')\n",
    "dates = dates_new_merge.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates = dates[['attr', 'sinc', 'intel', 'fun', 'amb', 'shar', 'gender', 'order','goal', 'field_cd', 'date','age', 'go_out', 'imprace', 'imprelig', 'age_o', 'race', 'pid', 'iid', 'race_partner', 'goal_partner', 'dec']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates.age.fillna(dates.age.median(), inplace = True)\n",
    "dates = dates.dropna().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"green\">Calculating new features</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\"><b><i>Explanations have been left out in this document. If one is interested in the explanation of the code and/or results. Please see consult our first assignment</i></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates['attr_o'] = dates['attr'] + dates['sinc'] + dates['intel'] + dates['fun'] + dates['amb'] + dates['shar']\n",
    "dates = dates.drop(['attr', 'sinc', 'intel', 'fun', 'shar', 'amb'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates['age_diff'] = abs(dates['age'] - dates['age_o'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates['race_equals'] = (dates['race'] == dates['race_partner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates['goal_equals'] = dates.apply(lambda r: r.goal == r.goal_partner, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>order</th>\n",
       "      <th>goal</th>\n",
       "      <th>field_cd</th>\n",
       "      <th>date</th>\n",
       "      <th>age</th>\n",
       "      <th>go_out</th>\n",
       "      <th>imprace</th>\n",
       "      <th>imprelig</th>\n",
       "      <th>attr_o</th>\n",
       "      <th>race</th>\n",
       "      <th>age_diff</th>\n",
       "      <th>goal_equals</th>\n",
       "      <th>dec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  order  goal  field_cd  date   age  go_out  imprace  imprelig  \\\n",
       "0       0      4   2.0       1.0   7.0  21.0     1.0      2.0       4.0   \n",
       "1       0      3   2.0       1.0   7.0  21.0     1.0      2.0       4.0   \n",
       "2       0     10   2.0       1.0   7.0  21.0     1.0      2.0       4.0   \n",
       "3       0      5   2.0       1.0   7.0  21.0     1.0      2.0       4.0   \n",
       "4       0      7   2.0       1.0   7.0  21.0     1.0      2.0       4.0   \n",
       "\n",
       "   attr_o  race  age_diff  goal_equals  dec  \n",
       "0    40.0   4.0       6.0        False    1  \n",
       "1    41.0   4.0       1.0        False    1  \n",
       "2    42.0   4.0       1.0         True    1  \n",
       "3    42.0   4.0       2.0         True    1  \n",
       "4    37.0   4.0       3.0        False    1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = dates[['gender', 'order','goal', 'field_cd', 'date','age', 'go_out', 'imprace',  'imprelig', 'attr_o', 'race','age_diff', 'goal_equals', 'dec']]\n",
    "dates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3455, 13), (3384, 13))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_subjects = dates[dates.gender == 1]\n",
    "female_subjects = dates[dates.gender == 0]\n",
    "male_subjects = male_subjects.drop('gender', axis = 1) # do not need this attribute\n",
    "female_subjects = female_subjects.drop('gender', axis = 1) # do not need this attribute\n",
    "male_subjects.shape, female_subjects.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_subjects_shuffle = male_subjects.sample(frac=1).reset_index(drop=True) # shuffle rows\n",
    "female_subjects_shuffle = female_subjects.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_x_data = male_subjects_shuffle.drop('dec', axis = 1) # dec is target attribute\n",
    "female_x_data = female_subjects_shuffle.drop('dec', axis = 1)\n",
    "male_labels = male_subjects_shuffle['dec']\n",
    "female_labels = female_subjects_shuffle['dec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_x_train, male_x_test, male_y_train, male_y_test = train_test_split(male_x_data, male_labels, test_size = 0.2)\n",
    "female_x_train, female_x_test, female_y_train, female_y_test = train_test_split(female_x_data, female_labels, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_tree_male = tree.DecisionTreeClassifier(criterion = \"gini\", max_depth = 3)\n",
    "dec_tree_female = tree.DecisionTreeClassifier(criterion = \"gini\", max_depth = 3)\n",
    "# build decision tree classifiers from the training sets\n",
    "dec_tree_male.fit(male_x_train, male_y_train)\n",
    "dec_tree_female.fit(female_x_train, female_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_tree(dec_tree, path, classnames, feat_names):\n",
    "    dfile = io.StringIO()\n",
    "    tree.export_graphviz(dec_tree, out_file = dfile, feature_names = feat_names)\n",
    "    pydotplus.graph_from_dot_data(dfile.getvalue()).write_png(path)\n",
    "    i = imageio.imread(path)\n",
    "    plt.imshow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed: Kan opgegeven module niet vinden.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-c4dea21aea7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmale_col_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdec_tree_male\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmale_feature_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmale_subjects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmale_subjects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# the features (attributes) used in the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mvisualize_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec_tree_male\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"male_decision_tree_sens.png\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmale_col_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmale_feature_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-4944b614130e>\u001b[0m in \u001b[0;36mvisualize_tree\u001b[1;34m(dec_tree, path, classnames, feat_names)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport_graphviz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec_tree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeat_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mpydotplus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_png\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimageio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(uri, format, **kwargs)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;31m# Get reader and read first\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'i'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mget_reader\u001b[1;34m(uri, format, mode, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mformat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mformat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch_read_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         raise ValueError('Could not find a format to read the specified file '\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imageio\\core\\format.py\u001b[0m in \u001b[0;36msearch_read_format\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    658\u001b[0m         \u001b[1;31m# Select the first that can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mselected_formats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 660\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcan_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    661\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imageio\\core\\format.py\u001b[0m in \u001b[0;36mcan_read\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[0mGet\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mformat\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mread\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mspecified\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m         \"\"\"\n\u001b[1;32m--> 189\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcan_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imageio\\plugins\\pillow.py\u001b[0m in \u001b[0;36m_can_read\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_can_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mImage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_pillow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodes\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'?'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplugin_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPEN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imageio\\plugins\\pillow.py\u001b[0m in \u001b[0;36m_init_pillow\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     50\u001b[0m                     raise ImportError('Imageio Pillow requires '\n\u001b[0;32m     51\u001b[0m                                       'Pillow, not PIL!')\n\u001b[1;32m---> 52\u001b[1;33m                 \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Image\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;31m# Also note that Image.core is not a publicly documented interface,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;31m# and should be considered private and subject to change.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_imaging\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mPILLOW_VERSION\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PILLOW_VERSION'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         raise ImportError(\"The _imaging extension was built for another \"\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: Kan opgegeven module niet vinden."
     ]
    }
   ],
   "source": [
    "male_col_names = dec_tree_male.classes_\n",
    "male_feature_names = male_subjects.columns[0:(male_subjects.shape[1] - 1)] # the features (attributes) used in the model\n",
    "visualize_tree(dec_tree_male, \"male_decision_tree_sens.png\", male_col_names, male_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "female_col_names = dec_tree_female.classes_\n",
    "female_feature_names = female_subjects.columns[0:(female_subjects.shape[1] - 1)] # the features (attributes) used in the model\n",
    "visualize_tree(dec_tree_female, \"female_decision_tree_sens.png\", female_col_names, female_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Evaluating the performance of the gender models</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\"><b><i>Explanations have been left out in this document. If one is interested in the explanation of the code and/or results. Please see consult our first assignment</i></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_male = dec_tree_male.predict(male_x_test) # predicting 'dec' for data which the model has not seen yet\n",
    "print(\"Accuracy score: \", metrics.accuracy_score(male_y_test, pred_male))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_female = dec_tree_female.predict(female_x_test) # predicting 'dec' for data which the model has not seen yet\n",
    "print(\"Accuracy score: \", metrics.accuracy_score(female_y_test, pred_female))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(metrics.classification_report(male_y_test, pred_male))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('percentage \"dec = 0\" in the male data set: ', round((male_subjects_shuffle.loc[male_subjects_shuffle.dec == 0].shape[0] / male_subjects_shuffle.dec.values.shape[0]) * 100, 2), \"%\")\n",
    "print('percentage \"dec = 1\" in the male data set: ', round((male_subjects_shuffle.loc[male_subjects_shuffle.dec == 1].shape[0] / male_subjects_shuffle.dec.values.shape[0]) * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(metrics.classification_report(female_y_test, pred_female))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('percentage \"dec = 0\" in the female data set: ', round((female_subjects_shuffle.loc[female_subjects_shuffle.dec == 0].shape[0] / female_subjects_shuffle.dec.values.shape[0]) * 100, 2), \"%\")\n",
    "print('percentage \"dec = 1\" in the female data set: ', round((female_subjects_shuffle.loc[female_subjects_shuffle.dec == 1].shape[0] / female_subjects_shuffle.dec.values.shape[0]) * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Unisex model with sensitive attributes</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unisex = pd.read_csv(\"speed_dating_assignment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unisex_o = unisex.copy()\n",
    "unisex_o = unisex_o.filter(items=['iid', 'age', 'race', 'goal'])\n",
    "unisex_o.rename(columns={'iid': 'pid', 'age': 'age_o', 'race': 'race_partner', 'goal':'goal_partner'}, inplace = True)\n",
    "unisex_o = unisex_o.drop_duplicates()\n",
    "\n",
    "unisex_new = pd.merge(unisex, unisex_o, on=['pid'], how = 'left')\n",
    "unisex = unisex_new.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unisex = unisex[['attr', 'sinc', 'intel', 'fun', 'amb', 'shar', 'order','goal', 'field_cd', 'date','age', 'go_out', 'imprace', 'imprelig', 'dec', 'age_o', 'race', 'pid', 'iid', 'race_partner', 'goal_partner']]\n",
    "unisex.age.fillna(unisex.age.median(), inplace = True)\n",
    "unisex = unisex.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Calculating new features</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unisex['attr_o'] = unisex['attr'] + unisex['sinc'] + unisex['intel'] + unisex['fun'] + unisex['amb'] + unisex['shar']\n",
    "unisex = unisex.drop(['attr', 'sinc', 'intel', 'fun', 'shar', 'amb'], axis = 1)\n",
    "unisex['age_diff'] = abs(unisex['age'] - unisex['age_o'])\n",
    "unisex['race_equals'] = (unisex['race'] == unisex['race_partner'])\n",
    "unisex['goal_equals'] = unisex.apply(lambda r: r.goal == r.goal_partner, axis = 1)\n",
    "unisex = unisex[['order','goal', 'field_cd', 'date','age', 'go_out', 'attr_o', 'imprace', 'imprelig', 'race','age_diff', 'goal_equals', 'dec']]\n",
    "unisex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training the model\n",
    "subjects_shuff_uni = unisex.sample(frac=1).reset_index(drop=True) # shuffle rows\n",
    "x_data_uni = subjects_shuff_uni.drop('dec', axis = 1) # dec is target attribute\n",
    "labels_uni = subjects_shuff_uni['dec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_uni, x_test_uni, y_train_uni, y_test_uni = train_test_split(x_data_uni, labels_uni, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dec_tree_uni = tree.DecisionTreeClassifier(criterion = \"gini\", max_depth = 3)\n",
    "dec_tree_uni.fit(x_train_uni, y_train_uni)\n",
    "col_names_uni = dec_tree_uni.classes_\n",
    "feature_names_uni = unisex.columns[0:(unisex.shape[1] - 1)] # the features (attributes) used in the model\n",
    "visualize_tree(dec_tree_uni, \"unisex_decision_tree_sens.png\", col_names_uni, feature_names_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_uni = dec_tree_uni.predict(x_test_uni) # predicting 'dec' for data which the model has not seen yet\n",
    "print(\"Accuracy score: \", metrics.accuracy_score(y_test_uni, pred_uni))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test_uni, pred_uni))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('percentage \"dec = 0\" in the unisex data set: ', round((subjects_shuff_uni.loc[subjects_shuff_uni.dec == 0].shape[0] / subjects_shuff_uni.dec.values.shape[0]) * 100, 2), \"%\")\n",
    "print('percentage \"dec = 1\" in the unisex data set: ', round((subjects_shuff_uni.loc[subjects_shuff_uni.dec == 1].shape[0] / subjects_shuff_uni.dec.values.shape[0]) * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">----------------------------------------------------------------------------------------------------</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Start second homework assignment</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Discrimination-aware classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"darkred\">The goal of this assignment is to acquire a deeper understanding of model performance and to study how one can compare performance of different models and their internals/decision logic</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abdel K. Bokharouss - December 2017\n",
    "## 1 Sensitive attributes in classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Modeling without sensitive attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictive models of the first assignment can, for example, be used to match partcipants of a (speed) dating event. Some people might not like the idea of an algorithm matching them to other participants. Especially when this algorithm uses sensitive (<i>subjective</i>) attributes about them such as their race, their age (difference), how they value religion in their lives et cetera.\n",
    "\n",
    "<br>The models which were trained in the first assignment (<b>see the two gender- and unisex model(s) at the start of this notebook</b>) did use some attributes that would be considered to be sensitive attributes. In particular, these models used the attributes <i>imprace</i>, <i>imprelig</i>, <i>race_equals</i>, <i>age_diff</i> and <i>race</i>.\n",
    "The first two attributes tells something about how the subject values a partner who is of the same racial/religious background. The third attribute tells us whether the subject and potential match have the same racial background. The fourth attribute tells us about the age difference between the subject and the potential match. And the last attribute is the race of the subject. These are all considered to be sensitive attributes. It should come as no surprise why attributes related to the ethnicity and/or religious background are considered to be sensitive. Take for example the commotion last week around Facebook using the ethnicity of its users to target ads (https://www.technologyreview.com/the-download/609543/facebook-still-lets-people-target-ads-by-race-and-ethnicity/). The age difference is also considered to be a sensitive attribute since a lot of people would not like to be restricted to certain matches because of their age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of this task is, therefore, to build a predictive model that does not include these attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attr_used_old = ['order','goal', 'field_cd', 'date','age', 'go_out', 'imprace',\n",
    "                 'imprelig', 'race','age_diff', 'attr_o', 'goal_equals', 'dec'] # old attributes used\n",
    "sensitive_attr = ['imprace', 'imprelig', 'race_equals', 'age_diff', 'race', 'age'] # attributes which should be excluded\n",
    "without_sens = [attribute for attribute in attr_used_old if attribute not in sensitive_attr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uni_sens = unisex[without_sens] # use the same attributes, but exclude the sensitive attributes\n",
    "print(uni_sens.shape)\n",
    "uni_sens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uni_sens_shuff = uni_sens.sample(frac = 1).reset_index(drop = True) # shuffle the data\n",
    "x_data_uni_sens = uni_sens_shuff.drop('dec', axis = 1) # dec is target attribute\n",
    "labels_uni_sens = uni_sens_shuff['dec']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "80/20 training-test split since this ratio was also used in the previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_uni_sens, x_test_uni_sens, y_train_uni_sens, y_test_uni_sens = train_test_split(\n",
    "    x_data_uni_sens, labels_uni_sens, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The max-depth is set to 3 which will ease the comparative research between the model exploiting sensitive attributes and this model which is the same model, but excludes the sensitive attributes in the training and classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dec_tree_uni_sens = tree.DecisionTreeClassifier(criterion = \"gini\", max_depth = 3)\n",
    "dec_tree_uni_sens.fit(x_train_uni_sens, y_train_uni_sens)\n",
    "col_names_uni_sens = dec_tree_uni_sens.classes_\n",
    "feature_names_uni_sens = uni_sens.columns[0:(uni_sens.shape[1] - 1)] # the features (attributes) used in the model\n",
    "visualize_tree(dec_tree_uni_sens, \"unisex_decision_tree_noSensAttr.png\", col_names_uni_sens, feature_names_uni_sens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_uni_sens = dec_tree_uni_sens.predict(x_test_uni_sens) # predicting 'dec' for data which the model has not seen yet\n",
    "print(\"Accuracy score: \", metrics.accuracy_score(y_test_uni_sens, pred_uni_sens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test_uni_sens, pred_uni_sens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"green\">Evaluating the performance of the (same) model which excludes the sensitive attributes</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few cells back one can see that accuracy of the same unisex model <i>(0.701)</i> which uses the sensitive attributes is only slightly better than the accuracy of the same unisex model which exludes these attributes from the classification process. In the first assignment we have seen that the accuruacy is not the most appropriate performance metric, depending on the situation. The insignificant difference in accuracy does not validate a conclusion about the difference in performance between the two models. The next step is, therefore, to look at the other performance metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the expectation there will be no major differences in precision and recall between the models, one can see that the recall of the model with the sensitive attributes for the cases in which the subject expressed an interest in his/her partner after the date (<i>dec = 1</i>) is almost 10% higher than the recall of the same type of cases for the model excluding sensitive attributes. In addition, the precision of the model with the sensitive attributes for the cases in which the subject expressed no interest in his/her partner after the date (<i>dec = 0</i>) is almost 6% higher than than the precision of the same type of cases for the model. There are no significant/noteworthy differences between the other performance metrics which are obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, the model with the sensitive attributes does seem to perform better for the particular classification task, but the differences are minor. The model with the sensitive attributes is slightly better (recall for dec = 1; 0.68 > 0.62)  in the finding and correctly classifying the cases in which the subject expressed an interest in his/her partner after the date, and the the model with sensitive attributes makes less mistakes for the type of cases in which the subject expresses no interesest since the higher precision (precision for dec = 0; 0.74> 0.70) implies that model classifies less cases which should have the other label (dec = 1) with dec = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"green\">Comparing the models in term of discrimination</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several metrics which can be used to measure discrimination have been explained in a paper on the topic of discrimination/fairness-aware data mining (<a>link.springer.com/article/10.1007/s10618-017-0506-1</a>). The next step is to choose one or more of these discrimination measures to be able to quantify whether the model(s) discriminate, and if they do, how much to they disciminate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before diving into the actual discimination measures some notation needs to be introduced. Fair/non-discriminating data-minining can be defined as:\n",
    "1. people that are similar in terms of non-protected charactersitics (i.e. non-sensitive atttributes) should receive similar predictions (i.e. classifications).\n",
    "2. differences in predictions across groups of people can only be as large as justified by their non-protected (ie. non-sensitive attributes).\n",
    "\n",
    "If this is translated to problem domain of matching subjects at a dating event the following conditions should hold in the context of fair/non-discriminating data-mining in predicitve models exploited at these events:\n",
    "\n",
    "1. subjects that have similiar non-sensitive attributes (all the attributes used in the model, excluding the attributes which were classified earlier on as sensitive) should receive similar predictions.\n",
    "2. differences in predictions across groups of subjects can only be as large as justified by their non-sensitive attributes.\n",
    "\n",
    "The first condition is necessary, but not suffcient by itself to ensure non-discrimination/fairness in the predictive models. This can be explained by the fact that even though subjects who are similar (as far as the non-sensitve attributes can tell) are treated similary (receive similar predictions), groups of subjects with similarities in the non-sensitive attributes may be treated differently from other groups of subjects. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get into the actual discrimination measures. The variable $y$ is used to denote the value of a binary target variable, $y \\in \\{y^+, y^-\\}$ ($+$ (1) and $-$ (0) are used to denote the potential values of the binary target attribute).\n",
    "\n",
    "The variable $s$ will be used to denote a protected attribute (i.e. a sensitive attribute) and $s^i$ will be used to denote value of categorical/binary protected attribute (i.e. a sensitive attribute). Index 1 will be used to denote the protected group in the context of this variable (e.g. $s^1$ will be used to denote a potential ethinic minority, and $s^0$ the majority).\n",
    "\n",
    "The following probabilities notations are going to be used: $p(s^1)$ for $p(s = 1)$ and $p(y^+)$ for $p(y = +)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various discrimination measure types are given in the paper (e.g staticitcal tests, absolute-, conditional-, and situation-measures). Not all of these types are going to be considered in this discrimination analysis ( $\\geq 1$ measure has to be assessed). The focus is going to be on absolute measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Absoulute measures measure the magnitude of discrimination (and thus also the presence/absence of discrimination). The groups are described by a certain characteristic protected attribute. In other words, the groups are divided by a certain sensitive attribute. This can be done with two groups (e.g. if gender would be considered to be a sensitive attribute; males and females), but also with more than one group (e.g. ethnicities). In the latter case one typically compares all the groups  to the most favoured group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An absolute measure of discriminiation is the <b>mean difference</b> $d$. It is given by: $d = E(y^+\\,|\\, s^0) - E(y^+\\,|\\,s^1)$. If there is no difference, then it is considered that there is no discrimination. Note that there is, however, no correction for the standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most obvious sensitive attribute which is considered in this analysis to which this absolute measure can be applied is the <i>race</i> attribute. The ethnicities found in the test split of the unisex model which uses the sensitive attributes (and thus the race attribute) are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unisex.race.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The speed-dating datasets uses numerical encodings to distinguish the different races\n",
    "* 1 = Black/African American\n",
    "* 2 = European/Caucasian-American\n",
    "* 3 = Latino/Hispanic American\n",
    "* 4 = Asian/Pacific Islander/Asian-American\n",
    "* <font color=\"lightgrey\">(5 = Native America) </font> \n",
    "* 6 = Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let consider the mean of the binary target attribute of each of these ethnic groups (in the test sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "race_encodings = {\"Black/African American\": 1, \"European/Caucasian-American\": 2, \"Latino/Hispanic American\": 3, \n",
    "                   \"Asian/Pacific Islander/Asian-American\": 4, \"Other\": 6}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test sample can be found under the variable $x\\_test\\_uni$. This dataframe does not have a column with the actual predictions for those records. The actual predictions can be found under the variable $pred\\_uni$. These two need to be linked before the mean of the binary target attribute of each of the ethnic groups can be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data_test = x_test_uni.copy()\n",
    "x_data_test[\"pred_dec\"] = pred_uni # assign the prediction to the original test records\n",
    "x_data_test.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k, v in race_encodings.items():\n",
    "    print(\"The mean of the target attribute of the\", k, \"group is\", x_data_test.loc[x_data_test.race == v].pred_dec.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can immediately conclude that the model which uses the sensitive attributes ($race$ in particular) is not an example of fair/non-discriminating data-minining/predictive modeling. Note that the mean of the European/Caucasian-American group and the \"Other\" group are almost equivalent. The mean of the target attribute of, for example, the Black/African American group is, however, significantly larger. The magnititude of discrimination for all the groups can be calculated by $d = E(y^+\\,|\\, s^0) - E(y^+\\,|\\,s^1)$, where one uses the most favourable group as $s^1$. Which is in this case the Asian/Pacific Islander/Asian-American group. Calculating the magnitude of discrimination for the Latino/Hispanic American group would result in $d = E(y^+\\,|\\, s^0) - E(y^+\\,|\\,s^1) = 0.504673 - 0.401163 = 0.10351.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Qualitative Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Patterns of discrimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Is there still a bias towards gender?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new = pd.read_csv(\"speed_dating_assignment.csv\")\n",
    "df_new = df_new.drop_duplicates(subset='iid')\n",
    "\n",
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_goal_male = df_new[df_new['gender'] == 1]\n",
    "grouped_goal_male = df_goal_male.groupby(['goal']).size()\n",
    "grouped_goal_male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_goal_female = df_new[df_new['gender'] == 0]\n",
    "grouped_goal_female = df_goal_female.groupby(['goal']).size()\n",
    "grouped_goal_female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_field_male = df_new[df_new['gender'] == 1]\n",
    "grouped_field_male = df_field_male.groupby(['field_cd']).size()\n",
    "grouped_field_male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_field_fe = df_new[df_new['gender'] == 0]\n",
    "grouped_field_fe = df_field_fe.groupby(['field_cd']).size()\n",
    "grouped_field_fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped_field_diff = df_field_male.groupby(['field_cd']).size() - df_field_fe.groupby(['field_cd']).size()\n",
    "grouped_field_diff= grouped_field_diff.dropna()\n",
    "grouped_field_diff.plot(kind= 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discrimination = dates.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discrimination = discrimination.drop(['order', 'goal', 'date', 'age', 'go_out', 'age_diff', 'goal_equals', 'dec'], axis=1)\n",
    "discrimination.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discrimination.corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross = pd.crosstab(discrimination[\"field_cd\"], discrimination[\"gender\"])\n",
    "print(cross)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Unisex decision tree\n",
    "![title](unisex_decision_tree_sens.png)\n",
    "\n",
    "###### Male decision tree\n",
    "![title](male_decision_tree_sens.png)\n",
    "\n",
    "###### Female decision tree\n",
    "![title](female_decision_tree_sens.png)\n",
    "\n",
    "Now, here is a colour-coded version of the unisex decision tree. Decisions that are more similar to the female model than they are to the male model have been coloured pink. Likewise, seemingly male-oriented decisions have been coloured blue. Decisions that are average between the male and female models were coloured orange, and finally, decisions that appear in neither the male, nor the female model have been left white.\n",
    "![title](unisex_decision_tree_sens_coloured.png)\n",
    "\n",
    "As you can see, the first step in the decision tree is a perfect average of the male and female models, which only makes sense. The decisions in the second level, however, are closer to those in the male model. The decisions in the female model are similar as well, but the values used in the unisex model are slightly closer to those that appear in the male model. Finally, we can see that in the third level, the decisions are clearly more similar to those in the female model. None of the decisions in this level look anything like those in the male model. This level also has one decision that has been coloured white, meaning it wasn't similar to either of the gender models.\n",
    "\n",
    "But even though these decisions look like they come from the female model, we do not really know whether they hold for males as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find out whether these decisions really are gender-oriented, we will take as example the bottom-right decision based on 'imprace <= 7.5'. If the female subjects are the only ones for whom this step in the decision tree has the approprate effect on their values of 'dec', then this will show that it is indeed a female-oriented decision. However, if the dec-values for males are affected similarly, then this would show that the model doesn't discriminate, and that this decision makes sense for both genders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_subjects0 = male_subjects.drop(male_subjects[male_subjects.attr_o <= 44.25].index)\n",
    "male_subjects1 = male_subjects0.drop(male_subjects0[male_subjects0.imprace > 7.5].index)\n",
    "male_subjects2 = male_subjects0.drop(male_subjects0[male_subjects0.imprace <= 7.5].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_subjects11 = male_subjects1.drop(male_subjects1[male_subjects1.dec == 0].index)\n",
    "male_subjects12 = male_subjects1.drop(male_subjects1[male_subjects1.dec == 1].index)\n",
    "print(\"Male percentage dec=1 where imprace=<7.5 : \" + str(len(male_subjects11) / (len(male_subjects12) + len(male_subjects11))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_subjects21 = male_subjects2.drop(male_subjects2[male_subjects2.dec == 0].index)\n",
    "male_subjects22 = male_subjects2.drop(male_subjects2[male_subjects2.dec == 1].index)\n",
    "print(\"Male percentage dec=1 where imprace>7.5: \" + str(len(male_subjects21) / (len(male_subjects22) + len(male_subjects21))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "female_subjects0 = female_subjects.drop(female_subjects[female_subjects.attr_o <= 44.25].index)\n",
    "female_subjects1 = female_subjects0.drop(female_subjects0[female_subjects0.imprace > 7.5].index)\n",
    "female_subjects2 = female_subjects0.drop(female_subjects0[female_subjects0.imprace <= 7.5].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "female_subjects11 = female_subjects1.drop(female_subjects1[female_subjects1.dec == 0].index)\n",
    "female_subjects12 = female_subjects1.drop(female_subjects1[female_subjects1.dec == 1].index)\n",
    "print(\"Female percentage dec=1 where imprace=<7.5 : \" + str(len(female_subjects11) / (len(female_subjects12) + len(female_subjects11))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "female_subjects21 = female_subjects2.drop(female_subjects2[female_subjects2.dec == 0].index)\n",
    "female_subjects22 = female_subjects2.drop(female_subjects2[female_subjects2.dec == 1].index)\n",
    "print(\"Female percentage dec=1 where imprace>7.5: \" + str(len(female_subjects21) / (len(female_subjects22) + len(female_subjects21))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As these numbers show, it is not only the female decisions that have an increased chance when imprace <= 7.5. In fact, for males the increase in positive decisions is even greater (from 56% to 79%, instead of 54% to 72%). This shows that the decision is not female-oriented, and thus that the model doesn't discriminate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another path that is worth to look at in the female decision tree, is the bottom left part. In the female model the path where attr_0 <= 31.5 and imprelig > 2.5, has a leaf that is almost pure. In other words, females that don't rate their partner very high and that it's quite important that the partner is of the same religious background, the decision leads to not see the partner again. Because the split is on imprelig > 2.5, it is hard to imply anything about whether females want a partner of the same background. This is because larger than 2.5 is not a very exreme value. However, when looking at the male model, the split is made on imprace <= 4.5. When imprace > 4.5, the majority of the male subjects expresses their wish to not see their partner again. Looking at the third model, the unisex model, one can see that the split in the left bottom path is based on imprelig <= 3.5, where a value of imprelig > 3.5 gives a quite pure leaf containing the majority where dec = 0. In other words, in the unisex model the split is made on a larger imprelig value compared to the female model, and on a completely other attribute compared to the split of the male model. The unisex model could be discriminate on females in this particular split. However, if the dec-values for males are affected similarly, then this would show that the model doesn't discriminate, and that this decision makes sense for both genders. For both male and female models, the correlation between gender and the attribute imprelig are computed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_subjects0_2 = male_subjects.drop(male_subjects[male_subjects.attr_o > 34.5].index)\n",
    "male_subjects1_2 = male_subjects0_2.drop(male_subjects0_2[male_subjects0_2.imprelig > 3.5].index)\n",
    "male_subjects2_2 = male_subjects0_2.drop(male_subjects0_2[male_subjects0_2.imprelig <= 3.5].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_subjects1_21 = male_subjects1_2.drop(male_subjects1_2[male_subjects1_2.dec == 0].index)\n",
    "male_subjects1_22 = male_subjects1_2.drop(male_subjects1_2[male_subjects1_2.dec == 1].index)\n",
    "print(\"Male percentage dec=1 where imprelig <= 3.5 : \" + str(len(male_subjects1_21) / (len(male_subjects1_22) + len(male_subjects1_21))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_subjects2_21 = male_subjects2_2.drop(male_subjects2_2[male_subjects2_2.dec == 0].index)\n",
    "male_subjects2_22 = male_subjects2_2.drop(male_subjects2_2[male_subjects2_2.dec == 1].index)\n",
    "print(\"Male percentage dec=1 where imprelig >3.5: \" + str(len(male_subjects2_21) / (len(male_subjects2_22) + len(male_subjects2_21))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "female_subjects0_2 = female_subjects.drop(female_subjects[female_subjects.attr_o > 34.5].index)\n",
    "female_subjects1_2 = female_subjects0_2.drop(female_subjects0_2[female_subjects0_2.imprelig > 3.5].index)\n",
    "female_subjects2_2 = female_subjects0_2.drop(female_subjects0_2[female_subjects0_2.imprelig <= 3.5].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "female_subjects1_21 = female_subjects1_2.drop(female_subjects1_2[female_subjects1_2.dec == 0].index)\n",
    "female_subjects1_22 = female_subjects1_2.drop(female_subjects1_2[female_subjects1_2.dec == 1].index)\n",
    "print(\"Female percentage dec=1 where imprelig <= 3.5 : \" + str(len(female_subjects1_21) / (len(female_subjects1_22) + len(female_subjects1_21))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "female_subjects2_21 = female_subjects2_2.drop(female_subjects2_2[female_subjects2_2.dec == 0].index)\n",
    "female_subjects2_22 = female_subjects2_2.drop(female_subjects2_2[female_subjects2_2.dec == 1].index)\n",
    "print(\"Female percentage dec=1 where imprelig > 3.5: \" + str(len(female_subjects2_21) / (len(female_subjects2_22) + len(female_subjects2_21))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As these numbers show, it is not only the female decisions that have an increased chance when imprace <= 7.5.\n",
    "\n",
    "What can be concluded from these numbers, is that when imprelig is strictly larger than 3.5 for females, the values of negative decisions decreases from 18% to 5%. For males, the percentage of positive decisions decreases from 23% to 11%. Thus, one could say that the unisex model is discriminating in this split, namely the model is significantly more appropriate for females. However, even though the split is most appropriate for females, this does not necessarily mean that the decision doesn't make sense for males at all. The percentage for males still more than halves, showing that the split is actually quite significant. Thus, the model doesn't truly discriminate against males here. \n",
    "However, data mining provides some powerfool tools for discovering discrimination in historical decision records. One of these is the classification rule mining. For classification rule mining, a potentially distriminated (PD) groups. A subset of attribute values are perceived as potentially discriminatory based on background knowledge. Potentially discriminated groups are people with those attribute values. This are the sensitive attributes that were chosen in the model at the beginning of this assignment. Direct discrimination occurs when decisions are made based on biased sensitive attributes. Associaton rules are if/ then statements that can help uncover relationships between, on first sight, unrelated data in a dataset. In a classification rule, $Y$ is a class item (in this case, `gender`) and $X$ contains no class items (in this case, the unisex model). This is denoted as follows: $X \\rightarrow Y$. PD rules are any classification rule of the form: $A, B \\rightarrow C$, where $A$ is the protected attribute (PD, the gender correlated attribute), $B$ is some context and $C$ is the attribute to predict (`dec`). It gets more complicated when you enter the area of indirect discrimination. Indirect discrimination occurs when decisions are made based on non-sensitive attributes which are strongly correlated with biased sensitive attributes. Potentially non-discriminatory (PND) rules may unveil discrimination, and are described as follows: $D,B \\rightarrow C$, where $D$ is a PND group. For indirect discrimination, background knowledge is needed to allow us to infer discrimination in the model. Of course, this is all qualified what the confidence of these delivered rules are. The notion of extended lift is very important for measuing whether a group of people in a group are treated \"less favorably\" than others. Extended lift is a measture of the increased confidence in concluding an assertion $C$ resulting from adding (potentially discriminatory) information $A$ to a rule $B \\rightarrow C$ where no PD itemset appears. Recall that `conf`($X \\rightarrow Y$) = $\\frac{`support`(X \\rightarrow Y)}{`support`(X)}$So, let $A, B \\rightarrow C$ be a classification rule with `conf`($B \\rightarrow C$ > 0). The extended lift of the rule is: $$ elift(A,B \\rightarrow C) = \\frac{conf(A,B \\rightarrow C)}{conf(B \\rightarrow C)} $$. So, for example, a rule `gender = female`, `race <= 2.5` $\\rightarrow$ `dec = 0` with an extended lift of 3 means that being a female increases 3 times the probability of deciding not to see the partner again with respect to the average confidence of people  who find it not important that their partner is of the same race. So when the extended lift, or this ratio, is very high, than you can claim that males or females are discriminated. So, you are trying to look for these rules where you have a increase in the confidence that is explainable only by the protected attributes that you were not supposed to see in the first place. The last thing that is important to know is the concept of $\\alpha$-protection. For a given threshold $\\alpha$, we say that PD rule $A,B \\rightarrow C$, involving a PD group A in a contect B for an outcome C is $\\alpha$-protective if:\n",
    "                                $$elift_B (A,B \\rightarrow C) = \\frac{conf(A,B \\rightarrow C}{conf(B \\rightarrow C)} \\leq \\alpha$$\n",
    "Otherwise, we say that $A,B \\rightarrow C$ is an $\\alpha$-discriminatory rule. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to construct these association rules, we need to mine al itemsets (only with a minimum support) that contains both $A$ (`gender correlated attribute`) and $C$(`dec_predicted`), Apriori's algorithm is used to mine these rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_apriori2 = dates.copy()\n",
    "df_apriori2 = df_apriori2.drop(['go_out', 'goal', 'goal_equals'], axis = 1)\n",
    "df_apriori2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import OnehotTransactions\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frequent_itemsets = apriori(df_apriori2, min_support=0.2, use_colnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules[ (rules['lift'] >= 2) &\n",
    "       (rules['confidence'] >= 0.1) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Biclustering"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
