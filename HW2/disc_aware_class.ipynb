{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed dating data-set\n",
    "## Discrimination-aware classification\n",
    "#### <i>Abdel K. Bokharouss, Bart van Helvert, Joris Rombouts & Remco Surtel</i>   -   December 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"darkred\"><b><i>Important note: a concrete goal of this assignment is, among other things, to give an extensive and qualitative comparison between a model which includes sensitive attributes and a model which excludes these sensitive attributes. Whether or not attributes are considered to be sensitive is subjective, and any decisions should, therefore, be supported by well-grounded arguments.</i></b>\n",
    "<br>\n",
    "<b><i>This brings us to our next important point: This assignment was discussed during the instruction of Wednesday 29-11. The conclusion was made that the models of our first assignment used no significant amount of sensitive attributes (this was no requirement of the first assignment) to facilitate a qualitative comparison. In consultation with the instructors present during that instruction, the choice was made to re-make the same model which was used in assignment 1, but with more sensitive attributes. This will facilitate a better comparison with the discrimination-aware model which uses no sensitive attributes</i></b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Imports, preparation and configuration</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree, preprocessing, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports needed for the visualization and exportation of visualizations\n",
    "import graphviz as gv # not included in the standard anaconda installer (can be found in the Anaconda Navigator)\n",
    "import pydotplus # not included in anaconda at all (use pip/conda install pydotplus in cmd/conda prompt etc)\n",
    "import io\n",
    "from scipy import misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.text_cell_render h1 {\n",
       "font-size: 1.6em;\n",
       "line-height:1.2em;\n",
       "}\n",
       "\n",
       "div.text_cell_render h2 { \n",
       "margin-bottom: -0.4em;\n",
       "}\n",
       "\n",
       "div.text_cell_render { \n",
       "font-size:1.2em;\n",
       "line-height:1.2em;\n",
       "font-weight:500;\n",
       "}\n",
       "\n",
       "div.text_cell_render p, li {\n",
       "color:Navy;\n",
       "}\n",
       "\n",
       "</style>\n",
       "\n",
       "<script>\n",
       "code_show_err=false; \n",
       "function code_toggle_err() {\n",
       " if (code_show_err){\n",
       " $('div.output_stderr').hide();\n",
       " } else {\n",
       " $('div.output_stderr').show();\n",
       " }\n",
       " code_show_err = !code_show_err\n",
       "} \n",
       "$( document ).ready(code_toggle_err);\n",
       "</script>\n",
       "To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>.\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML # markdown cell styling and enabling/disabling warning messages\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    "div.text_cell_render h1 {\n",
    "font-size: 1.6em;\n",
    "line-height:1.2em;\n",
    "}\n",
    "\n",
    "div.text_cell_render h2 { \n",
    "margin-bottom: -0.4em;\n",
    "}\n",
    "\n",
    "div.text_cell_render { \n",
    "font-size:1.2em;\n",
    "line-height:1.2em;\n",
    "font-weight:500;\n",
    "}\n",
    "\n",
    "div.text_cell_render p, li {\n",
    "color:Navy;\n",
    "}\n",
    "\n",
    "</style>\n",
    "\n",
    "<script>\n",
    "code_show_err=false; \n",
    "function code_toggle_err() {\n",
    " if (code_show_err){\n",
    " $('div.output_stderr').hide();\n",
    " } else {\n",
    " $('div.output_stderr').show();\n",
    " }\n",
    " code_show_err = !code_show_err\n",
    "} \n",
    "$( document ).ready(code_toggle_err);\n",
    "</script>\n",
    "To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>.\n",
    "\"\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(44) # seed the generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous model used the following attributes:\n",
    "* <b>order</b>\n",
    "* <b>field</b>\n",
    "* <b>imprace</b> and <b>imprelig</b>\n",
    "* <b>goal</b>, <b>date</b> and <b>go_out</b>\n",
    "\n",
    "And in 1.3 the following attributes were \"engineered\" from existing attributes:\n",
    "* <b>age_diff</b>: The absolute difference between the subject's age and the partner's age.\n",
    "* <b>attr_o</b>: Rating by partner the night of the event, for all six attributes (attr, sinc, intel, fun, amb, and shar).\n",
    "* <b>race_equals</b>: Boolean value, which is True if the race of the partner is the same as the race of the participant, and False otherwise.\n",
    "* <b>goal_equals</b>: Boolean value, which is True if the goal of the partner is the same as the goal of the participant, and False otherwise.\n",
    "\n",
    "<font color=\"darkred\">The attributes <b>imprace</b>, <b>imprelig</b>, <b>age_diff</b> and <b>race_equals</b> are considered to be sensitive attributes.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"darkred\">The choice was made to feed the model one more sensitive attribute: <b>race</b>. Another attribute that was considered sensitive is the <b>income</b> attribute. However, this attribute has a lot of missing values. Which is why the choice was made to exclude it from the model. In addition to adding one sensitive attribute to the model, the goal of re-making the model is to decrease the <b>height</b> of the decision tree. The height of the decision trees in the first assignment was chosen to be eight. A tree with a lower height would ease the visualization and evaluation process. The height is going to be decreased in steps while checking the performance of the models. The goal is to find the right trade-off between the height and the performance of the model.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"darkred\">Considering the fact that the second assignment states that model can be potentially used to match partcipants of a (speed) dating event beforehand, it does not make sense anymore to use the <b>attr_o</b> attribute, since this is a rating which is given after a date. The choices is, therefore, to change this attribute into just the <b>attr</b> attribute (unlike attributes such as the rating of, for example, someone's intelligence) (one of the 6 dimensions of the attr_o attribute). The attractiveness could be rated before a date, for example by showing pictures of potential dates. This is, of course, controversial and can thus immediately be considered as a sensitive attribute.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Gender models with sensitive attributes</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>idg</th>\n",
       "      <th>condtn</th>\n",
       "      <th>wave</th>\n",
       "      <th>round</th>\n",
       "      <th>position</th>\n",
       "      <th>positin1</th>\n",
       "      <th>order</th>\n",
       "      <th>...</th>\n",
       "      <th>attr3_3</th>\n",
       "      <th>sinc3_3</th>\n",
       "      <th>intel3_3</th>\n",
       "      <th>fun3_3</th>\n",
       "      <th>amb3_3</th>\n",
       "      <th>attr5_3</th>\n",
       "      <th>sinc5_3</th>\n",
       "      <th>intel5_3</th>\n",
       "      <th>fun5_3</th>\n",
       "      <th>amb5_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   iid   id  gender  idg  condtn  wave  round  position  positin1  order  \\\n",
       "0    1  1.0       0    1       1     1     10         7       NaN      4   \n",
       "1    1  1.0       0    1       1     1     10         7       NaN      3   \n",
       "2    1  1.0       0    1       1     1     10         7       NaN     10   \n",
       "3    1  1.0       0    1       1     1     10         7       NaN      5   \n",
       "4    1  1.0       0    1       1     1     10         7       NaN      7   \n",
       "\n",
       "    ...    attr3_3  sinc3_3  intel3_3  fun3_3 amb3_3  attr5_3 sinc5_3  \\\n",
       "0   ...        5.0      7.0       7.0     7.0    7.0      NaN     NaN   \n",
       "1   ...        5.0      7.0       7.0     7.0    7.0      NaN     NaN   \n",
       "2   ...        5.0      7.0       7.0     7.0    7.0      NaN     NaN   \n",
       "3   ...        5.0      7.0       7.0     7.0    7.0      NaN     NaN   \n",
       "4   ...        5.0      7.0       7.0     7.0    7.0      NaN     NaN   \n",
       "\n",
       "  intel5_3 fun5_3  amb5_3  \n",
       "0      NaN    NaN     NaN  \n",
       "1      NaN    NaN     NaN  \n",
       "2      NaN    NaN     NaN  \n",
       "3      NaN    NaN     NaN  \n",
       "4      NaN    NaN     NaN  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = pd.read_csv(\"speed_dating_assignment.csv\")\n",
    "dates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next few cells are for preprocessing purposes (filtering, construction of new attributes etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates_new = dates.copy()\n",
    "dates_new = dates_new.filter(items = ['iid', 'age', 'race', 'goal'])\n",
    "dates_new.rename(columns={'iid': 'pid', 'age': 'age_o', 'race': 'race_partner', 'goal':'goal_partner'}, inplace = True)\n",
    "dates_new = dates_new.drop_duplicates()\n",
    "dates_new_merge = pd.merge(dates, dates_new, on=['pid'], how = 'left')\n",
    "dates = dates_new_merge.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates = dates[['attr', 'gender', 'order','goal', 'field_cd', 'date','age', 'go_out', 'imprace', 'imprelig', 'age_o', 'race', 'pid', 'iid', 'race_partner', 'goal_partner', 'dec']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates.age.fillna(dates.age.median(), inplace = True)\n",
    "dates = dates.dropna().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"green\">Calculating new features</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\"><b><i>Explanations have been left out in this document. If one is interested in the explanation of the code and/or results, please consult our first assignment.</i></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates['age_diff'] = abs(dates['age'] - dates['age_o'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates['race_equals'] = (dates['race'] == dates['race_partner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates['goal_equals'] = dates.apply(lambda r: r.goal == r.goal_partner, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>order</th>\n",
       "      <th>goal</th>\n",
       "      <th>field_cd</th>\n",
       "      <th>date</th>\n",
       "      <th>age</th>\n",
       "      <th>go_out</th>\n",
       "      <th>imprace</th>\n",
       "      <th>imprelig</th>\n",
       "      <th>attr</th>\n",
       "      <th>race</th>\n",
       "      <th>age_diff</th>\n",
       "      <th>goal_equals</th>\n",
       "      <th>dec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  order  goal  field_cd  date   age  go_out  imprace  imprelig  attr  \\\n",
       "0       0      4   2.0       1.0   7.0  21.0     1.0      2.0       4.0   6.0   \n",
       "1       0      3   2.0       1.0   7.0  21.0     1.0      2.0       4.0   7.0   \n",
       "2       0     10   2.0       1.0   7.0  21.0     1.0      2.0       4.0   5.0   \n",
       "3       0      5   2.0       1.0   7.0  21.0     1.0      2.0       4.0   7.0   \n",
       "4       0      7   2.0       1.0   7.0  21.0     1.0      2.0       4.0   5.0   \n",
       "\n",
       "   race  age_diff  goal_equals  dec  \n",
       "0   4.0       6.0        False    1  \n",
       "1   4.0       1.0        False    1  \n",
       "2   4.0       1.0         True    1  \n",
       "3   4.0       2.0         True    1  \n",
       "4   4.0       3.0        False    1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = dates[['gender', 'order','goal', 'field_cd', 'date','age', 'go_out', 'imprace',  'imprelig', 'attr', 'race','age_diff', 'goal_equals', 'dec']]\n",
    "dates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3957, 13), (4004, 13))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_subjects = dates[dates.gender == 1]\n",
    "female_subjects = dates[dates.gender == 0]\n",
    "male_subjects = male_subjects.drop('gender', axis = 1) # do not need this attribute\n",
    "female_subjects = female_subjects.drop('gender', axis = 1) # do not need this attribute\n",
    "male_subjects.shape, female_subjects.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_subjects_shuffle = male_subjects.sample(frac=1).reset_index(drop=True) # shuffle rows\n",
    "female_subjects_shuffle = female_subjects.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_x_data = male_subjects_shuffle.drop('dec', axis = 1) # dec is target attribute\n",
    "female_x_data = female_subjects_shuffle.drop('dec', axis = 1)\n",
    "male_labels = male_subjects_shuffle['dec']\n",
    "female_labels = female_subjects_shuffle['dec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_x_train, male_x_test, male_y_train, male_y_test = train_test_split(male_x_data, male_labels, test_size = 0.2)\n",
    "female_x_train, female_x_test, female_y_train, female_y_test = train_test_split(female_x_data, female_labels, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_tree_male = tree.DecisionTreeClassifier(criterion = \"gini\", max_depth = 3)\n",
    "dec_tree_female = tree.DecisionTreeClassifier(criterion = \"gini\", max_depth = 3)\n",
    "# build decision tree classifiers from the training sets\n",
    "dec_tree_male.fit(male_x_train, male_y_train)\n",
    "dec_tree_female.fit(female_x_train, female_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_tree(dec_tree, path, classnames, feat_names):\n",
    "    dfile = io.StringIO()\n",
    "    tree.export_graphviz(dec_tree, out_file = dfile, feature_names = feat_names)\n",
    "    pydotplus.graph_from_dot_data(dfile.getvalue()).write_png(path)\n",
    "    i = misc.imread(path)\n",
    "    plt.imshow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_col_names = dec_tree_male.classes_\n",
    "male_feature_names = male_subjects.columns[0:(male_subjects.shape[1] - 1)] # the features (attributes) used in the model\n",
    "#visualize_tree(dec_tree_male, \"male_decision_tree_sens.png\", male_col_names, male_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](male_decision_tree_sens.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "female_col_names = dec_tree_female.classes_\n",
    "female_feature_names = female_subjects.columns[0:(female_subjects.shape[1] - 1)] # the features (attributes) used in the model\n",
    "#visualize_tree(dec_tree_female, \"female_decision_tree_sens.png\", female_col_names, female_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](female_decision_tree_sens.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Evaluating the performance of the gender models</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\"><b><i>Explanations have been left out in this document. If one is interested in the explanation of the code and/or results, please consult our first assignment.</i></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.710858585859\n"
     ]
    }
   ],
   "source": [
    "pred_male = dec_tree_male.predict(male_x_test) # predicting 'dec' for data which the model has not seen yet\n",
    "print(\"Accuracy score: \", metrics.accuracy_score(male_y_test, pred_male))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.715355805243\n"
     ]
    }
   ],
   "source": [
    "pred_female = dec_tree_female.predict(female_x_test) # predicting 'dec' for data which the model has not seen yet\n",
    "print(\"Accuracy score: \", metrics.accuracy_score(female_y_test, pred_female))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.72      0.71       395\n",
      "          1       0.71      0.71      0.71       397\n",
      "\n",
      "avg / total       0.71      0.71      0.71       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(male_y_test, pred_male))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage \"dec = 0\" in the male data set:  51.18 %\n",
      "percentage \"dec = 1\" in the male data set:  48.82 %\n"
     ]
    }
   ],
   "source": [
    "print('percentage \"dec = 0\" in the male data set: ', round((male_subjects_shuffle.loc[male_subjects_shuffle.dec == 0].shape[0] / male_subjects_shuffle.dec.values.shape[0]) * 100, 2), \"%\")\n",
    "print('percentage \"dec = 1\" in the male data set: ', round((male_subjects_shuffle.loc[male_subjects_shuffle.dec == 1].shape[0] / male_subjects_shuffle.dec.values.shape[0]) * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.83      0.78       501\n",
      "          1       0.65      0.52      0.58       300\n",
      "\n",
      "avg / total       0.71      0.72      0.71       801\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(female_y_test, pred_female))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage \"dec = 0\" in the female data set:  62.74 %\n",
      "percentage \"dec = 1\" in the female data set:  37.26 %\n"
     ]
    }
   ],
   "source": [
    "print('percentage \"dec = 0\" in the female data set: ', round((female_subjects_shuffle.loc[female_subjects_shuffle.dec == 0].shape[0] / female_subjects_shuffle.dec.values.shape[0]) * 100, 2), \"%\")\n",
    "print('percentage \"dec = 1\" in the female data set: ', round((female_subjects_shuffle.loc[female_subjects_shuffle.dec == 1].shape[0] / female_subjects_shuffle.dec.values.shape[0]) * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Unisex model with sensitive attributes</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unisex = pd.read_csv(\"speed_dating_assignment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unisex_o = unisex.copy()\n",
    "unisex_o = unisex_o.filter(items=['iid', 'age', 'race', 'goal'])\n",
    "unisex_o.rename(columns={'iid': 'pid', 'age': 'age_o', 'race': 'race_partner', 'goal':'goal_partner'}, inplace = True)\n",
    "unisex_o = unisex_o.drop_duplicates()\n",
    "\n",
    "unisex_new = pd.merge(unisex, unisex_o, on=['pid'], how = 'left')\n",
    "unisex = unisex_new.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unisex = unisex[['attr', 'order','goal', 'field_cd', 'date','age', 'go_out', 'imprace', 'imprelig', 'dec', 'age_o', 'race', 'pid', 'iid', 'race_partner', 'goal_partner']]\n",
    "unisex.age.fillna(unisex.age.median(), inplace = True)\n",
    "unisex = unisex.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"green\">Calculating new features</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order</th>\n",
       "      <th>goal</th>\n",
       "      <th>field_cd</th>\n",
       "      <th>date</th>\n",
       "      <th>age</th>\n",
       "      <th>go_out</th>\n",
       "      <th>attr</th>\n",
       "      <th>imprace</th>\n",
       "      <th>imprelig</th>\n",
       "      <th>race</th>\n",
       "      <th>age_diff</th>\n",
       "      <th>goal_equals</th>\n",
       "      <th>dec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order  goal  field_cd  date   age  go_out  attr  imprace  imprelig  race  \\\n",
       "0      4   2.0       1.0   7.0  21.0     1.0   6.0      2.0       4.0   4.0   \n",
       "1      3   2.0       1.0   7.0  21.0     1.0   7.0      2.0       4.0   4.0   \n",
       "2     10   2.0       1.0   7.0  21.0     1.0   5.0      2.0       4.0   4.0   \n",
       "3      5   2.0       1.0   7.0  21.0     1.0   7.0      2.0       4.0   4.0   \n",
       "4      7   2.0       1.0   7.0  21.0     1.0   5.0      2.0       4.0   4.0   \n",
       "\n",
       "   age_diff  goal_equals  dec  \n",
       "0       6.0        False    1  \n",
       "1       1.0        False    1  \n",
       "2       1.0         True    1  \n",
       "3       2.0         True    1  \n",
       "4       3.0        False    1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unisex['age_diff'] = abs(unisex['age'] - unisex['age_o'])\n",
    "unisex['race_equals'] = (unisex['race'] == unisex['race_partner'])\n",
    "unisex['goal_equals'] = unisex.apply(lambda r: r.goal == r.goal_partner, axis = 1)\n",
    "unisex = unisex[['order','goal', 'field_cd', 'date','age', 'go_out', 'attr', 'imprace', 'imprelig', 'race','age_diff', 'goal_equals', 'dec']]\n",
    "unisex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training the model\n",
    "subjects_shuff_uni = unisex.sample(frac=1).reset_index(drop=True) # shuffle rows\n",
    "x_data_uni = subjects_shuff_uni.drop('dec', axis = 1) # dec is target attribute\n",
    "labels_uni = subjects_shuff_uni['dec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_uni, x_test_uni, y_train_uni, y_test_uni = train_test_split(x_data_uni, labels_uni, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dec_tree_uni = tree.DecisionTreeClassifier(criterion = \"gini\", max_depth = 3)\n",
    "dec_tree_uni.fit(x_train_uni, y_train_uni)\n",
    "col_names_uni = dec_tree_uni.classes_\n",
    "feature_names_uni = unisex.columns[0:(unisex.shape[1] - 1)] # the features (attributes) used in the model\n",
    "#visualize_tree(dec_tree_uni, \"unisex_decision_tree_sens.png\", col_names_uni, feature_names_uni)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](unisex_decision_tree_sens.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.747018204645\n"
     ]
    }
   ],
   "source": [
    "pred_uni = dec_tree_uni.predict(x_test_uni) # predicting 'dec' for data which the model has not seen yet\n",
    "print(\"Accuracy score: \", metrics.accuracy_score(y_test_uni, pred_uni))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.76      0.77       896\n",
      "          1       0.70      0.73      0.72       697\n",
      "\n",
      "avg / total       0.75      0.75      0.75      1593\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test_uni, pred_uni))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage \"dec = 0\" in the unisex data set:  56.99 %\n",
      "percentage \"dec = 1\" in the unisex data set:  43.01 %\n"
     ]
    }
   ],
   "source": [
    "print('percentage \"dec = 0\" in the unisex data set: ', round((subjects_shuff_uni.loc[subjects_shuff_uni.dec == 0].shape[0] / subjects_shuff_uni.dec.values.shape[0]) * 100, 2), \"%\")\n",
    "print('percentage \"dec = 1\" in the unisex data set: ', round((subjects_shuff_uni.loc[subjects_shuff_uni.dec == 1].shape[0] / subjects_shuff_uni.dec.values.shape[0]) * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">----------------------------------------------------------------------------------------------------</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Start second homework assignment</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Discrimination-aware classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"darkred\">The goal of this assignment is to acquire a deeper understanding of model performance and to study how one can compare the performance of different models and their internals/decision logic.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Sensitive attributes in classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Modeling without sensitive attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictive models of the first assignment can be used to match partcipants of a (speed) dating event, for example. Some people might not like the idea of an algorithm matching them to other participants, though. This is especially true when this algorithm uses sensitive (<i>subjective</i>) attributes about them, such as their race, age (difference), how they value religion in their lives, et cetera.\n",
    "\n",
    "<br>The models which were trained in the first assignment (<b>see the two gender- and unisex model(s) at the start of this notebook</b>) did use some attributes that would be considered sensitive attributes. In particular, these models used the attributes <i>imprace</i>, <i>imprelig</i>, <i>race_equals</i>, <i>age_diff</i>, and <i>race</i>.\n",
    "The first two attributes tell us something about how the subject values a partner who is of the same racial/religious background. The third attribute tells us whether the subject and potential match have the same racial background. The fourth attribute tells us about the age difference between the subject and the potential match. And the last attribute is the race of the subject. These are all considered to be sensitive attributes. It should come as no surprise that attributes related to the ethnicity and/or religious background are considered to be sensitive. Take for example the commotion last week around Facebook using the ethnicity of its users to target ads (https://www.technologyreview.com/the-download/609543/facebook-still-lets-people-target-ads-by-race-and-ethnicity/). The age difference is also considered to be a sensitive attribute, since a lot of people would not like to be restricted to certain matches because of their age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the first step of this task is to build a predictive model that does not include these attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attr_used_old = ['order','goal', 'field_cd', 'date','age', 'go_out', 'imprace',\n",
    "                 'imprelig', 'race','age_diff', 'attr', 'goal_equals', 'dec'] # old attributes used\n",
    "sensitive_attr = ['imprace', 'imprelig', 'race_equals', 'age_diff', 'race', 'age'] # attributes which should be excluded\n",
    "without_sens = [attribute for attribute in attr_used_old if attribute not in sensitive_attr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7961, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order</th>\n",
       "      <th>goal</th>\n",
       "      <th>field_cd</th>\n",
       "      <th>date</th>\n",
       "      <th>go_out</th>\n",
       "      <th>attr</th>\n",
       "      <th>goal_equals</th>\n",
       "      <th>dec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order  goal  field_cd  date  go_out  attr  goal_equals  dec\n",
       "0      4   2.0       1.0   7.0     1.0   6.0        False    1\n",
       "1      3   2.0       1.0   7.0     1.0   7.0        False    1\n",
       "2     10   2.0       1.0   7.0     1.0   5.0         True    1\n",
       "3      5   2.0       1.0   7.0     1.0   7.0         True    1\n",
       "4      7   2.0       1.0   7.0     1.0   5.0        False    1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_sens = unisex[without_sens] # use the same attributes, but exclude the sensitive attributes\n",
    "print(uni_sens.shape)\n",
    "uni_sens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uni_sens_shuff = uni_sens.sample(frac = 1).reset_index(drop = True) # shuffle the data\n",
    "x_data_uni_sens = uni_sens_shuff.drop('dec', axis = 1) # dec is target attribute\n",
    "labels_uni_sens = uni_sens_shuff['dec']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use an 80/20 training-test split, since this ratio was also used in the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_uni_sens, x_test_uni_sens, y_train_uni_sens, y_test_uni_sens = train_test_split(\n",
    "    x_data_uni_sens, labels_uni_sens, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The max-depth is set to 3, which will ease the comparative research between the model exploiting sensitive attributes and this model, which is the same model except it excludes the sensitive attributes in the training and classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dec_tree_uni_sens = tree.DecisionTreeClassifier(criterion = \"gini\", max_depth = 3)\n",
    "dec_tree_uni_sens.fit(x_train_uni_sens, y_train_uni_sens)\n",
    "col_names_uni_sens = dec_tree_uni_sens.classes_\n",
    "feature_names_uni_sens = uni_sens.columns[0:(uni_sens.shape[1] - 1)] # the features (attributes) used in the model\n",
    "#visualize_tree(dec_tree_uni_sens, \"unisex_decision_tree_noSensAttr.png\", col_names_uni_sens, feature_names_uni_sens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](unisex_decision_tree_noSensAttr.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.740740740741\n"
     ]
    }
   ],
   "source": [
    "pred_uni_sens = dec_tree_uni_sens.predict(x_test_uni_sens) # predicting 'dec' for data which the model has not seen yet\n",
    "print(\"Accuracy score: \", metrics.accuracy_score(y_test_uni_sens, pred_uni_sens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.75      0.76       883\n",
      "          1       0.70      0.72      0.71       710\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1593\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test_uni_sens, pred_uni_sens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"green\">Evaluating the performance of the (same) model which excludes the sensitive attributes</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few cells back one can see that the accuracy of the same unisex model <i>(0.747)</i> using the sensitive attributes is only slightly better than the accuracy of the same unisex model which exludes these attributes from the classification process. In the first assignment, we have seen that accuruacy may not be the most appropriate performance metric, depending on the situation. Thus, the insignificant difference in accuracy does not necessarily validate a conclusion about the difference in performance between the two models. Therefore, the next step is to look at the other performance metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the expectation is that there will be no major differences in precision and recall between the models, one can see that the recall of the model with the sensitive attributes for the cases in which the subject expressed an interest in his/her partner after the date (<i>dec = 1</i>) is higher than the recall of the same type of cases for the model excluding sensitive attributes, but this difference of 0.01 is, of course, not significant. The precision for this case remained the same after the exclusion of the sensitive attributes. The recall and precision metrics for the other potential value of the target attribute also didn't undergo major devaluations. Both the recall and precision dropped by 0.01. Therefore, one could argue that the model got slightly worse at recognizing these cases (dec = 0) without the sensitive attributes, even though these differences are not substantial by any means. The slight drop in these performance metrics explains the slight decrease of the accuracy of the model which excludes the sensitive attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"green\">Comparing the models in terms of discrimination</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several metrics which can be used to measure discrimination have been explained in a paper on the topic of discrimination/fairness-aware data mining (<a>link.springer.com/article/10.1007/s10618-017-0506-1</a>). The next step is to choose one or more of these discrimination measures to be able to quantify whether the model(s) discriminate, and if they do, how much they disciminate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before diving into the actual discrimination measures, some notation needs to be introduced. Fair/non-discriminating data-minining can be defined as:\n",
    "1. People who are similar in terms of non-protected charactersitics (i.e. non-sensitive atttributes) should receive similar predictions (i.e. classifications).\n",
    "2. Differences in predictions across groups of people can only be as large as justified by their non-protected (ie. non-sensitive attributes).\n",
    "\n",
    "If this is translated to problem domain of matching subjects at a dating event, the following conditions should hold in the context of fair/non-discriminating data-mining in predicitve models exploited at these events:\n",
    "\n",
    "1. Subjects who have similar non-sensitive attributes (all the attributes used in the model, excluding the attributes which were classified earlier on as sensitive) should receive similar predictions.\n",
    "2. Differences in predictions across groups of subjects can only be as large as justified by their non-sensitive attributes.\n",
    "\n",
    "The first condition is necessary, but not suffcient by itself to ensure non-discrimination/fairness in the predictive models. This can be explained by the fact that even though subjects who are similar (as far as the non-sensitve attributes can tell) are treated similary (receive similar predictions), groups of subjects with similarities in the non-sensitive attributes may be treated differently from other groups of subjects. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get into the actual discrimination measures. The variable $y$ is used to denote the value of a binary target variable, $y \\in \\{y^+, y^-\\}$ ($+$ (1) and $-$ (0) are used to denote the potential values of the binary target attribute).\n",
    "\n",
    "The variable $s$ will be used to denote a protected attribute (i.e. a sensitive attribute) and $s^i$ will be used to denote the value of a categorical/binary protected attribute (i.e. a sensitive attribute). Index 1 will be used to denote the protected group in the context of this variable (e.g. $s^1$ will be used to denote a potential ethnic minority, and $s^0$ the majority).\n",
    "\n",
    "The following probability notations will be used: $p(s^1)$ for $p(s = 1)$ and $p(y^+)$ for $p(y = +)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various discrimination measure types are given in the paper (e.g staticitcal tests, absolute-, conditional-, and situation-measures). Not all of these types are going to be considered in this discrimination analysis ( $\\geq 1$ measure has to be assessed). The focus is going to be on absolute measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Absolute measures measure the magnitude of discrimination (and thus also the presence/absence of discrimination). The groups are described by a certain characteristic protected attribute. In other words, the groups are divided by a certain sensitive attribute. This can be done with two groups (e.g. if gender would be considered to be a sensitive attribute; males and females), but also with more than one group (e.g. ethnicities). In the latter case, one typically compares all the groups  to the most favoured group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An absolute measure of discriminiation is the <b>mean difference</b> $d$. It is given by: $d = E(y^+\\,|\\, s^0) - E(y^+\\,|\\,s^1)$. If there is no difference, then it is concluded that there is no discrimination. Note that there is, however, no correction for the standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most obvious sensitive attribute which is considered in this analysis to which this absolute measure can be applied, is the <i>race</i> attribute. The ethnicities found in the test split of the unisex model, which uses the sensitive attributes (and thus the race attribute), are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.,  2.,  6.,  3.,  1.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unisex.race.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The speed-dating datasets uses numerical encodings to distinguish the different races\n",
    "* 1 = Black/African American\n",
    "* 2 = European/Caucasian-American\n",
    "* 3 = Latino/Hispanic American\n",
    "* 4 = Asian/Pacific Islander/Asian-American\n",
    "* <font color=\"lightgrey\">(5 = Native America) </font> \n",
    "* 6 = Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider the mean of the binary target attribute of each of these ethnic groups (in the test sample)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "race_encodings = {\"Black/African American\": 1, \"European/Caucasian-American\": 2, \"Latino/Hispanic American\": 3, \n",
    "                   \"Asian/Pacific Islander/Asian-American\": 4, \"Other\": 6}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test sample can be found under the variable $x\\_test\\_uni$. This dataframe does not have a column with the actual predictions for those records. The actual predictions can be found under the variable $pred\\_uni$. These two need to be linked before the mean of the binary target attribute of each of the ethnic groups can be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order</th>\n",
       "      <th>goal</th>\n",
       "      <th>field_cd</th>\n",
       "      <th>date</th>\n",
       "      <th>age</th>\n",
       "      <th>go_out</th>\n",
       "      <th>attr</th>\n",
       "      <th>imprace</th>\n",
       "      <th>imprelig</th>\n",
       "      <th>race</th>\n",
       "      <th>age_diff</th>\n",
       "      <th>goal_equals</th>\n",
       "      <th>pred_dec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3108</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4691</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3591</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6782</th>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7732</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      order  goal  field_cd  date   age  go_out  attr  imprace  imprelig  \\\n",
       "3108      5   2.0      13.0   6.0  29.0     3.0   5.0      2.0       7.0   \n",
       "4691      7   1.0       3.0   6.0  27.0     3.0   4.0      3.0       5.0   \n",
       "3591      3   5.0       5.0   5.0  22.0     3.0   4.0      6.0       6.0   \n",
       "6782      5   3.0       1.0   6.0  24.0     1.0   7.0      1.0       3.0   \n",
       "7732      1   1.0       3.0   4.0  33.0     2.0   7.0      1.0       7.0   \n",
       "\n",
       "      race  age_diff  goal_equals  pred_dec  \n",
       "3108   2.0       1.0        False         0  \n",
       "4691   2.0       1.0         True         0  \n",
       "3591   2.0       6.0        False         0  \n",
       "6782   4.0       3.0        False         1  \n",
       "7732   2.0       6.0        False         1  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_test = x_test_uni.copy()\n",
    "x_data_test[\"pred_dec\"] = pred_uni # assign the prediction to the original test records\n",
    "x_data_test.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the target attribute of the Black/African American group is 0.5052631578947369\n",
      "The mean of the target attribute of the European/Caucasian-American group is 0.4638009049773756\n",
      "The mean of the target attribute of the Latino/Hispanic American group is 0.43333333333333335\n",
      "The mean of the target attribute of the Asian/Pacific Islander/Asian-American group is 0.40934065934065933\n",
      "The mean of the target attribute of the Other group is 0.52\n"
     ]
    }
   ],
   "source": [
    "for k, v in race_encodings.items():\n",
    "    print(\"The mean of the target attribute of the\", k, \"group is\", x_data_test.loc[x_data_test.race == v].pred_dec.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can immediately conclude that the model which uses the sensitive attributes ($race$ in particular) is not an example of fair/non-discriminating data-minining/predictive modeling. The magnitude of discrimination for all the groups can be calculated by $d = E(y^+\\,|\\, s^0) - E(y^+\\,|\\,s^1)$, where one uses the ethnic minority as $s^1$, which is in this case the Asian/Pacific Islander/Asian-American group, and where $s^0$ would be the majority. Calculating the magnitude of discrimination for the Asian/Pacific Islander/Asian-American would result in $d = E(y^+\\,|\\, s^0) - E(y^+\\,|\\,s^1) = E(y^+\\,|\\, s^0) - 0.40934.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, however, that the absolute measure mean difference should actually be used for binary protected variables. The mean difference should thus be defined as the mean targets of the protected group and the general group. This means that one ethnic group should be classified as the protected group, while all the other ethnic groups (i.e. races) are defined to be the general group in this problem's context  This immediately brings us to the next question: based on the results depicted above, what group should be classified as the protected group and the general group? This can be a tricky question since it depends on the context of the problem and the perspective of the problem-solver. First note that discrimination by a predictive model can only occur when the target variable is polar. In the paper on discrimination measures a classical and straightforward example is given. The paper discusses the problem of loan-granting. It is quite clear that getting a loan (for which is applied by the applicant) is better than receiving no loan, when this decision making is done or supported by an algorithm (predictive model). It is thus quite clear that when a protected group which is shown to receive loans less often than a similar group with the same attributes, except the sensitive attributes, there is discrimination. But in the context of speed-dating one could argue both ways. One could say that an algorithm which matches the subject less often is better than when it matches the subject more often (i.e. the mean of the target-attribute <i>dec</i> is lower) since this would mean that the subject has to go on fewer dates with potential partners (more effective), if this model is used to match subjects before actually sending them out on dates. But one could also argue that a match prediction outcome (dec = 1) is superior to others (dec = 0). We chose the latter, since the assumption is made that subjects would probably rather go on more dates and increase their chances of finding a partner. Thus, this means a lower mean of the target attribute would be considered to be unfavourable compared to a higher mean of the target attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, this would imply that the Asian/Pacific Islander/Asian-American group is the ethnic minority in this context and that the absolute mean of the majority (general group) would be the mean of all the ethnic groups other than the Asian/Pacific Islander/Asian-American group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the target attribute of the majority (general group) =  0.467860048820179\n"
     ]
    }
   ],
   "source": [
    "print(\"The mean of the target attribute of the majority (general group) = \",\n",
    "      x_data_test.loc[x_data_test.race != race_encodings.get(\"Asian/Pacific Islander/Asian-American\")].pred_dec.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the magnitude of discrimination for the Asian/Pacific Islander/Asian-American would result in $d = E(y^+\\,|\\, s^0) - E(y^+\\,|\\,s^1) = 0.46786 - 0.40934 = 0.05852 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this calculation one can safely conclude the presence of discrimination of the predictive model at a dataset level. In addition, the magnitude of this discrimination for the ethnic minortity which is the Asian/Pacific Islander/Asian-American is captured. Note how close the mean of the target attribute of the European/Caucasian-American group is to the mean of the of the target attribute of the majority (general group) (even though the European/Caucasian-American subjects are also used in the calculation of the man of the majority). One would expect that this group would be the least prone to discrimination at a speed-dating event in the United States, as one can conclude from these measures. It is, however, not safe to reason about any causation of the resulting measure, considering the small sample size and relative general and instable model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another absolute measure which will be considered (extra; one discrimination meausure is ought to be sufficient according to the assignment description) is the normalized difference. The normalized difference is fairly similar to the absolute mean difference, except as one would expect from the name of the measure; the mean difference is normalized by the rate of the positive outcomes. This can be captured by the following formula (where $\\delta$ denotes the normalized mean difference):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\delta = \\frac{p\\left(y^+\\,|\\, s^0\\right) - p\\left(y^+\\,|\\,s^1\\right)}{d_{max}}$, $\\, \\,$where $\\, d_{max} = min\\,\\left(\\left(\\frac{ p(y^+)}{p(s^1)}\\right),\\left(\\frac{p(y^-)}{p(s^0)}\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's calculate $d_{max}$ first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('p_y_plus: ', 0.45448838669177655, 'p_y_min: ', 0.5455116133082235, True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_y_plus = len(x_data_test[x_data_test.pred_dec == 1]) / len(x_data_test)\n",
    "p_y_min = len(x_data_test[x_data_test.pred_dec == 0]) / len(x_data_test) # can also use 1 - p_y_plus\n",
    "\"p_y_plus: \", p_y_plus, \"p_y_min: \", p_y_min, (p_y_plus +  p_y_min == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('p_s_one: ', 0.22849968612680477, 'p_s_zero: ', 0.7715003138731952, True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_s_one = p_y_plus = len(x_data_test[x_data_test.race == \n",
    "                                     race_encodings.get(\"Asian/Pacific Islander/Asian-American\")]) / len(x_data_test)\n",
    "p_s_zero = len(x_data_test[x_data_test.race\n",
    "                           != race_encodings.get(\"Asian/Pacific Islander/Asian-American\")]) / len(x_data_test)\n",
    "\"p_s_one: \", p_s_one, \"p_s_zero: \", p_s_zero, (p_s_one +  p_s_zero == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7070789259560619"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_max = min((p_y_plus / p_s_one), (p_y_min / p_s_zero))\n",
    "d_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05851938947951968"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerator = (x_data_test.loc[x_data_test.race != race_encodings.get(\n",
    "    \"Asian/Pacific Islander/Asian-American\")].pred_dec.mean()) - (x_data_test.loc[x_data_test.race == race_encodings.get(\n",
    "    \"Asian/Pacific Islander/Asian-American\")].pred_dec.mean())\n",
    "numerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08276217453432644"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_difference = (numerator) / d_max\n",
    "normalized_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This measure takes into account maximum possible discrimination at a given positive outcome rate, such that the magnitude of discrimination is at most $\\delta = 1$ (maximum possible discrimination), while $\\delta = 0$ indicates the absence of discrimination, as explained in the paper on measuring discrimination in algorithmic decision making. From these results one  can conclude that there is indeed some discrimination present in the predictive model on data set level, but the discrimination is far from extreme. Additionally, note that more protected attributes (i.e. sensitive attributes) can be evaluated to get a more complete assessment of discrimination in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Qualitative Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two unisex models have been considered in part 1.1. One model that includes-, and one model that excludes these same sensitive attributes. The performance differences, absence/presence of discrimination and magnitude of discrimination have been assessed and evaluated. The next step is to look for differences in behaviour (i.e. decision) logic between the two models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This comparison is going to start with a comparison of the visualizations which capture the decision logic of the two models that respectively include and exclude the sensitive attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two walks in the decision trees are a clear difference in decision logic of the two models:\n",
    "\n",
    "* $(attr \\leq 6.25) \\,\\rightarrow\\, (attr > 5.5)\\, \\rightarrow\\, (go\\_out > 5.5)$ $\\rightarrow$ ($dec = 1$) for the model which excludes sensitive attributes.\n",
    "* $(attr \\leq 6.25) \\,\\rightarrow\\, (attr > 4.5)\\, \\rightarrow\\, (attr > 5.5)$ $\\rightarrow$ (i.e. $dec = 0$) for the model which includes sensitive attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look whether the predictions for the test sample are conforming to this analysis of the differences in the decision logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order</th>\n",
       "      <th>goal</th>\n",
       "      <th>field_cd</th>\n",
       "      <th>date</th>\n",
       "      <th>go_out</th>\n",
       "      <th>attr</th>\n",
       "      <th>goal_equals</th>\n",
       "      <th>pred_dec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7055</th>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5562</th>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2896</th>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      order  goal  field_cd  date  go_out  attr  goal_equals  pred_dec\n",
       "7055      7   6.0       9.0   4.0     3.0   6.0         True         0\n",
       "267      16   1.0       1.0   4.0     1.0   4.0        False         0\n",
       "5562      2   6.0       8.0   4.0     2.0   4.0        False         0\n",
       "2417      2   2.0      13.0   6.0     3.0   8.0        False         1\n",
       "2896     14   2.0       9.0   5.0     3.0   7.0        False         1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_nosens_test = x_test_uni_sens.copy()\n",
    "x_data_nosens_test[\"pred_dec\"] = pred_uni_sens  # assign the prediction to the original test records\n",
    "x_data_nosens_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a043a988d0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGtXmsnVE0wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a043788c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_data_nosens_test[(x_data_nosens_test.attr <= 6.25) & (x_data_nosens_test.attr > 5.5) & (x_data_nosens_test.go_out > 5.5)].pred_dec.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a043a98da0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a043793cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_data_test[(x_data_test.attr <= 6.25) & (x_data_test.attr > 5.5) & (x_data_test.go_out > 5.5)].pred_dec.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And indeed, the decision logic of the two models that respectively include and exclude the sensitive attributes results in conflicting predictions for these samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Patterns of discrimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Is there still a bias towards gender?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Male decision tree\n",
    "![title](male_decision_tree_sens.png)\n",
    "\n",
    "###### Female decision tree\n",
    "![title](female_decision_tree_sens.png)\n",
    "\n",
    "###### Unisex decision tree\n",
    "![title](unisex_decision_tree_sens.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two different attributes in our unisex model, race and attr (attractiveness of the partner). Clearly, race is not a gender-correlated attribute, because regardless of race, the division between male and female will be approximately 50%, if your dataset is large enough. \n",
    "\n",
    "To test whether attractiveness is gender-correlated, we will investigate the ratio of males to females for certain levels of attractiveness. We start by trying the left-most path, i.e. where attr <= 4.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of male subjects where attr <= 4.5: 13%\n",
      "Percentage of female subjects where attr <= 4.5: 23%\n"
     ]
    }
   ],
   "source": [
    "male_subjects_L = male_subjects.drop(male_subjects[male_subjects.attr > 4.5].index)\n",
    "female_subjects_L = female_subjects.drop(female_subjects[female_subjects.attr > 4.5].index)\n",
    "print(\"Percentage of male subjects where attr <= 4.5: \" + str(int(len(male_subjects_L)/len(male_subjects)*100)) + \"%\")\n",
    "print(\"Percentage of female subjects where attr <= 4.5: \" + str(int(len(female_subjects_L)/len(female_subjects)*100)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly there is a very large difference, there are almost twice as many females who rate the attractiveness of their partners lower than 4.5. This is likely because females are more critical when selecting their partners, or perhaps the males in the dataset are more desperate to find a partner. Regardless, this shows that attr is a gender-correlated attribute, because when the value for attr is low, the subject is more likely to be female. \n",
    "\n",
    "Now, for completeness, we will investigate the right-most path as well, to see if this rule also holds the other way around: Does a high value for attr mean that the subject is likely male?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of male subjects where attr > 8.25: 12%\n",
      "Percentage of female subjects where attr > 8.25: 8%\n"
     ]
    }
   ],
   "source": [
    "male_subjects_R = male_subjects.drop(male_subjects[male_subjects.attr <= 8.25].index)\n",
    "female_subjects_R = female_subjects.drop(female_subjects[female_subjects.attr <= 8.25].index)\n",
    "print(\"Percentage of male subjects where attr > 8.25: \" + str(int(len(male_subjects_R)/len(male_subjects)*100)) + \"%\")\n",
    "print(\"Percentage of female subjects where attr > 8.25: \" + str(int(len(female_subjects_R)/len(female_subjects)*100)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So yes, the relation also holds the other way round. Subjects that have rated the attractiveness of their partner very high are more likely to be male. Thus, attr is certainly a gender-correlated attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at some paths in the decision trees. One path worth looking at in the female decision tree, is the bottom left part. In the female model the path where the value of attractiveness is larger than 6.5 and smaller than 7.5, splits on the value race <= 2.5. The two resulting leaves of these splits don't say very much, i.e. they are not pure. In the unisex model, this path looks almost exactly the same. However, the male model splits on imprace instead of race. Therefore it might be worth investigating whether the unisex model discriminates on the female gender in this particular split in the unisex model. If the dec-values for males are affected similarly, then this would show that the model doesn't discriminate, and that this decision makes sense for both genders. For both male and female models, the correlation between gender and the attribute imprelig are computed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test whether race is a gender-correlated attribute, we will investigate the ratio of males to females where race > 2.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male percentage dec=1 where race <= 2.5 : 32%\n"
     ]
    }
   ],
   "source": [
    "male_subjects0_R = male_subjects.drop(male_subjects[male_subjects.attr <= 6.25 ].index)\n",
    "male_subjects0_R = male_subjects.drop(male_subjects[male_subjects.attr > 7.25 ].index)\n",
    "male_subjects1_R = male_subjects0_R.drop(male_subjects0_R[male_subjects0_R.race > 2.5].index)\n",
    "male_subjects2_R = male_subjects0_R.drop(male_subjects0_R[male_subjects0_R.race <= 2.5].index)\n",
    "\n",
    "male_subjects2_R1 = male_subjects1_R.drop(male_subjects1_R[male_subjects1_R.dec == 0].index)\n",
    "male_subjects2_R2 = male_subjects1_R.drop(male_subjects1_R[male_subjects1_R.dec == 1].index)\n",
    "print(\"Male percentage dec=1 where race <= 2.5 : \" + str(int(len(male_subjects2_R1) / (len(male_subjects2_R1) + len(male_subjects2_R2))*100)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male percentage dec=1 where race > 2.5 : 41%\n"
     ]
    }
   ],
   "source": [
    "male_subjects2_R12 = male_subjects2_R.drop(male_subjects2_R[male_subjects2_R.dec == 0].index)\n",
    "male_subjects2_R22 = male_subjects2_R.drop(male_subjects2_R[male_subjects2_R.dec == 1].index)\n",
    "print(\"Male percentage dec=1 where race > 2.5 : \" + str(int(len(male_subjects2_R12) / (len(male_subjects2_R12) + len(male_subjects2_R22))*100)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female percentage dec=1 where race <= 2.5 : 23%\n"
     ]
    }
   ],
   "source": [
    "female_subjects0_R = female_subjects.drop(female_subjects[female_subjects.attr <= 6.25 ].index)\n",
    "female_subjects0_R = female_subjects.drop(female_subjects[female_subjects.attr > 7.25 ].index)\n",
    "\n",
    "female_subjects1_R = female_subjects0_R.drop(female_subjects0_R[female_subjects0_R.race > 2.5].index)\n",
    "female_subjects2_R = female_subjects0_R.drop(female_subjects0_R[female_subjects0_R.race <= 2.5].index)\n",
    "\n",
    "female_subjects2_R1 = female_subjects1_R.drop(female_subjects1_R[female_subjects1_R.dec == 0].index)\n",
    "female_subjects2_R2 = female_subjects1_R.drop(female_subjects1_R[female_subjects1_R.dec == 1].index)\n",
    "print(\"Female percentage dec=1 where race <= 2.5 : \" + str(int(len(female_subjects2_R1) / (len(female_subjects2_R1) + len(female_subjects2_R2))*100))+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female percentage dec=1 where race > 3.5 : 33%\n"
     ]
    }
   ],
   "source": [
    "female_subjects2_R12 = female_subjects2_R.drop(female_subjects2_R[female_subjects2_R.dec == 0].index)\n",
    "female_subjects2_R22 = female_subjects2_R.drop(female_subjects2_R[female_subjects2_R.dec == 1].index)\n",
    "print(\"Female percentage dec=1 where race > 3.5 : \" + str(int(len(female_subjects2_R12) / (len(female_subjects2_R12) + len(female_subjects2_R22))*100))+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male_subjects_R = male_subjects.drop(male_subjects[male_subjects.race <= 2.5].index)\n",
    "female_subjects_R = female_subjects.drop(female_subjects[female_subjects.race <= 2.5].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of male subjects where race > 2.5: 35%\n",
      "Percentage of female subjects where race > 2.5: 41%\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of male subjects where race > 2.5: \" + str(int(len(male_subjects_R)/len(male_subjects)*100)) + \"%\")\n",
    "print(\"Percentage of female subjects where race > 2.5: \" + str(int(len(female_subjects_R)/len(female_subjects)*100)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As these results show, there is no significant difference between these two ratios. So we see that ethnicity does not influence the decision whether the subject wants to see the partner again. Note that the race attribute only says something about the race of the subject, and not about the partner's race."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data mining provides some powerfool tools for discovering discrimination in historical decision records. One of these is the classification rule mining. For classification rule mining, we consider a potentially distriminated (PD) group. A subset of attribute values are perceived as potentially discriminatory based on background knowledge. Potentially discriminated groups are people with those attribute values. These are the sensitive attributes that were chosen in the model at the beginning of this assignment. Direct discrimination occurs when decisions are made based on biased sensitive attributes. Associaton rules are if/ then statements that can help uncover relationships between, at first sight, unrelated data in a dataset. In a classification rule, $Y$ is a class item (in this case, `gender`) and $X$ contains no class items (in this case, the unisex model). This is denoted as follows: $X \\rightarrow Y$. \n",
    "\n",
    "PD rules are any classification rule of the form: $A, B \\rightarrow C$, where $A$ is the protected attribute (PD, the gender correlated attribute), $B$ is some context and $C$ is the attribute to predict (`dec`). It gets more complicated when you enter the area of indirect discrimination. \n",
    "\n",
    "Indirect discrimination occurs when decisions are made based on non-sensitive attributes which are strongly correlated with biased sensitive attributes. Potentially non-discriminatory (PND) rules may unveil discrimination, and are described as follows: $D,B \\rightarrow C$, where $D$ is a PND group. For indirect discrimination, background knowledge is needed to allow us to infer discrimination in the model. Of course, this is all qualified according to what the confidence of these delivered rules are. The notion of extended lift is very important for measuring whether a group of people are treated \"less favourably\" than others. Extended lift is a measure of the increased confidence in concluding an assertion $C$ resulting from adding (potentially discriminatory) information $A$ to a rule $B \\rightarrow C$ where no PD itemset appears. Recall that `conf`($X \\rightarrow Y$) = $\\frac{`support`(X \\rightarrow Y)}{`support`(X)}$. Support determines how often a rule is applicable to a given data set, while confidence determines how frequently items in $Y$ appear, when also $X$ is contained. \n",
    "\n",
    "So, let $A, B \\rightarrow C$ be a classification rule with `conf`($B \\rightarrow C$ > 0). The extended lift of the rule is: $$ elift(A,B \\rightarrow C) = \\frac{conf(A,B \\rightarrow C)}{conf(B \\rightarrow C)} $$. So, for example, a rule `gender = female`, `race <= 2.5` $\\rightarrow$ `dec = 0` with an extended lift of 3 means that being a female increases the probability of deciding not to see the partner again by 3-fold with respect to the average confidence of people who don't find it important that their partner is of the same race. So when the extended lift, or this ratio, is very high, then you can claim that males or females are discriminated against. So, you are trying to look for these rules where you have an increase in the confidence that is explicable only by the protected attributes that you were not supposed to see in the first place. \n",
    "\n",
    "The last thing that is important to know is the concept of $\\alpha$-protection. For a given threshold $\\alpha$, we say that PD rule $A,B \\rightarrow C$, involving a PD group A in a context B for an outcome C is $\\alpha$-protective if:\n",
    "                                $$elift_B (A,B \\rightarrow C) = \\frac{conf(A,B \\rightarrow C}{conf(B \\rightarrow C)} \\leq \\alpha$$\n",
    "Otherwise, we say that $A,B \\rightarrow C$ is an $\\alpha$-discriminatory rule. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To mine the association rules from the dataframe `dates`, the dataframe is converted to a csv file. To construct these association rules, alle itemsets are mined with a minimum support of 0.50 and a minimum confidence of 0.70 in RapidMiner. The RapidMiner process that is used to mine the association rules looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates.to_csv('featured_attributes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](rapid_miner_setup.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, all the attributes are selected from the dataset. For some association rules, we have to filter the attributes on some values, to measure the extended lift. After that all values in the columns are discretized, possible nominal values are converted to binominal values and the `FP-growth` operation calculates all frequent itemsets from the given dataset using the FP-tree data structure. It is compulsory that all attributes of the input dataset should be binominal. The `create Association rules`- operation generates a set of association rules from the given set of frequent itemsets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](association_rules.png)\n",
    "![title](race_dec_rule.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we are looking for association rules of the form $A, B \\rightarrow C$, where $A$ is the gender correlated attribute, $B$ is some context and $C$ is the attribute to predict. From the analysis above, we have concluded that `attr` the only gender correlated attribute is in our model. $C$ is the value to be predicted, which is `dec` in our case. There are only two association rules where $C$ == 'dec'. The first one is `attr`, `race` $\\rightarrow$ `dec`.  The conf($A,B \\rightarrow C$)= 0.656 and conf($B \\rightarrow C$) = 0.422. Therefore $elift(A,B \\rightarrow C) = \\frac{conf(A,B \\rightarrow C)}{conf(B \\rightarrow C)} = \\frac{0.715}{0.465} = 1.54$.\n",
    "\n",
    "The second rule( `gender`, `attr` $\\rightarrow$ `dec`), has `gender` as the `gender correlated attribute`, which doesn't make sense at all. \n",
    "\n",
    "To claim that `attr`, `race` $\\rightarrow$ `dec` is an $\\alpha$-discriminatory rule, we have to set a value for $\\alpha$. To make a strong claim that this rule is discriminatory, we set $\\alpha = 2$. This means that we want to be twice as confident about the subgroup for this particular gender, than for all the other people. Because $1.55 < 2$, we can conclude that this association rule is not discriminatory. However, note that the context $B$ in this case contains all the races of the dataset. The elift could be increased by filtering some races out of the dataset. After experimenting with different race values, the highest elift was extracted when `race` = 2,3 or 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](race_rule_234.png)\n",
    "![title](race_dec_rule.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$elift(attr,race \\rightarrow dec) = \\frac{conf(attr,race \\rightarrow dec)}{conf(race \\rightarrow dec)} = \\frac{0.724}{0.456} = 1.60$. This means that this rule is 1.60 times as confident about the Latino/Hispanic/Asian and European Americans that the decision leads to see their partner again.\n",
    "The extented lift has increased somewhat, but still it is not larger than the predefined threshold of $\\alpha = 2$. Therefore , we can conclude that this rule is not discriminating. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the figure above, there are two other association rules where $A = $`attr` and $C = $`dec`. The first one is `attr`, `go_out` $\\rightarrow$ `dec`. The extended lift of this rule is calculated as follows: $elift(attr,go\\_out \\rightarrow dec) = \\frac{conf(attr,go\\_out \\rightarrow dec)}{conf(go\\_out \\rightarrow dec)} = \\frac{0.698}{0.465} = 1.50$. This means that this rule is 1.50 times as confident about the females, than for all the persons.\n",
    "The last association rule is `attr`, `age_diff` $\\rightarrow$ `dec`. In the first assignment we saw that the chance of `dec=1` gets higher when the age difference between the partner and the subject is small. Therefore, we set `age_diff`= 10.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](age_diff_rule_10.png)\n",
    "![title](agediff10_dec_rule.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the picture above, the confidence of this rule is 0.668. The extended lift of `attr`, `age_diff` $\\rightarrow$`dec` is: \n",
    "$elift(attr, age\\_{diff} \\rightarrow dec) = \\frac{conf(attr,age\\_ {diff} \\rightarrow dec)}{(attr,(age\\_{diff} \\rightarrow dec)} = \\frac{0.668}{0.410} = 1.67$. This means that for the female correlated attribute attractiveness and when the age difference between the subject and the partner is, we are 1.67 times more confident that these females chose to see their partner again. However, comparing to $\\alpha = 2$, this rule is not strong enough, and therefore not discriminating. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because `attr` was the only gender-correlated attribute in the model, there are no more association rules to discuss. The examples where the context is set to a specific value are chosen after different experiments with the values of that particular attribute. All the rules have an elift of approximately 1.50 or higher, which means that the model is slighty biased when it splits on the attractiveness attribute. This attribute is slightly gender-correlated, however, the relation is not very strong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Biclustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biclustering algorithms simultaneously cluster rows and columns of a data matrix. These clusters of rows and columns are knows as biclusters. Each determines a submatrix of the original data matrix with some desired properties. \n",
    "\n",
    "In this paragraph we want to find interesting patterns and discriminations or biases that make a grop of subjects, with some coherent characterstics, prefer a specific group of partners, also with some specific characteristics. For Biclustering, the package `coclust` is used. First the values of the unisex model are scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>567.567568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>2333.333333</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>1312.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>666.666667</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>567.567568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4900.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>2333.333333</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>218.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000.000000</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>567.567568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>2333.333333</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>218.75</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>7000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1333.333333</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>567.567568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4900.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>2333.333333</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>437.50</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>7000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>567.567568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>2333.333333</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>656.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1    2       3           4    5       6       7   \\\n",
       "0  1000.000000  1400.0  0.0  7000.0  567.567568  0.0  4200.0  1400.0   \n",
       "1   666.666667  1400.0  0.0  7000.0  567.567568  0.0  4900.0  1400.0   \n",
       "2  3000.000000  1400.0  0.0  7000.0  567.567568  0.0  3500.0  1400.0   \n",
       "3  1333.333333  1400.0  0.0  7000.0  567.567568  0.0  4900.0  1400.0   \n",
       "4  2000.000000  1400.0  0.0  7000.0  567.567568  0.0  3500.0  1400.0   \n",
       "\n",
       "            8       9        10      11      12  \n",
       "0  2333.333333  4200.0  1312.50     0.0  7000.0  \n",
       "1  2333.333333  4200.0   218.75     0.0  7000.0  \n",
       "2  2333.333333  4200.0   218.75  7000.0  7000.0  \n",
       "3  2333.333333  4200.0   437.50  7000.0  7000.0  \n",
       "4  2333.333333  4200.0   656.25     0.0  7000.0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "x = unisex.values\n",
    "scaler = preprocessing.MinMaxScaler((0,7000))\n",
    "X_scaled = scaler.fit_transform(x)\n",
    "X_scaled = pd.DataFrame(X_scaled)\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np, scipy.sparse as sp, scipy.io as io\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from coclust.coclustering import (CoclustMod, CoclustSpecMod, CoclustInfo)\n",
    "from coclust.evaluation.external import accuracy\n",
    "from coclust.visualization import plot_reorganized_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADUAAAD8CAYAAADXAewMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAACm1JREFUeJztnV1sk9Ufxz9POxxsla4tbJMpyXjx\nAghi3OJAcbz5EvDCLGaJysWM3lDGMhcSISaaiMQ3xiZsZFwQMGjiFeNGo4mZYHAhGXtzIk6Hk0xh\nq1u3rl03+/b7XyxtmDI6+Hejpzmfq/bJ6XP62Tl9evrdye8xRERIMUz3+g3MBlpKFbSUKqSkVNq9\nfgNRKioq6O/vB+CBBx7A7/fj8Xj+0+7IkSPk5ube9lxJM1LPPfccJSUlmM1mIpEIHo8Hq9WKw+EA\nIC0tDcMw+PLLL+OeK2mktm/fziOPPAJAMBgEwO/3s3PnTgDsdjsiwsjISNxzJY3UzYTDYUwmE8Fg\nkE8++SR2DGDNmjVxX58Un6kDBw4wMjLCxMQE4XCY0dFRRASz2YxhGIRCodgIFRUVxT2fkUxrvytX\nrvDuu+9iNpsJBAK3bONwOHj//ffJysqa9jxJOf2ibzgrK4v09HQAbDYbCxYs4MMPP7ytECTRSDmd\nTgYHB2/bxjAMNm7cSHl5+e3bJYtUIknK6ff/oqVUISWl5vzLt6Ojg5MnTxKJRNi6dSsvvPBC4juR\nOSQcDkt5ebn09/dLMBiUvXv3Sl9fX8L7mdPp19PTQ25uLjk5OaSlpbFhwwZaWloS3s+cSrnd7thP\nCZhc8rjd7oT3M6dScovvecMwEt7PnEo5HA6GhoZiz4eGhrDZbAnvZ06lli9fzo0bN3C5XIRCIZqb\nmykoKEh4P3O+9mtra+PTTz8lEomwefNmSkpKEt6HXtCqgpZSBS2lClpKFbSUKmgpVdBSqqClVEFL\nqYKWUoW4WfqxY8doa2vDarVSXV0NgM/no6amhr///pvFixfzxhtvYLFYEBFOnjxJe3s76enpOJ1O\nli1bBsC5c+c4c+YMACUlJWzatGn2rOLl0pcvX5arV69KVVVV7Njp06elsbFRREQaGxvl9OnTIiLS\n2toqBw8elEgkIt3d3bJ//34REfF6vbJ7927xer1THs8WcaffqlWrsFgsU461tLRQXFwMQHFxcSwP\nv3TpEk899RSGYfDwww8zNjbG8PAwHR0drF27FovFgsViYe3atXR0dMzCEE1yV58pj8cTS1ZtNhuj\no6PAZFa+aNGiWLtoVv7vDN1ut89Khh4loRcKuYOsfDYy9Ch3JWW1WhkeHgZgeHiYhQsXApMjc/O2\ngWhWbrfbp2Tobrd7VjL0KHclVVBQwPnz5wE4f/48hYWFsePff/89IsKvv/5KRkYGNpuNdevW0dnZ\nic/nw+fz0dnZybp16xJn8S/ixs61tbX8/PPPeL1erFYrpaWlFBYWUlNTw+DgIIsWLaKqqip2ST9x\n4gSdnZ3cd999OJ1Oli9fDkBTUxONjY3A5CV98+bN905KRVJyRaGlVEFLqYKWUgUtpQpaShW0lCpo\nKVXQUqqQklJxY+fBwUHq6+sZGRnBMAy2bdvG9u3bkzt6jhfhut1uuXr1qoiI+P1+qaiokL6+vqSO\nnuNOP5vNFvtLL1iwgLy8PNxud1JHz3f0mXK5XPT29rJixYqkjp5nLDUxMUF1dTVlZWVkZGRM2+5W\nidtcR88zkgqFQlRXV7Nx40Yef/xxILmj57hSIkJDQwN5eXk8//zzsePJHD3HTWh/+eUX3n77bZYu\nXRqbLi+99BIrV65M2uhZx86qoKVUQUupgpZSBS2lClpKFbSUKmgpVdBSqpCSUnFj50AgwDvvvEMo\nFCIcDlNUVERpaSkul4va2lp8Ph/5+fns2bOHtLQ0gsEgdXV1/P7779x///1UVlaSnZ0NQGNjI01N\nTZhMJl599dXZ2/MXL8KNRCIyPj4uIiLBYFD2798v3d3dUl1dLRcuXBARkePHj8s333wjIiJff/21\nHD9+XERELly4IIcPHxYRkb6+Ptm7d68EAgEZGBiQ8vJyCYfDCY2bo8SdfoZhMH/+fGCycls4HMYw\nDC5fvhwrdrZp06YpsXM0+C8qKuKnn35CRGhpaWHDhg3MmzeP7OxscnNz6enpmZWBmlHhmkgkwptv\nvkl/fz/PPvssOTk5ZGRkYDabgakR8s3xstlsJiMjA6/Xi9vtZuXKlbFzzmbsPCMpk8nExx9/zNjY\nGIcOHeKvv/6atq1MEzvf6vhscUdXv8zMTFatWsVvv/2G3++PFRJ0u93Y7XZganWQcDiM3+/HYrH8\np2rIza9JNHGlRkdHGRsbAyavhF1dXeTl5bF69WouXrwITP4zLVoB5LHHHuPcuXMAXLx4kdWrV2MY\nBgUFBTQ3NxMMBnG5XNy4cYMVK1bMilTchPbatWvU19cTiUQQEdavX8+LL77IwMDAfy7p8+bNIxAI\nUFdXR29vLxaLhcrKSnJycgA4c+YM3333HSaTibKyMh599NF7I6UiKbmi0FKqoKVUQUupgpZSBS2l\nClpKFbSUKmgpVUhJqRkXrI5EIuzbtw+73c6+ffuSOnae8Uh99dVX5OXlxZ5/9tln7NixgyNHjpCZ\nmUlTUxMwuacvMzOTo0ePsmPHDj7//HMA/vzzT5qbmzl8+DBvvfUWJ06cIBKJJFhnkhlJDQ0N0dbW\nxtatW4HJwDKZY+cZSZ06dYqdO3fGdmZ6vd67ip2TZrdza2srVqs1tjc9HskQO8e9UHR3d3Pp0iXa\n29sJBAKMj49z6tSpWOxsNptvGTs7HI7kjZ1ffvllGhoaqK+vp7KykjVr1lBRUZHUsfNd34PglVde\noba2li+++IL8/Hy2bNkCwJYtW6irq2PPnj2x2BngoYceYv369VRVVWEymXjttdcwmWbna1LHzqqg\npVRBS6mCllIFLaUKWkoVtJQqaClV0FKqoKVUYUbBy+7du5k/fz4mkwmz2cwHH3ygduUQERGn0yke\nj2fKMaUrh0xHMlcOmXHud/DgQQCefvpptm3bltSVQ2YkdeDAAex2Ox6Ph/fee48lS5ZM21ZUqRwS\nzbytViuFhYX09PSoXTlkYmKC8fHx2OMff/yRpUuXql05ZGBggEOHDgGTm+effPJJSkpK8Hq9unLI\nXJKSKwotpQpaShW0lCpoKVXQUqqgpVRBS6mCllKFlJSaUUQ2NjZGQ0MDfX19GIbBrl27WLJkidqx\n89GjR+Xbb78VkcnqIT6fT+3Y2e/3c+XKldjOy7S0NDIzM9WOnV0uFwsXLuTYsWNcu3aNZcuWUVZW\nltSxc9yRCofD9Pb28swzz/DRRx+Rnp7O2bNnp20vKsTODocDh8MRq89SVFREb2+v2rFzVlYWDoeD\n69evA9DV1cWDDz6oduwM8Mcff9DQ0EAoFCI7Oxun04mI6Nh5LknJFYWWUgUtpQpaShW0lCpoKVXQ\nUqqgpVRBS6lCSkrFzf2uX79OTU1N7LnL5aK0tJTi4mK1Y+co4XBYXn/9dXG5XGrHzjfT1dVFbm4u\nixcvTurY+Y6kfvjhB5544gkAtWPnKKFQiNbW1lhdl+kQFWLnKO3t7eTn55OVlQUofp/EKDdPPVD8\nPokA//zzD7t27aKuri52i06923mOSckVhZZSBS2lClpKFbSUKmgpVdBSqqClVEFLqYKWUgUtpQpa\nShW0lCpoKVXQUqqgpVQhJaX+B9vNJRcK6OKeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a043f25d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADUAAAD8CAYAAADXAewMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nShW0lCpoKVXQUqqgpVQhJaX+B9vNJRcK6OKeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a04379c550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADUAAAD8CAYAAADXAewMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nShW0lCpoKVXQUqqgpVQhJaX+B9vNJRcK6OKeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a000155fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = X_scaled.as_matrix()\n",
    "model_1 = CoclustMod(n_clusters=4, n_init=4)\n",
    "model_1.fit(X)\n",
    "model_2 = CoclustSpecMod(n_clusters=4, n_init=4)\n",
    "model_2.fit(X)\n",
    "\n",
    "model_3 = CoclustInfo(n_row_clusters=3, n_col_clusters=4, n_init=4)\n",
    "model_3.fit(X)\n",
    "\n",
    "plot_reorganized_matrix(X, model_1)\n",
    "\n",
    "plot_reorganized_matrix(X, model_2)\n",
    "\n",
    "plot_reorganized_matrix(X, model_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the best try we could make. We tried also the `biclustering` from the `scikitlearn` package, but that gives the same result. Biclustering is not mentioned in the slides, and the explanation oin the assignment is vague and short. The clusters can't be read well, despite the scaling we applied to it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Peer review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During our work on this assignment, all four group members have tried their best to contribute equally to the completion of the assignment. Naturally though, some group members are more experienced with the programming language that we chose, Python. Furthermore, some group members also have more experience with similar assignments about similar data-sets and their analysis. Therefore, they were able to use their time more efficiently, working on the assignment instead of researching how Python works, for instance. \n",
    "\n",
    "However, since all group members have worked hard on the assignment and have shown that they wanted to contribute all that they could, we do not feel that these differences should be reflected in grading. We think that every member of our group deserves to get the same grade for their contribution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
